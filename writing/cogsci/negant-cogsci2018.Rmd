---
title: "Not unreasonable: Carving vague dimensions with contraries and contradictions"
bibliography: negant.bib
csl: apa6.csl
document-params: "10pt, letterpaper"
header-includes:
  - \usepackage{tabularx}
  - \usepackage{multicol}
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \usepackage{booktabs}
  
author-information: > 
  \author{{\large \bf Michael Henry Tessler (mhtessler@stanford.edu)} \\ Department of Psychology, Stanford University 
  \AND {\large \bf Michael Franke (mchfranke@gmail.com)} \\ Department of Linguistics, University of T\"{u}bingen}

abstract: 
    "Language provides multiple distinct ways of conveying the opposite: A person *not happy*, can be *unhappy*, *sad*, or perhaps neither, just *not happy*. Rather than being redundant, we hypothesize that uncertainty about the meaning of negation markers allows listeners to derive fine-grained distinctions in interpretation among these various alternatives. We formalize this hypothesis in a probabilistic model of gradable adjectives (e.g., *happy*), and use this to address an outstanding puzzle: how to interpret double negations (e.g., *not unhappy*). Our model makes two additional predictions about the ordering of antonyms and their negations (*happy*/*not happy*/*unhappy*/*not unhappy*). Across two behavioral experiments, we confirm consistent orderings of interpretations that interact with context. These findings support the hypothesis that listeners represent uncertainty about the most logical of language: negation. "

keywords:
    "semantics; pragmatics; negation; Bayesian cognitive model; Rational Speech Act"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(cowplot)
library(tidyr)
library(dplyr)
library(magick)
library(ggthemes)
library(formatR)
library(bitops)
library(caTools)
#library(viridis)
theme_set(theme_few())
orange.purple.color.palette <- 
  #c("#fdb863", "#5e3c99", "#e66101", "#b2abd2")
  c( "#b2abd2", "#e66101", "#5e3c99","#fdb863")
orange.purple.blue.color.palette <- 
  #c("#fdb863", "#5e3c99", "#e66101", "#b2abd2")
  c("#74a9cf", "#0570b0","#5e3c99",  "#e66101", "#b2abd2","#fdb863")
```

\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}
\newcommand{\tableref}[1]{Table$\thinspace$\ref{#1}}
\newcommand{\figref}[1]{Figure$\thinspace$\ref{#1}}
\newcommand{\appref}[1]{Appendix \ref{#1}}
\newcommand{\sectionref}[1]{Section \ref{#1}}
\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}
\definecolor{grey}{RGB}{40,40,40}

\newcommand{\red}[1]{\textcolor{Red}{#1}}  
\newcommand{\mf}[1]{\textcolor{Green}{[mf: #1]}}  
\newcommand{\mht}[1]{\textcolor{Blue}{[mht: #1]}} 

\newcommand{\wrapmf}[1]{#1}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
  
  
<!-- title: "Not unreasonable: Conveying the opposite and its opposite" -->
<!-- title: "Not unreasonable: Carving vague dimensions with contraries and contradictions" -->

# Introduction

<!-- If "Jones is happy" you understand that Jones' happiness -- a *gradable property* -- exceeds a certain threshold, which depends on the context and prior expectations about Jones' likely happiness [@kennedy2005scale; @Kennedy2007]. -->
<!-- But what about the compositional "Jones is not unhappy"?  -->
<!-- Do the two negatives make a positive? -->
If "Jones is not unhappy", does that mean that Jones is happy?
@Jespersen1924 believed not:

\begin{quote}
\footnotesize
[T]wo negatives do not exactly cancel one another [$\ldots$]; the longer expression is always weaker: ``this is not unknown to me'' or ``I am not ignorant of this'' means ``I am to some extent aware of it,'' etc. (p.$\thinspace$332)
\end{quote}

*Negated antonyms* (e.g., "not unhappy") are thought to occupy a particular region of their associated scale (e.g., happiness), below that of *positive adjectives* (happy) but above that of *negated positives* (not happy) and *antonyms* (unhappy) [Figure \ref{fig:happy-scale}; @Krifka2007:Negated-antonyms].
<!-- What is the logic of natural language negation such that two negatives don't make positive? -->
<!-- How negated antonyms are interpretated as slightly positive, or even that they are as @Jespersen1924 suggests, is a matter of some controversy. -->
A straight-forward, compositional analysis, however, would map morphological negation via affixation (e.g., *un-*) and negation particles (e.g., adverbial *not*) to proposition-level negation ($\neg$) in modern standard logic. 
Such a logically-transparent theory would predict the two overt negation markers cancel each other out: *not unhappy* means $\neg \neg \text{happy}$, or just *happy*.
@orwell1946politics voices this opinion:

\begin{quote}
\footnotesize
Banal statements are given an appearance of profundity by means of the ``not un-'' formation. [$\ldots$] It should be possible to laugh the ``not un-'' formation out of existence by memorizing this sentence: ``A not unblack dog was chasing a not unsmall rabbit across a not ungreen field.'' (p.$\thinspace$357)
\end{quote}

Alternatively, *morphological antonyms* (*unhappy*) could behave like lexical antonyms (*sad*) which seem clearly to express *contrary opposition*. 
Contraries cannot both be true but they can both be false [@Horn1989:Natural]: Jones may be neither happy nor sad, neither tall not short. 
Just like *tall* and *not short* may be true of the same people, *happy* and *not unhappy* would compete as pragmatic alternatives a speaker could use to describe a state of affairs.
*Not unhappy* would be pragmatically strengthened in context to have a more specific meaning than literally the negation of *unhappy*.
This logic alone, however, entails that *not unhappy* refers to a neutral or indifferent state [@Horn1991:Duplex], contra @Jespersen1924's intuition that *not unhappy* is a slightly positive state.
It's been noted that *not happy* should also be an alternative [@Blutner2004:pragmatics], but how pragmatics contextually strengthens *not happy* has yet to be fully spelled out [@Krifka2007:Negated-antonyms].
Furthermore, the meaning of *not happy* is at least as controversial as that of *unhappy*: @Jespersen1917:Negation and @Blutner2004:pragmatics argue that the two are basically identical in meaning (i.e., antonyms and negated positives are both contradictory in nature), but @Krifka2007:Negated-antonyms cites examples like the following (taken from the internet):

\begin{quote}
\footnotesize
It's an absolutely horrible feeling to be unhappy, and I don't even think I was unhappy, just not happy, if you know what I mean. 
\end{quote}

```{r happy-scale, fig.height=2, fig.width=3.5, fig.align = "center", fig.cap="Possible ordering of antonyms and their negations."}
happy.scale <- data.frame(
  adjective = c("happy", "not unhappy", "not happy", "unhappy"),
  low = c(0.75, 0.5, 0.25, 0),
  high = c(1, 0.75, 0.5, 0.25),
  x = 1,
  y = c(0.875, 0.625, 0.375, 0.125)
) %>%
  mutate(adjective = factor(adjective, levels = c("happy", "not unhappy", "not happy", "unhappy")))

ggplot(happy.scale, aes(x = x, y=y, ymin = low, ymax = high, color = adjective,
                        label = adjective))+
  geom_linerange(size = 5)+
  scale_color_manual(name="Adjective",
                    values = orange.purple.color.palette,
                    guide = guide_legend(reverse=TRUE))+
  coord_flip()+
  geom_label(x = 1.015, label.size = 0.5, size = 3)+
  guides(color = F)+
  scale_y_continuous(limits = c(0,1), breaks = c(0, 1))+
  scale_x_continuous(limits = c(0.9, 1.1))+
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        panel.border = element_blank())
```



<!-- Negation is the semantic operation of forming an opposite, but there are multiple kinds of semantic opposition -->
<!-- A *contrary* opposition is one where both predicates cannot be true at the same time, but both can be false. -->
<!-- <!-- "Happy" (a *positive* adjective) and "sad" (a *negative* adjective) or "polite" and "rude" are two such examples: it is conceivable that Jones is neither happy nor sad, but in a neutral middle ground. -->
<!-- In contrast, a *contradictory* opposition (e.g., *even/odd* positive integer), is one where falsity of one predicate entails truth of the other. -->
<!-- "Not happy" (a *negated positive*) or "unhappy" (an *antonym*) seem like good contenders to express contradictory opposition because each maps transparently to proposition-level negation ($\neg$) in modern standard logic.^[ -->
<!--   While "sad" is of course also an antonym of "happy", we speak of *negative* and *positive* adjectives, and reserve *antonym* for antonyms created by affixal negation (e.g., "un-").  -->
<!--   Also, we use *particle negation* or *negated X* for negation formed by "not" over the more accurate "adverbial negation". -->
<!--   We use a somewhat idiosyncratic terminology so as to be concise in the distinctions most relevant for this paper. -->
<!-- ] -->
<!-- If this is so, however, combining the two contradictory devices should cancel each other out: "not unhappy" means "happy". -->
<!-- Alterantively, antonyms created by affixal negation (*un-*, *in-*, etc.) could form a contrary, like a negative adjective. -->

<!-- Here is an instance of an attested difference in meaning between negated positives and morphological antonyms (e.g., *not happy* and *unhappy*), taken from @Krifka2007:Negated-antonyms, taken from internet: -->


<!-- This example suggests that at least in the context of explicit alternative utterances (*not unhappy just not happy*), antonyms and negated positives can take on distinct meanings, even if they may not in isolation. -->
How does such a logical linguistic device---negation---give rise to a multiplicity of meanings?
We posit that uncertainty about the meaning of overt negation markers (*un-*, *not*) interacts with communicative reasoning principles to give rise to fine-grained interpretations in the moment.
We propose a probabilistic speaker-listener pragmatic reasoning model in the Rational Speech Act tradition [@Franke2015a; @Goodman2016:RSA], combining previous work on gradable adjectives [e.g., *tall*; @Lassiter2015; @Qing2014:Adjectives] with elements of lexical uncertainty [@Bergen2016].
Our model interprets *not unhappy* as a slightly positive state and predicts qualitative differences between morphological antonyms (e.g., \{*happy*, *unhappy*\}) and antonyms that lack overt negation markers (*lexical antonyms* e.g., \{*tall, short*\}).
These differences are also shown to be sensitive to the presence of explicit alternative utterances [as illustrated in @Krifka2007:Negated-antonyms's example above]. 
We compare model predictions to novel data from two experiments that measure interpretations for different kinds of adjectives in different contexts, uncovering subtle but reliable differences.
<!-- These findings suggest that uncertainty in logical meanings can be exploited by pragmatic reasoning to signal fine-grained meaning on otherwise vague dimensions.  -->

<!-- \noindent We did not find such a difference in our experiment, but rather than conclude that no differnce exists, we note that the speaker in this example utterance chose to use both *unhappy* and *not happy* in the same utterance.  -->
<!-- We hypothesize that explicit comparisons between alternative utterances can draw out the difference in meaning between negated positives and morphological antonyms, which leads the morphological antonym to behave more like a bonafide antonym. -->

<!-- Given the manifold interpretations of antonyms and particle negation, we hypothesize that listeners represent these possibilities as uncertainty in meaning of overt negation markers and resolved it in context. -->
<!-- We propose a probabilistic speaker-listener pragmatic reasoning model in the Rational Speech Act tradition [@Franke2015a; @Goodman2016:RSA],  to model the indeterminacy about how to interpret overt negation markers.  -->
<!-- We combine previous work deriving interpretations for gradable adjectives by considerations of cooperative language use [@Lassiter2015; @Qing2014:Adjectives] with elements of lexical uncertainty [@Bergen2016]. -->
<!-- We compare model predictions to novel data from three experiments that measure interpretations for positive and negative adjectives (*happy*/*sad*) as well as antonyms (*unhappy*) and particle negations (*not happy/sad/unhappy*) in different contexts, uncovering subtle but reliable differences. -->
<!-- These findings suggest that pragmatic reasoning can utilize uncertainty in logical meanings to derive finer-grained interpretations through the competiton of multiple interpretations of multiple alternative utterances. -->
<!-- \mht{this last sentence is a behemoth \mf{is that a good thing? from Wikipedia: "Metaphorically, the name has come to be used for any extremely large or powerful entity."}}\mht{strictly speaking: I prefer my mythical creatures in metaphorically bite-size chunks} -->

<!-- In Experiment 1, we measure uncover this ordering for antonym pairs defined with unique lexical items (e.g., *tall*/*short*) but not for morphological antonyms (e.g., "happy"/"unhappy").  -->
<!-- In Experiment 2, we show that morphological antonyms to create a reliable ordering when context clearly provides a speaker's alternatives utterances. -->
<!-- In a large-scale, preregistered study, we replicate these findings within sets of adjectives that allow both lexical and morphological antonyms (e.g., "happy" / "unhappy" / "sad").  -->


<!-- Classical, bivalent logic mandates that two negatives make a positive, but speakers can use double negation (e.g., "not" + "un-" + "reasonable") in a non-redundant manner. -->
<!-- As @Jespersen1924 noted: -->

<!-- > The two negatives do not exactly cancel one another... the longer expression is always weaker: "this is not unknown to me" or "I am not ignorant of this" means *I am to some extent aware of it*, etc. -->

<!-- This intuitions is surely shared for *negated antonyms* (e.g., "not sad") and is predicted to carve the underlying semantic scale is a relatively stable ordering: "sad" $<$ "not happy" $<$ "not sad" $<$ "happy" [@Horn1989:Natural; @Krifka2007:Negated-antonyms]. -->
<!-- But creating an opposite meaning through an *affixed morpheme* (e.g., "un-") does not unambiguously create an antonym. -->
<!-- As @orwell1946politics noted:  -->

<!-- > Banal statements are given an appearance of profundity by means of the "not un-" formation... It should be possible to laugh the "not un-" formation out of existence by memorizing this sentence: "A not unblack dog was chasing a not unsmall rabbit across a not ungreen field." -->



<!-- The answer to how listeners interpret different kinds of opposing meanings lies at the intersection between compositional semantics and vague language understanding. -->
<!-- We draw inspiration from usage-based theories of grammar \red{(cite: ODonell2015, Bybee 2011?)} to introduce uncertainty about how to parse *morphological antonyms* (e.g., "unhappy") into a probabilistic model of gradable adjective understanding.  -->
<!-- This *uncertain parser* model includes, as a special case, a sub-model that interprets antonyms and their negations, producing the hypothesized ordering (Figure 1). -->
<!-- In Experiment 1, we measure uncover this ordering for antonym pairs defined with unique lexical items (e.g., "tall"/"short") but not for morphological antonyms (e.g., "happy"/"unhappy").  -->
<!-- In Experiment 2, we show that morphological antonyms to create a reliable ordering when context clearly provides a speaker's alternatives utterances. -->
<!-- In a large-scale, preregistered study, we replicate these findings within sets of adjectives that allow both lexical and morphological antonyms (e.g., "happy" / "unhappy" / "sad").  -->
<!-- These findings suggest that pragmatic reasoning can utilize the tension between parsing utterances compositionally (e.g., "un-" + "happy") and interpreting them holistically ("unhappy") to derive fine-grained meanings in-the-moment. -->


<!-- We hypothesize that the conflict in the literature surrounding  -->


<!-- In logic, two negatives make a positive, but the same does not seem to hold in natural language.  -->
<!-- Somebody "not sad" is not necessarily "happy".  -->
<!-- "Sad" is an antonym, whereas the particle "not" simply negates the positive "happy". -->



<!-- Instead, antonyms and their negations appear to partition the underlying semantic scale in an ordering:  We show how this semantic ordering falls out of an information-theoretic model of adjective interpretation, without assuming that *unhappy* $<$ *happy*. We then empirically investigate the semantic ordering, finding that the ordering appears when participants are fully aware of the utterances a speaker could say for antonym pairs defined by morphological negation (*[un]happy*); the explicit presentation of alternatives is not necessary for the analogous ordering of antonym pairs of distinct lexical items (*tall* / *short*). These findings suggest a model of interpretation where listeners maintain uncertainty about the parsing of an utterance involving multiple negations." -->


<!-- , derive this intuitive ordering which we validate in an expt. -->


<!-- Jespersen's intuition is not universally shared, however.  -->
<!-- "Not" and "un-" can be two ways of saying the same thing.  -->
<!-- "Not unreasonable" might mean "reasonable". -->


<!-- Why does language provide multiple, seemingly identical ways of conveying the same meanings? -->
<!-- Classical logic distinguished statements that are contrary to one another (e.g., *antonyms*; "Sam is happy" vs. "Sam is sad") and those that are contradictory (e.g., using *negation particles*: "Sam is *not* happy"). -->
<!-- For Jespersen's intuition to hold, "unhappy" (*morphene negation*) must be a *contrary*, like "sad".  -->
<!-- Then, "not unhappy" can receive a restricted interpretation via its literal meaning and pragmatic competition with "happy" [@Horn1991:Duplex; @Horn1993:Economy]. -->
<!-- This model, however, renders "not unhappy" as neutral or indifferent, contrary to the intuition that "not unhappy" is a slightly positive state [@Krifka2007:Negated-antonyms]. -->



<!-- \mht{Recent breakthroughs in the probabilistic modeling tradition have put this within grasp.} -->
<!-- We use the tools of probabilistic pragmatics to formalize how negated and antonymous meanings should produce an ordering on interpretations: *sad* $<$ *not happy* $<$ *not sad* $<$ *happy*. -->
<!-- We then investigate the ordering with *morpheme negation* (e.g., "unhappy"), providing empirical evidence that it is treated the same as *particle negation* (e.g., "not happy") when the relevant alternative utterances are not salient to the listener. -->
<!-- We hypothesize that *parsing uncertainty* underlies this interpretative behavior idiosyncractic to morpheme negation. -->


<!-- - There are two kinds of negation. -->
<!-- - They can be used together while not cancelling out.  -->
<!-- - Yet more forms exist: unhappy. -->
<!--   - morphological antonyms have been of particular interest for their underspecification inmeaning (conflicting intuitions) -->
<!--   - we hypothesize that the conflict in the literature can be attributed to an uncertain parse of morphological negation. -->
<!-- - We formalize this hypothesis in a model of gradable adjectives. As a special case of this model, when there is no uncertainty about parsing, the model reduces to a model of antonyms and negations, which predicts a precise ordering. Instead the uncertain parse model does not differentiate between two kinds of negation. We thus predict an interaction between parsing uncertainty and the difference between antonymous negation and particle negation. -->

<!-- \mht{mention ordering?} -->

<!-- underespecified meanings for gradable adjectives interacts with negation to produce  -->
<!-- Probabilistic models of pragmatic reasoning have proved useful in formalizing the vagueness of gradable adjectives [e.g., "happy"; @GoodmanLassiter2015-handbook], and we adopt this formalism to better understand  -->
<!-- A speaker can use a particle (e.g., "not happy"), affix a morpheme (e.g., "unhappy"), or say an antonym (e.g., "sad") -->
<!-- Contra classical logic, however, these two ways of employing negation *do not* cancel each other out: someone "not unhappy" is not necessarily happy. -->

```{r old-happy-scale, fig.cap="Hypothesized ordering of sets of antonyms and their negations.", eval=F}
ggdraw() + draw_image("img/happy-scale.pdf") +
  theme(plot.margin = unit(c(0,0,0,0), "pt")) 
```

<!-- The plot thickens when we consider that lexically-distinct words also provide antagonistic meanings: "" -->

<!-- These two issues motivate our current approach. -->
<!-- First, competing intuitions concerning the meaning of what we will here call *particle negation* ("not happy") and *affix negation* ("unhappy") suggest that empirical data should be consulted before further theorizing about pragmatic mechanisms. -->
<!-- Second, the fact that the mechanisms of pragmatic strengthening of particle negation are not clear suggests a benefit from a formal modeling approach.  -->
<!-- We first elaborate a computational model of adjective interpretation to include antonyms and their negations: adjectives (e.g., "happy"), their antonyms (e.g., "sad"), and the negations of each ("not happy", "not sad"). -->
<!-- We then formalize a hypothesis that natural language negation passes through a probabilistic parsing model, which provides a novel prediction about the interpretations of different kinds of negation (e.g., "not happy", "unhappy", "sad"). -->
<!-- In a behavioral experiment, we investigate the hypothesized ordering of antonym quartets for antonyms with distinct lexical entries (e.g., "tall" and "short") and antonyms constructed by affix negation (e.g., "happy" and "unhappy"). -->

<!-- \begin{figure}[h] -->
<!-- \vspace{-2.5cm} -->
<!-- \includegraphics[width = \columnwidth]{figs/happy-scale-1}  -->
<!-- \vspace{-3cm} -->
<!-- \caption[Hypothesized ordering of sets of antonyms and their negations]{Hypothesized ordering of antonyms and negations.}\label{fig:happy-scale} -->
<!-- \end{figure} -->

# Computational model


Negation is the semantic operation of forming an opposite, but there are multiple kinds of semantic opposition
A *contrary* opposition is one where both predicates cannot be true at the same time, but both can be false (e.g., *tall* and *short*).
In contrast, a *contradictory* opposition (e.g., *even/odd* positive integer), is one where falsity of one predicate entails truth of the other.
We posit that listeners have uncertainty about whether negation markers (*not*, *un-*) express contradictory or contrary opposition, and examine its effect on the interpretation of negated gradable adjectives (e.g., *tall*, *happy*).

Formal linguistic theories capture the meaning of gradable adjectives as a threshold function: $\denote{happy} = \lambda e \thinspace . \thinspace \text{happiness}(e) > \theta$, whose threshold variable $\theta$ is supplied by the context [@Kennedy2007]. Here, we consider a pragmatic model that reasons about which value for $\theta$ would make a speaker's observed utterance most likely [@Lassiter2015]. 

How to combine a threshold semantics with contrary and contradictory negation?
Formally, if $Hx$ expresses that $x$ is happy, contradictory opposition is standard, bivalent, proposition-level negation $\neg Hx$.
Contrary opposition is made by a predicate-forming operation $\tilde{H}x$ which introduces its own free threshold $\theta_{\tilde{H}}$ for gradable predicates.
The latter is not iterable [@Horn1989:Natural; @sep-negation], so while it makes sense to iterate $\neg \neg Hx$, it is impossible to iterated contrary negation. 
<!-- It is, however possible, to have $\neg \tilde{H}x$.  -->
<!-- But it is not possible to have $\neg$ in the scope of $\tilde{H}x$. -->
As a result, *not happy* and *unhappy* can be construed as either $\neg Hx$ or $\tilde{H}x$, while "not unhappy" may be $\neg \neg Hx$ or $\neg \tilde{H}x$ (Table$\thinspace$\ref{tab:Interpretations}).
<!-- Negative adjectives (e.g., "short", discussed later) have no overt negation marker, and thus are assumed to be contraries $\tilde{H}x$, which receive their own thresholds $\theta_{\tilde{H}}$. -->

\begin{table}[b]
  \vspace{-0.25cm}
  \centering
  \footnotesize
  \begin{tabular}{ll}
	\textbf{expression} & \textbf{interpretation options} \\ \midrule
    \emph{not happy} / \emph{unhappy} & $\lambda e \thinspace . \thinspace \neg (\mathit{happiness}(e) >
    \theta_{h})$ \\
    & $\lambda e \thinspace . \thinspace \mathit{happiness}(e) <
    \theta_{\tilde{h}}$ \\ \midrule
    \emph{not unhappy} & $\lambda e \thinspace . \thinspace \mathit{happiness}(e) >
    \theta_{h}$ \\
		& $\lambda e \thinspace . \thinspace \neg(\mathit{happiness}(e) <
    \theta_{\tilde{h}})$ \\ 
  \end{tabular}
  \caption{Logically possible interpretations of negated expressions.}
  \label{tab:Interpretations}
\end{table}

A listener's uncertainty about how to interpret negation markers can be formally modeled as uncertainty about the lexicon $\mathcal{L}$ a speaker is likely to use [@Bergen2016]. 
We combine this technique with a model that derives plausible thresholds $\theta$ for gradable adjective interpretation @Lassiter2015 [see also @Potts2008:Interpretive-Ec; @Qing2014:Adjectives].

\vspace{-0.5cm}
\begin{align}
L_{1}(x, \theta, \mathcal{L} \mid u) &\propto S_{1}(u \mid x, \theta, \mathcal{L}) \cdot P(x) \cdot  P(\theta) \cdot P(\mathcal{L}) \label{eq:L1} \\
S_{1}(u \mid x, \theta, \mathcal{L}) &\propto \exp{(\alpha \cdot \ln {L_{0}(x \mid u, \theta, \mathcal{L})} - \text{cost}(u))} \label{eq:S1}\\
L_{0}(x \mid u, \theta, \mathcal{L}) &\propto \mathcal{L}(u, x, \theta) \cdot P(x) \label{eq:L0}
\end{align}

\noindent where $\mathcal{L}(u, x, \theta)$ represents the semantic truth-function of $u$ in lexicon $\mathcal{L}$ applied to state $x$ assuming semantic threshold $\theta$.

Eqs.$\thinspace$\ref{eq:L1}-\ref{eq:L0} are a Rational Speech Act (RSA) model, a recursive Bayesian model wherein a pragmatic listener $L_{1}$ tries to resolve the intended meaning of an utterance $u$ (e.g., "Jones is not unhappy") by combining its prior beliefs $P(x)$ about the degree $x$ of Jones' happiness, with the generative process of the utterance, a speaker model $S_1$.
The speaker model $S_1$ (Eq.$\thinspace$\ref{eq:S1}) describes an approximately rational Bayesian agent (with degree of rationality $\alpha$) trying to inform a naive listener $L_0$ (Eq.$\thinspace$\ref{eq:L0}) about the degree $x$.
<!-- In the context of adjective interpretation, the state of the world is given by the value of the scalar degree $x$ (e.g., the height of the referent). -->
The literal listener $L_0$ updates its prior beliefs $P(x)$ via an utterance's literal meaning in lexicon $\mathcal{L}$.
Additionally, the pragmatic listener (Eq.$\thinspace$\ref{eq:L1}) has uncertainty about $\theta$, which comes from an uninformed prior and is resolved by jointly reasoning about the likely degree $P(x)$, the likely lexicon $P(\mathcal{L})$, and the likelihood $S_1(u \mid x, \theta, \mathcal{L})$ that a cooperative information-maximizing speaker would utter the adjective given a degree $x$, threshold $\theta$, and lexicon $\mathcal{L}$.

Possible lexica differ in how overt negation markers (*un-*, *not*) are semantically parsed (Table$\thinspace$\ref{tab:Interpretations}).
According to the *uncertain negation* model listeners have uncertainty about which lexicon a speaker may be using; we explore the simplest instantiation of this model, putting equal probability on the logically possible parses of utterances with negation.^[These model predictions assume the following model parameters: $P(x) = \mathcal{N}(0, 1); \alpha = 1; \text{cost}(\mathit{un}) = 1; \text{cost}(\mathit{not}) = 2$.]
When this model hears *not unhappy* it reasons that a truly compositional, double negation is implausible (intuitively because the speaker could have said the simpler *happy*) and interprets the utterances as signalling a slightly positive state (Figure$\thinspace$\ref{fig:modelPredictions}).
Interestingly, the *uncertain negation* model does not differentiate antonyms (*unhappy*) from negated positives (*not happy*)---in line with the intuition of @Jespersen1917:Negation and @Blutner2004:pragmatics.\mf{clearer references to which part of Figure are relevant; use same model names in figure and order left-right like introduced in text?}

Different settings to the lexicon prior $P(\mathcal{L})$ correspond to distinct hypotheses about the semantics of overt negation.
An alterantive *pure logical negation* (or *George Orwell*) model can be derived by assigning probability zero to lexica with contrary interpretations of overt negation markers. 
This model believes negation markers only express contradictory opposition. 
As a result, the *pure logical negation* model does not differentiate between negated antonyms (*not unhappy*) and positives (*happy*), nor between negated positives and antonyms.

As a second alternative, we consider a model that interprets morphological negation (*un-*) as expressing true contrary opposition by assigning probability zero to lexica with contradictory interpretations of morphological antonyms.
This *bonafide contraries* hypothesis still has uncertainty about the correct interpretation of particle negation (*not*), but in context, reasons that *not* should be interpreted as contradictory opposition ($\neg$) so as to keep the lexicon non-redundant.
This model interprets negated antonyms (*not unhappy*) as slightly positive and predicts the ordering hypothesized by @Krifka2007:Negated-antonyms and shown in Fig.\ref{fig:happy-scale}.

We posit uncertainty about the meaning of negation that is resovlved in context. 
As such, multiple utterances heard in the same context can have different meanings than a single utterance heard in isolation. 
We simulate the three models' predictions when presented with multiple utterances in the same context.^[
  To match our experimental setup described later, the multiple utterances simulation corresponds to hearing all four adjective alternatives about four different individuals.
]
In this situation, all models have more exaggerated interpretations from the adjectival utterances.
The *uncertain negation* model, though, uniquely differentiates itself from the single utterance simulation: It now predicts a true ordering as in Figure \ref{fig:happy-scale} between negated positives and antonyms.


<!-- The proportionality in Eq.$\thinspace$\ref{eq:S1} implies normalization over a set of alternative utterances (potentially differentiated by their cost). -->
<!-- Our primary focus is on an alternative set composed of a positive adjective, its antonym, and their respective negations [e.g., \{*happy*, *not happy*, *unhappy*, *not unhappy*\}; @Blutner2004:pragmatics; @Krifka2007:Negated-antonyms]. -->



<!-- \mht{explain why quantitative differences are exaggereted? maybe too much...} -->
<!-- However, in the context of explicit alternative utterances, the differences in interpretation between a positive adjective and its negation become quantitatively exaggerated ().  -->

<!-- \mht{i wonder if we should talk about all model variants with the same alternative set (unhappy), and note at the end of this paragraph that the bonafide antonyms model we hypothesize is the correct model for lexical anotnyms} -->
<!-- alternative set \{*happy*, *not happy*, *sad*, *not sad*\}, where a *bonafide antonym* like *sad* receives its own independent threshold, since it unambiguously expresses contrary  opposition; alternatively, this model can be interpreted as a special case of alternatives \{*happy*, *not happy*, *unhappy*, *not unhappy*\} when the listener only considers *unhappy* as contrary opposition, thus treating *unhappy* as a *bonafide antonym* like *sad*. -->
<!-- We retain uncertainty about the meaning of particle negation. -->












<!-- We consider two such alternative sets: postives, negatives, and their negations (e.g., \{*tall*, *not tall*, *short*, *not short*\}) and positives, antonyms, and their negations  -->


<!-- cases, distinguished by what antonym is assumed for a positive form like *happy*. -->
<!-- First, with a *lexical antonym* the set of alternative utterances is \{"happy", "not happy", "sad", "not sad"\}. -->
<!-- Second, with a *morphological (affix-negated) antonym* the set of alternative utterances is: \{"happy", "not happy", "unhappy", "not unhappy"\} [@Blutner2004:pragmatics; @Krifka2007:Negated-antonyms]. -->
<!-- The pragmatic listener assumes that affixal negation (e.g., *un-* or *in-*) and particle negation (e.g., *not*) can in principle both be used to express contradictory or contrary opposition.  -->
<!-- Rational pragmatic reasoning decides which interpretation of a negation marker is more likely, in conjunction with which thresholds to assign to any basic gradable expressions. -->

```{r modelPredictions, fig.cap="Predictions for the strengths of adjective interpretations for three model variants.", fig.env = "figure", fig.pos = "t", fig.width=3.5, fig.height=3, fig.align = "center"}
load('cached_results/rsa_model_predictions.RData') # rs.listener.wp.expectation

# new_type = ifelse(antonym_type == "lexical", 
#                            ifelse(adjective_type == "Antonym", "Negative", 
#                             ifelse(adjective_type == "Negated Antonym", "Negated negative", 
#                                    as.character(adjective_type))), as.character(adjective_type))

rs.listener.wp.expectation %>%
  mutate(utterance = factor(utterance, levels = c("Antonym", "Negated positive",
                         "Negated antonym", "Positive"),
                         labels = c("Antonym", "Negated\npositive",
                         "Negated\nantonym", "Positive")),
         src = factor(src, levels = c("george orwell", "bonafide contraries", "full uncertainty"),
                      labels = c("george orwell", "bonafide contraries", "full uncertainty")),
         utterances = factor(utterances, 
                             levels = c("independent", "simultaneous"),
                             labels = c("implicit", "explicit"))) %>%
  ggplot(., aes( x = src, y = interpretation,
                 fill = utterance))+
    geom_col(position = position_dodge(0.8), 
             width = 0.8, color = 'black')+
    scale_fill_manual(name="Adjective type",
                    values = orange.purple.color.palette,
                    guide = guide_legend(reverse=F,
                                         keywidth = 0.5,
                                         keyheight = 0.4,
                                         default.unit = "cm"))+
  facet_wrap(~utterances)+
  #xlab("Model")+
  ylab("Model interpretation")+
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 10, vjust = 0),
    axis.text.y = element_text(size = 9),
    #axis.text.x = element_text(size = 9, angle = 30, hjust = 0.8, vjust = 0.9), 
    axis.text.x = element_text(size = 9, angle = 45, hjust = 1, vjust = 1), 
        legend.position = 'bottom',
        legend.text = element_text(size = 9, hjust= 0),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(-7,0,0,-10),
        legend.title = element_blank(),
    panel.spacing = unit(0, "lines")
        #legend.key.size = unit(0.5, "cm"),
      #legend.key = element_rect(size = 10)
      )+
  scale_y_continuous(limits = c(-0.8, 0.85), breaks = c(-0.75, 0, 0.75))#+
  #guides(fill=guide_legend(nrow=2,byrow=TRUE))
```




<!-- and evaluate them (and our *full uncertainty* model) in situations where they hear a single utterance from a speaker (e.g., "Jones is unhappy") and when they multiple utterances from a speaker (e.g., "Jones is unhappy. Smith is not unhappy."). -->



To summarize, we hypothesize that overt negation markers (*un-*, *not*) come with uncertainty in meaning (contrary vs. contradictory negation) that produces a partial ordering for antonym pairs and their negations when heard in isolation (Figure$\thinspace$\ref{fig:modelPredictions} left, *uncertain negation*).
This uncertainty can be resolved by hearing multiple utterances from the same speaker, producing a full ordering (Figure$\thinspace$\ref{fig:modelPredictions} right, *uncertain negation*).
As a control condition, we additionally predict that antonyms which do not have overt negation markers (e.g., *short*) will thus behave like *bonafide contraries* and show a full ordering regardless of the context. 
We design our behavioral experiments to test these predictions.
<!-- \text{Expts.$\thinspace$1 $\&$ 2} were exploratory and informed our computational modeling. -->
\text{Expt.$\thinspace$1} was exploratory and informed our computational modeling.
\text{Expt.$\thinspace$2} is a more powerful and more stringent, preregistered confirmatory replication.
Experimental paradigms, computational models, preregistration report, and data for this paper can be found at \url{https://mhtess.github.io}.
<!-- \mht{i feel like this paragraph and the one right after it could be merged somehow..} -->
\mf{what about the official preregistration as OSF?}

# Behavioral experiments

The *uncertain negation model* predicts that antonyms created by affixal negation (*unhappy*) and negated positives (*not happy*) receive similar interpretations when evaluated in isolation, but are drawn apart when heard in the same context.
<!-- while negated antonyms (*not unhappy*) are interpreted more weakly than positive adjectives (*happy*). -->
We contrast this context-sensitive quasi-ordering for *morphological antonyms* (*unhappy* $\approx$ *not happy* $<$ *not unhappy* $<$ *happy*) with a full-ordering predicted when overt negation is not present in antonyms (*bonafide contraries* model), as for *lexical antonyms* (*short* $<$ *not tall* $<$ *not short* $<$ *tall*), the latter of which is predicted even when utterances are presented in isolation. 

## Experiment 1: Single utterances

<!-- ### Methods -->

```{r expt1_subjInfo}
load("cached_results/time_summary_e1.RData") # d.expt1.time.summary
load("cached_results/english_summary_e1.RData") # d.l1.7.nativeEnglish
```

### Participants

We recruited 120 participants from Amazon's Mechanical Turk (MTurk). 
This number was arrived at with the intention of getting approximately 25 ratings for each unique item in the experiment.
In all experiments, participants were restricted to those with U.S. IP addresses and at least a 95\% work approval rating. 
The experiment took on average `r round(d.expt1.time.summary[[1, "aveTime"]],1)` minutes and participants were compensated \$0.40 for their work.

### Procedure

On each trial, participants read a statement introducing a person using a gradable adjective of one of four *adjective types*: 
<!-- $\textsc{positives}$ -->
positives (e.g., *happy*, *tall*), 
<!-- $\textsc{opposites}$  -->
antonyms (e.g., *short*, *unhappy*), and their respective negations (e.g., *not* + adj). 
There were two *antonym types* (mophological, e.g., *unhappy*; and lexical, e.g., *short*).
Participants were asked to rate the character on a scale from "the most \textsc{positive} person" to "the most \textsc{anotnym} person", which depended on the item, using a slider bar (\figref{fig:experiment-slides}A).
Participants rated one sentence at a time (e.g., "Greg is not unhappy") and saw items from both antonym types throughout the experiment. 
Each participant completed a total of 16 trials, with exactly 2 repetitions of each adjective type in each antonym type.

### Materials 

*Adjective sets* described properties of people using a positive adjective, its antonym (morphological or lexical), and their negations using the particle "not" (e.g., one adjective set is *happy*, *unhappy*, *not happy*, *not unhappy*).
10 adjective sets were constructed for each antonym type (total 20 adjective sets) from an informal survey of the linguistics literature and taken from a list of "common opposites" available online (for a full list, see Table 2).^[http://www.enchantedlearning.com/wordlist/opposites.shtml]
Each trial of the experiment used an adjective from a distinct adjective set (e.g., if a participant rated *unhappy*, they rated no other adjective from the \{*happy*, *unhappy*\} set).


```{r items12, results="asis"}
load(file = "cached_results/item_table_e12.RData")
print(tab1, type="latex", comment = F, table.placement = "H", size="\\fontsize{9pt}{10pt}\\selectfont", include.rownames=FALSE)
```


```{r experiment-slides, fig.pos = "hbt", fig.cap="Example experimental trials.", fig.env = "figure*", fig.width=7, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2}
slide.expt.1 <- cowplot::ggdraw() + 
  cowplot::draw_image("img/expt1.jpeg", scale = 1) +
  theme(plot.margin = unit(c(0,0,0,0), "pt")) + 
  cowplot::panel_border()
slide.expt.2 <- cowplot::ggdraw() + 
  cowplot::draw_image("img/expt2.jpeg", scale = 1)+
  theme(plot.margin = unit(c(0,0,0,0), "pt")) + 
  cowplot::panel_border()

cowplot::plot_grid(
    cowplot::add_sub(slide.expt.1, "Experiment 1 (implicit alternatives)", size = 8), 
    cowplot::add_sub(slide.expt.2, "Experiment 2 (explicit alternatives)", size = 8), 
    labels = c("A", "B"), 
    nrow = 1)
```





### Results

```{r regression_expt1}
load("cached_results/regression_antTypeXadjType_expt1.RData") # rs1.expt1.helmert.summary
rs1.expt1.coef <- rs1.expt1.helmert.summary[["coefficients"]]
```

`r sum(!d.l1.7.nativeEnglish$englishNative)` participants were excluded for self-reporting a native language other than English, leaving a remainder of `r sum(d.l1.7.nativeEnglish$englishNative)` participants for these analyses.

The qualitative predictions of our models concern the ordering within a set of alternatives for different antonym types (morphological vs. lexical).
To visualize the data, we compute normalized responses on a participant-wise basis (i.e., normalized response $r'_{ij} = \frac{r_{ij} - mean_j}{sd_j}$ for trial $i$ and participant $j$).
Figure \ref{fig:expt-results}A shows the mean normalized responses and bootstrapped 95\% confidence intervals for each of the four adjective types for morphological and lexical antonyms.
As predicted by the bonafide contraries model, adjective sets with lexical antonyms show a strict ordering: $\textsc{opposite}_\textsc{neg} < \textsc{negated positive} < \textsc{negated opposite}_\textsc{neg} < \textsc{positive}$.
Critically, as predicted by the uncertain negation model, adjective sets with morphological antonyms show only a partial ordering: $\textsc{opposite}_\textsc{ant} \approx  \textsc{negated positive} < \textsc{negated opposite}_\textsc{ant} < \textsc{positive}$.

To confirm these observations, we built a linear mixed model predicting the raw, unnormalized ratings in terms of fixed effects of *antonym type* (morphological vs. lexical), *adjective type* (Helmert coded in order: antonym, negated positive, negated antonym, positive^[
 Throughout, we code adjective type using Helmert coding, which compares levels of a factor to the average of preceding levels, in order to compare anotnym vs. negated positive levels of the adjective type factor.
]), and their interaction; the model also included random intercepts and random slopes of *adjective type* by-participant and by-item.^[
  This, and all subsequent regression models, were the maximal mixed-effects model that converged for the data set that additionally explained significantly more variance than models with simpler mixed-effects structures, using the \texttt{lme4} package in R [@lme4].]
Consistent with our observations, the difference between the *antonym* vs. *negated positive* levels of adjective type interacted significantly with antonym type (morphological vs.\text{~}lexical): $\beta = `r round(rs1.expt1.coef["antonym_typelexical:st1","Estimate"],3)`$, $SE =  `r round(rs1.expt1.coef["antonym_typelexical:st1","Std. Error"],4)`$, t$(`r round(rs1.expt1.coef["antonym_typelexical:st1","df"], 1)`) = `r round(rs1.expt1.coef["antonym_typelexical:st1","t value"],2)`, p = `r round(rs1.expt1.coef["antonym_typelexical:st1","Pr(>|t|)"], 4)`$.

We additionally observe that interpretations of negated morphological antonyms (e.g., *not unhappy*) were appreciably less positive for than those of negated lexical antonyms (e.g., *not tall*). 
\mf{I don't understand the previous sentence.}
Investigation of the empirical distribution of responses revealed that negated antonyms received a bimodal distribution of ratings: The vast majority of ratings were slightly positive, while a clearly distinguishable minority distribution of ratings were slightly negative (e.g., *not dishonest* meaning that the person is below average in honesty).
This marginally negative interpretation for negated antonyms was seen at least somewhat in every item and roughly half of participants gave at least one below average rating for a negated antonym. 
<!-- \mf{Was this bimodality consistent between certain subjects or certain items? Does this violate assumptions of normality for the regression model?}\mht{i looked at the residuals... which are not crazy... but then again, I dont often do residuals / regression so i'm not totally sure...} -->
This interpretation may be attributable to politeness on behalf of the speaker, a phenomenon noted by @Horn1991:Duplex and similar to that observed in speaker production data in recent investigations of politeness [@Yoon2017].

<!-- ### Discussion -->
<!-- Consistent with the intuition from all but George Orwell, the negated (morphological) antonyms were interpreted as slightly positive, though less-so that purely postive statements. -->
<!-- This interpretation is predicted by the *bonafide antonyms* model and the *uncertain parser* model.  -->
<!-- \text{Expt.$\thinspace$1} further confirmed our hypothesized asymmetry between lexical and morphological antonyms.  -->
<!-- In particular, interpretations of morphological antonyms were indistinguishable from those of negated positive statements, consistent with the intuition of @Jespersen1917:Negation and @Blutner2004:pragmatics as well as our *uncertain parser* model.  -->
<!-- Lexical antonyms, on the other hand, showed a clear ordering: ANT $<$ NEG POS $<$ NEG ANT $<$ POS.  -->


<!-- Differences in meaning between negated positives and morphological antonyms (e.g., *not happy* and *unhappy*) were not found.  -->
<!-- However, differences in meaning have been noted in such naturalistic examples as  -->
<!-- Here is an instance of an attested difference in meaning between negated positives and morphological antonyms (e.g., *not happy* and *unhappy*), taken from @Krifka2007:Negated-antonyms, taken from internet: -->
<!-- \begin{quote} -->
<!-- \footnotesize -->
<!-- It's an absolutely horrible feeling to be unhappy, and I don't even think I was unhappy, just not happy, if you know what I mean.  -->
<!-- \end{quote} -->

<!-- \noindent We did not find such a difference in our experiment, but rather than conclude that no differnce exists, we note that the speaker in this example utterance chose to use both *unhappy* and *not happy* in the same utterance.  -->
<!-- We hypothesize that explicit comparisons between alternative utterances can draw out the difference in meaning between negated positives and morphological antonyms, which leads the morphological antonym to behave more like a bonafide antonym. -->


## Experiment 2: Within-item replication

<!-- \text{Expts$\thinspace$1 \& 2} revealed an asymmetry between opposites with overt negation markers (*affixal antonyms* e.g., "unhappy") and those with (*negative adjectives* e.g., "short"). -->
\text{Expt$\thinspace$1} revealed an asymmetry: lexical antonyms (e.g., *short*) are clearly distinguished from negated positives (e.g., *not tall*), whereas morphological antonyms (e.g., *not unhappy*) were not markedly different from negated positives (e.g., *not happy*).
<!-- , unless a speaker used multiple distinct alternatives in the same context (Expt.$\thinspace$2).  -->
In this experiment, we aim to replicate these findings while controlling for the semantic scale under consideration. 
<!-- Specifically, in \text{Expts.$\thinspace$1~\&~2}, our adjective sets varied both in terms of their opposites (negatives vs.\text{~}antonyms) as well as the actual degree scales being described (e.g., height for *tall*/*short* vs.\text{~}happiness for *happy*/*unhappy*). -->
Specifically, in \text{Expt.$\thinspace$1}, our adjective sets varied both in terms of their antonyms (morphological vs.\text{~}lexical) as well as the actual degree scales being described (e.g., height for *tall*/*short* vs.\text{~}happiness for *happy*/*unhappy*).
Many adjective sets have both negatives and antonyms (e.g., *happy*/*unhappy*/*sad*) and we use these sets to test our hypothesis within-scale. 
In addition, we test the prediction of hearing multiple utterances in the same context, which is hypothesized to produce the full ordering in morphological antonym sets (Fig.$\thinspace$\ref{fig:modelPredictions}).

<!-- ## Methods -->

```{r expt3_subjInfo}
load("cached_results/time_summary.RData") # d.time.summary
load("cached_results/english_summary.RData") #d.full.nativeEnglish
```

### Participants

We recruited 750 participants from MTurk.
The experiment comprised of four between-subjects experimental conditions arranged in a 2x2 Latin Square design: *antonym type (morphological vs.\text{~}lexical)* X *context (multiple utterances vs.\text{~}single utterances)*.
300 participants were assigned to each of the *single utterances* conditions, and 75 participants were assigned to each of the *multiple utterances* conditions.
These numbers follow from the intention of getting approximately 45 ratings for each unique adjective in the experiment.

The *single utterances* task took on average `r round(filter(d.time.summary, condition == "implicit")[[1,"aveTime"]], 1)` minutes and participants were compensated \$0.40; the *multiple utterances* task took on average `r round(filter(d.time.summary, condition == "explicit")[[1,"aveTime"]], 1)` minutes and participants were compensated \$0.80.
As before, participants who self-reported a native language other than English were excluded.
This exclusion criterion and our planned sample size, along with the procedure and analysis described below, were preregistered: \url{osf.io/p7f25/}.

### Materials

<!-- Our pilot testing revealed differences between lexical and morphological antonym sets (e.g., "tall"/"short" and "happy"/"unhappy"). -->

To best isolate the contribution of morphological vs.\text{~}lexical antonyms, we curated *adjective sets* consisting of words for properties of people, such that both types of antonyms existed for the same positive adjective (e.g., *happy* $\rightarrow$ *unhappy*, *sad*; \text{Table$\thinspace$3}).
Lexical antonyms were selected from a set of possibilities produced from a small survey (n=18) on MTurk eliciting "opposites" for a list of 30 positive-form adjectives which had morphological antonyms (asking participants in the same experimental context as our interpretation studies, "What is the opposite of e.g., *forgiving*?").
From the list of freely-produced opposites (the vast majority of which were not morphological), the first author chose the one that intuitively best conveyed the same scalar dimension as the morphological antonym and which was not already used as a lexical antonym for another item (e.g., opposite of *forgiving* $\rightarrow$ *resentful*; opposite of *kind* $\rightarrow$ *cruel*, because opposite of *friendly* $\rightarrow$ *mean*).
Ten out of the original 30 items were dropped for either not having such a well-suited lexical antonym (e.g., *moral*) or for having a well-suited lexical antonym that conflicted with another item (e.g., *compassionate* $\rightarrow$ *cold*, but also *affectionate* $\rightarrow$ *cold*).

<!-- For a list of the 20 positive-adjectives and their lexical and morphological antonyms used in the experiment, see Table \@ref(tab:items). -->

<!-- We used **adjective sets** of size 6 composed of positive-form gradable adjectives (\textsc{POS}; e.g., *happy*), their negation (\textsc{NEG POS}; e.g., *not happy*), antonyms constructed by altering the morphology of the adjective (\textsc{MORPH ANT}; e.g., *unhappy*), anotnyms with a distinct lexical entry (\textsc{LEX ANT}; e.g., *sad*) and their respective negations (e.g., *not unhappy*, *not sad*). -->
<!-- Antonyms were either created by morphological negation (\emph{morphological antonyms}; e.g., *unhappy* for *happy*) or were distinct lexical entries (\emph{lexical antonyms}; e.g., *short*, for *tall*). -->
<!-- All adjectives were individual-level predicates that applied to people; items were constructed from an informal survey of the linguistics literature and taken from list of *common opposites* available online\footnote{http://www.enchantedlearning.com/wordlist/opposites.shtml} (for a full list, see \tableref{tab:items}. -->


```{r items, results="asis"}
load(file = "cached_results/item_table.RData")
print(tab1, type="latex", comment = F, table.placement = "h", size="\\fontsize{9pt}{10pt}\\selectfont", include.rownames=FALSE)
```



```{r expt1results}
load("cached_results/oneSlider_bootstrappedCIs.RData") # df.oneSlider.ci

# fig.expt1 <- ggplot(df.oneSlider.ci %>%
#                       mutate(src = 'implicit'), aes(x = antonym_type,
#                       y = mean,
#                        ymin = ci_lower, ymax = ci_upper,
#                        fill = adjective_type,
#                       group = adjective_type
#               ))+
#   geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
#   geom_errorbar(position = position_dodge(0.8), color = 'black',
#                 width = 0.4)+
#   #coord_flip()+
#   facet_wrap(~src)+
#   xlab("")+
#   #scale_fill_viridis(discrete = T, name="Adjective type")+
#   scale_fill_manual(name="Adjective type",
#                     values = orange.purple.color.palette,
#                     guide = guide_legend(reverse=TRUE))+
#   ylab("mean normalized rating")+
#   theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ))+
#   scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))

# fig.expt1 <- df.oneSlider.ci %>%
#   ungroup() %>%
#   mutate(
#     new_type = ifelse(antonym_type == "lexical", 
#                            ifelse(adjective_type == "Antonym", "Negative", 
#                             ifelse(adjective_type == "Negated antonym", "Negated negative", 
#                                    as.character(adjective_type))), as.character(adjective_type)),
#     antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
#                           labels = c("negative", "antonym")),
#     src = 'implicit'
#       ) %>%
#   ggplot(., aes(x = antonym_type,
#                       y = mean,
#                        ymin = ci_lower, ymax = ci_upper,
#                        fill = new_type,
#                       group = adjective_type
#               ))+
#   geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
#   geom_errorbar(position = position_dodge(0.8), color = 'black',
#                 width = 0.4)+
#   #coord_flip()+
#   facet_wrap(~src)+
#   xlab("")+
#   #scale_fill_viridis(discrete = T, name="Adjective type")+
#   scale_fill_manual(name="Adjective type",
#                     values = orange.purple.blue.color.palette,
#                     guide = guide_legend(reverse=F),
#                     breaks = c("Negative", "Negated negative", 
#                                "Antonym", "Negated antonym", 
#                                "Positive", "Negated positive"))+
#   ylab("mean normalized rating")+
#   theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ),
#         legend.position = 'bottom')+
#   scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))

fig.expt1 <- df.oneSlider.ci %>%
  ungroup() %>%
  mutate(
    new_type = ifelse(antonym_type == "lexical", 
                           ifelse(adjective_type == "Antonym", "Negative", 
                            ifelse(adjective_type == "Negated antonym", "Negated negative", 
                                   as.character(adjective_type))), as.character(adjective_type)),
    antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
                          labels = c("negative", "antonym")),
    src = 'implicit'
      ) %>%
  ggplot(., aes(x = 0,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       color = new_type,
                      group = antonym_type
              ))+
    xlab("")+
    coord_flip()+
    geom_linerange(position = position_jitterdodge(dodge.width = 0.3,
      jitter.height = 0,
      jitter.width = 0), size = 10, alpha = 1)+
    geom_vline(xintercept =  -(0.3/4),  size = 5, alpha = 0.1, color = 'darkgreen')+
    geom_vline(xintercept =  0.3/4,  size = 5, alpha = 0.1) +
    geom_text(x = -(0.3/4) + 0.05, y = 0.1, label = 'lexical antonyms', color = 'darkgreen', size = 2.5)+
    geom_text(x = (0.3/4) + 0.05, y = 0.1, label = 'morphological antonyms', color = 'black', alpha = 0.6, size = 2.5)+
    geom_text(x = -(0.3/4) - 0.07, y = 0.75, label = 'single utterance', color = 'black', alpha = 0.8, size = 3)+
    scale_color_manual(name="Adjective type",
                    values = orange.purple.blue.color.palette,
                    guide = guide_legend(reverse=F),
                    breaks = c("Negative", "Negated negative", 
                               "Antonym", "Negated antonym", 
                               "Positive", "Negated positive"))+
    ylab("mean normalized rating")+
    scale_y_continuous(limits = c(-1.1,1.3), breaks = c(-1, 0, 1))+
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

```

```{r expt2results, eval = F}
load("cached_results/fourSlider_bootstrappedCIs.RData") # df.fourSlider.ci
fig.expt2 <- ggplot(df.fourSlider.ci %>%
                      mutate(src = 'explicit',
                             new_type = ifelse(antonym_type == "lexical", 
                           ifelse(adjective_type == "Antonym", "Negative", 
                            ifelse(adjective_type == "Negated Antonym", "Negated negative", 
                                   as.character(adjective_type))), as.character(adjective_type)),
                               antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
                          labels = c("negative", "antonym"))), aes(x = antonym_type,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type,
                      group = adjective_type
              ))+
  geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
  geom_errorbar(position = position_dodge(0.8), color = 'black',
                width = 0.4)+
  #coord_flip()+
  xlab("Antonym type")+
  facet_wrap(~src)+
  xlab("")+
  #scale_fill_viridis(discrete = T, name="Adjective type")+
  scale_fill_manual(name="Adjective type",
                    values = orange.purple.blue.color.palette,
                    guide = guide_legend(reverse=TRUE)
                    )+
  ylab("mean normalized rating")+
    theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ))+
  scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))
```

```{r expt-results, fig.cap="Empirical ratings for adjective sets with morphological antonyms opposites (e.g., \"sad\") and antonyms (e.g., \"unhappy\"). A-B: Expts. 1, 2, respectively; participants rated all adjective types for both negative and antonym opposites. C: Four between-participants conditions. Left end-points of rating scales were defined by the opposite type (negative vs. antonym).", fig.env = "figure*", fig.pos = "h", fig.width=7, fig.height=3, fig.align = "center", set.cap.width=T, num.cols.cap=2}

load(file = "cached_results/bootstrappedCIs.RData") # d.full.boot

# fig.bs.ci <- d.full.boot %>%
#   ungroup() %>%
#   mutate(antonym_type = factor(antonym_type, 
#                                levels = c(  "lexant", "morphant"),
#                                labels = c("lexical", "morphological")),
#          adjective_type_rescaled = 
#            factor(adjective_type_rescaled,
#               levels = c("antonym", "neg_positive", "neg_antonym","positive"),
#               labels = c("Antonym", "Negated positive",
#                          "Negated antonym", "Positive")),
#          new_type = ifelse(antonym_type == "lexical", 
#                            ifelse(adjective_type_rescaled == "Antonym", "Negative", 
#                             ifelse(adjective_type_rescaled == "Negated antonym", "Negated negative", 
#                                    as.character(adjective_type_rescaled))), as.character(adjective_type_rescaled)),
#              antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
#                           labels = c("negative", "antonym"))) %>%
#   ggplot(., aes(x = antonym_type,
#                       y = mean,
#                        ymin = ci_lower, ymax = ci_upper,
#                        fill = new_type,
#                       group = adjective_type_rescaled
#               ))+
#   geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
#   geom_errorbar(position = position_dodge(0.8), color = 'black',
#                 width = 0.4)+
#   #coord_flip()+
#   xlab("Antonym type")+
#   #scale_fill_viridis(discrete = T, name="Adjective type")+
#   scale_fill_manual(name="Adjective type",
#                     values = orange.purple.blue.color.palette,
#                     guide = guide_legend(reverse=F),
#                     breaks = c("Negative", "Negated negative", 
#                                "Antonym", "Negated antonym", 
#                                "Positive", "Negated positive"))+
#   facet_wrap(~condition, scales = 'free', nrow = 1)+
#   ylab("mean normalized rating")+
#   xlab("")+
#     theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ))+
#   #scale_y_reverse(limits = c(1.25, -1.1), breaks = c(1, 0, -1))
#   scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))

# 
# fig.bs.ci <- d.full.boot %>%
#   ungroup() %>%
#   mutate(antonym_type = factor(antonym_type, 
#                                levels = c(  "lexant", "morphant"),
#                                labels = c("lexical", "morphological")),
#          adjective_type_rescaled = 
#            factor(adjective_type_rescaled,
#               levels = c("antonym", "neg_positive", "neg_antonym","positive"),
#               labels = c("Antonym", "Negated positive",
#                          "Negated antonym", "Positive")),
#          new_type = ifelse(antonym_type == "lexical", 
#                            ifelse(adjective_type_rescaled == "Antonym", "Negative", 
#                             ifelse(adjective_type_rescaled == "Negated antonym", "Negated negative", 
#                                    as.character(adjective_type_rescaled))), as.character(adjective_type_rescaled)),
#              antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
#                           labels = c("negative", "antonym")),
#          condition = factor(condition, levels = c("explicit", "implicit"),
#                             labels=c("multiple utterances", "single utterance"))) %>%
#   
#   ggplot(., aes( x = condition, y = mean, ymin = ci_lower, 
#     ymax = ci_upper, color = new_type, group = antonym_type ))+
#     xlab("")+
#     coord_flip()+
#     geom_linerange(position = position_jitterdodge(dodge.width = 0.75,
#                                     jitter.height = 0,
#                                     jitter.width = 0), size = 10, alpha = 1)+
#   
#     geom_vline(xintercept = 0.81,  size = 5, alpha = 0.1, color = 'darkgreen')+
#     geom_vline(xintercept = 1.19,  size = 5, alpha = 0.1) +
#     geom_vline(xintercept = 1.81,  size = 5, alpha = 0.1, color = 'darkgreen')+
#     geom_vline(xintercept = 2.19,  size = 5, alpha = 0.1) +
#     geom_text(x = 2.0, y = 1.17, label = 'lexical antonyms', color = 'darkgreen', size = 2.5)+
#     geom_text(x = 2.4, y = 1.07, label = 'morphological antonyms', color = 'black', alpha = 0.6, size = 2.5)+
#     geom_text(x = 2.45, y = 0.1, label = 'single utterance condition', color = 'black', size = 3)+
#     geom_text(x = 1.45, y = 0.1, label = 'multiple utterances condition', color = 'black', size = 3)+
#     scale_color_manual(name="Adjective type",
#                     values = orange.purple.blue.color.palette,
#                     guide = guide_legend(reverse=F),
#                     breaks = c("Negative", "Negated negative", 
#                                "Antonym", "Negated antonym", 
#                                "Positive", "Negated positive"))+
#     ylab("mean normalized rating")+
#     scale_y_continuous(limits = c(-1.1,1.3), breaks = c(-1, 0, 1))+
#     theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())


fig.expt2.single <- d.full.boot %>%
  ungroup() %>%
  mutate(antonym_type = factor(antonym_type, 
                               levels = c(  "lexant", "morphant"),
                               labels = c("lexical", "morphological")),
         adjective_type_rescaled = 
           factor(adjective_type_rescaled,
              levels = c("antonym", "neg_positive", "neg_antonym","positive"),
              labels = c("Antonym", "Negated positive",
                         "Negated antonym", "Positive")),
         new_type = ifelse(antonym_type == "lexical", 
                           ifelse(adjective_type_rescaled == "Antonym", "Negative", 
                            ifelse(adjective_type_rescaled == "Negated antonym", "Negated negative", 
                                   as.character(adjective_type_rescaled))), as.character(adjective_type_rescaled)),
             antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
                          labels = c("negative", "antonym")),
         condition = factor(condition, levels = c("explicit", "implicit"),
                            labels=c("multiple utterances", "single utterance"))) %>%
  filter(condition == "single utterance") %>%
  ggplot(., aes(x = 0,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       color = new_type,
                      group = antonym_type
              ))+
    xlab("")+
    coord_flip()+
    geom_linerange(position = position_jitterdodge(dodge.width = 0.3,
      jitter.height = 0,
      jitter.width = 0), size = 10, alpha = 1)+
    geom_vline(xintercept =  -(0.3/4),  size = 5, alpha = 0.1, color = 'darkgreen')+
    geom_vline(xintercept =  0.3/4,  size = 5, alpha = 0.1) +
    geom_text(x = -(0.3/4) + 0.05, y = 0.1, label = 'lexical antonyms', color = 'darkgreen', size = 2.5)+
    geom_text(x = (0.3/4) + 0.05, y = 0.1, label = 'morphological antonyms', color = 'black', alpha = 0.6, size = 2.5)+
    geom_text(x = -(0.3/4) - 0.07, y = 0.75, label = 'single utterance', color = 'black', alpha = 0.8, size = 3)+
    scale_color_manual(name="Adjective type",
                    values = orange.purple.blue.color.palette,
                    guide = guide_legend(reverse=F),
                    breaks = c("Negative", "Negated negative", 
                               "Antonym", "Negated antonym", 
                               "Positive", "Negated positive"))+
    ylab("mean normalized rating")+
    scale_y_continuous(limits = c(-1.1,1.3), breaks = c(-1, 0, 1))+
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

fig.expt2.multiple <- d.full.boot %>%
  ungroup() %>%
  mutate(antonym_type = factor(antonym_type, 
                               levels = c(  "lexant", "morphant"),
                               labels = c("lexical", "morphological")),
         adjective_type_rescaled = 
           factor(adjective_type_rescaled,
              levels = c("antonym", "neg_positive", "neg_antonym","positive"),
              labels = c("Antonym", "Negated positive",
                         "Negated antonym", "Positive")),
         new_type = ifelse(antonym_type == "lexical", 
                           ifelse(adjective_type_rescaled == "Antonym", "Lexical antonym", 
                            ifelse(adjective_type_rescaled == "Negated antonym", "Negated lexical antonym", 
                                   as.character(adjective_type_rescaled))), as.character(adjective_type_rescaled)),
           new_type = ifelse(antonym_type == "morphological", 
                           ifelse(adjective_type_rescaled == "Antonym", "Morphological antonym", 
                            ifelse(adjective_type_rescaled == "Negated antonym", "Negated morphological antonym", 
                                   as.character(adjective_type_rescaled))), as.character(adjective_type_rescaled)),
             antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
                          labels = c("negative", "antonym")),
         condition = factor(condition, levels = c("explicit", "implicit"),
                            labels=c("multiple utterances", "single utterance"))) %>%
  filter(condition == "multiple utterances") %>%
  ggplot(., aes(x = 0,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       color = new_type,
                      group = antonym_type
              ))+
    xlab("")+
    coord_flip()+
    geom_linerange(position = position_jitterdodge(dodge.width = 0.3,
      jitter.height = 0,
      jitter.width = 0), size = 10, alpha = 1)+
    geom_vline(xintercept =  -(0.3/4),  size = 5, alpha = 0.1, color = 'darkgreen')+
    geom_vline(xintercept =  0.3/4,  size = 5, alpha = 0.1) +
    geom_text(x = -(0.3/4) + 0.05, y = 0.1, label = 'lexical antonyms', color = 'darkgreen', size = 2.5)+
    geom_text(x = (0.3/4) + 0.05, y = 0.1, label = 'morphological antonyms', color = 'black', alpha = 0.6, size = 2.5)+
    geom_text(x = -(0.3/4) - 0.07, y = 0.7, label = 'multiple utterances', color = 'black', alpha = 0.8, size = 3)+
    scale_color_manual(name="Adjective type",
                    values = orange.purple.blue.color.palette,
                    guide = guide_legend(reverse=F),
                    breaks = c("Lexical antonym", "Negated lexical antonym", 
                               "Morphological antonym", "Negated morphological antonym", 
                               "Positive", "Negated positive"))+
    ylab("mean normalized rating")+
    scale_y_continuous(limits = c(-1.1,1.3), breaks = c(-1, 0, 1))+
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())


legend <- get_legend(fig.expt2.multiple + 
                       theme(legend.position="bottom", legend.margin=margin(0,0,0,0), legend.box.margin=margin(0,0,0,0),
                             legend.direction = "horizontal",
                             legend.key.size = unit(0.0005, "cm"),
                             #legend.title = element_text(size = 4),
                             legend.text = element_text(size = 8)
                             ))


prow <- plot_grid(
  fig.expt1 + theme(legend.position="none",
                                     plot.margin = unit(c(6,0,6,6), "pt"),
                    axis.title.x = element_blank()),
   fig.expt2.single + theme(legend.position="none",
                     plot.margin = unit(c(6,0,6,6), "pt")),
   fig.expt2.multiple + theme(legend.position="none",
                     plot.margin = unit(c(6,0,6,6), "pt"),
                     axis.title.x = element_blank()),
           align = 'vh',
           labels = c("A", "B", "C"),
           hjust = -1,
           nrow = 1, rel_widths = c(1,1,1)
           )



# prow <- plot_grid(
#   fig.expt1 + theme(legend.position="none",
#                                      plot.margin = unit(c(6,0,6,0), "pt")),
#    # fig.expt2 + theme(legend.position="none",
#    #                   plot.margin = unit(c(6,0,6,0), "pt")) + ylab(""),
#    fig.bs.ci + theme(legend.position="none",
#                      plot.margin = unit(c(6,0,6,0), "pt")) + ylab(""),
#            align = 'vh',
#            labels = c("A", "B", "C"),
#            hjust = -1,
#            nrow = 1, rel_widths = c(1,2)
#            )

plot_grid( prow, legend, ncol = 1, rel_heights = c(1, .25))

#prow
#fig.bs.ci
```





### Procedure

<!-- Participants rated adjective sets made with either lexical or morphological antonyms. -->
<!-- In addition, participants provided ratings with alternative utterances either explicit or implicit.  -->

<!-- On each trial, participants read a statement introducing a character using a gradable adjective of one of four **adjective types** (e.g., "Greg is \{POS, ANT, NEG POS, NEG ANT\}"). -->
<!-- Participants were asked rate the character on a scale from "the most POS person in the world" to "the most ANT person in the world", using a slider bar (\figref{fig:expt1}). -->
<!-- In the *lexical antonyms* conditions, ANT (and NEG ANT) were antonyms with distinct lexical entries (e.g., "sad", "not sad" for POS = "happy"). -->
<!-- In the *morphological antonyms* conditions, ANT (and NEG ANT) were antonyms created by adding a negation-inducing prefix (e.g., "unhappy", "not unhappy" for POS = "happy"). -->

In the *multiple utterances* conditions, participants rated all four adjective types simultaneously, each referring to a different person (\figref{fig:experiment-slides}B); there were a total of 12 trials.
The *single utterances* conditions were similar to that \text{Expts.$\thinspace$1}: Participants rated one sentence at a time (e.g., *Greg is not unhappy*), each from a unique adjective set (e.g., never rated both *unhappy* and *not happy*), completing a total of 12 trials, with exactly 3 repetitions of each adjective type (\textsc{positive}, \textsc{antonym}, and their negations).
In contrast to the first experiment, *antonym type* (morphological vs.\text{~}lexical) was a between-participants factor.
In addition, the slider bar endpoints were relabeled to "the most \{\textsc{positive}, \textsc{negative}\} person *in the world*"; without "in the world", there is a salient interpretation in the multiple utterances conditions of the endpoints indicating  "the most \{\textsc{positive}, \textsc{antonym}\} person (of these four)".

<!-- The procedure was similar to that of \text{Expts.$\thinspace$1~\&~2}. -->
<!-- In the *implicit alternatives* conditions, participants rated one sentence at a time (e.g., *Greg is not unhappy*), each from a unique adjective set (e.g., never rated both *unhappy* and *not happy*) *a la* \text{Expt.$\thinspace$1}, completing a total of 12 trials, with exactly 3 repetitions of each adjective type (\textsc{positive}, \textsc{opposite}, and their negations). -->

<!-- Again, there were 12 trials. -->

### Results 

```{r loadRegressionResults}
# regression 1: opposite vs. negated positive X opposite type (implicit only)
load("cached_results/regression_antTypeXadjType_implicitCond.RData") # rs1.helmert.implicit.summary
## simple effects
load("cached_results/regression_simple_adjType_morph_implicit.RData") #rs1.simple.morph.implicit.summary
load("cached_results/regression_simple_adjType_lex_implicit.RData") #rs1.simple.lex.implicit.summary

load("cached_results/regression_adjTypeXcontext_morph.RData") #rs2.helmert.morph.summary
load("cached_results/regression_antTypeXadjTypeXcontext.RData") # rs3.3way.summary

rs1.implicit.coef <- rs1.helmert.implicit.summary[["coefficients"]]
rs1.implicit.simple.morph.coef <- rs1.simple.morph.implicit.summary[["coefficients"]]
rs1.implicit.simple.lex.coef <- rs1.simple.lex.implicit.summary[["coefficients"]]
rs2.morph.coef <- rs2.helmert.morph.summary[["coefficients"]]
rs3.3way.coef <- rs3.3way.summary[["coefficients"]]
```

`r sum(!d.full.nativeEnglish$englishNative)` participants were excluded for self-reporting a native language other than English, leaving a remainder of `r sum(d.full.nativeEnglish$englishNative)` participants for these analyses.
The mean normalized responses for each adjective type in each condition are shown in Figure \ref{fig:expt-results}C. 
<!-- The patterns visually mirror those of the first two experiments. -->

As we did in \text{Expt.$\thinspace$1}, we evaluate our hypothesis that morphological antonyms behave like the *uncertain negation* model (i.e., show a partial ordering) while lexical antonyms behave like *bonafide contraries* (i.e., show a true ordering). 
To do so, we considered data only from the *single utterances* conditions and built a linear mixed model predicting the raw, unnormalized ratings in terms of fixed effects of *antonym type* (morphological vs. lexical), *adjective type* (Helmert coded in order: antonym, negated positive, negated antonym, positive
<!-- ^[ -->
<!--  We coded adjective type using Helmert coding, which compares levels of a factor to the average of preceding levels, in order to compare *opposite* vs. *negated positive* levels of the adjective type factor. -->
<!-- ]),  -->
and their interaction; the model also included random intercepts and random slopes of *adjective type* by-participant and by-item.
Consistent with our hypothesis, the interaction between the *antonym* vs. *negated positive* levels of adjective type and antonym type (morphological vs.\text{~}lexical) was significant: $\beta = `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","Estimate"],3)`$, $SE =  `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","Std. Error"],4)`$, t$(`r round(rs1.implicit.coef["antonym_typelexant:adj_type1","df"], 1)`) = `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","t value"],2)`, p = `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","Pr(>|t|)"], 4)`$. 
We then analyzed the simple effects.
Morphological antonyms were not significantly different than *negated positives* $\beta = `r format(rs1.implicit.simple.morph.coef["adj_type1","Estimate"], digits = 2, scientific = T)`$, $SE =  `r round(rs1.implicit.simple.morph.coef["adj_type1","Std. Error"],4)`$, t$(`r round(rs1.implicit.simple.morph.coef["adj_type1","df"], 1)`) = `r round(rs1.implicit.simple.morph.coef["adj_type1","t value"],2)`, p = `r round(rs1.implicit.simple.morph.coef["adj_type1","Pr(>|t|)"], 2)`$, lexical antonyms were significantly more negative than *negated positives* $\beta = `r -1*round(rs1.implicit.simple.lex.coef["adj_type1","Estimate"],3)`$, $SE =  `r round(rs1.implicit.simple.lex.coef["adj_type1","Std. Error"],4)`$, t$(`r round(rs1.implicit.simple.lex.coef["adj_type1","df"], 1)`) = `r round(rs1.implicit.simple.lex.coef["adj_type1","t value"],2)`, p = `r round(rs1.implicit.simple.lex.coef["adj_type1","Pr(>|t|)"], 4)`$.^[
  The random effect structure for the simple effects models mirrored the full model. The only difference was that in analyzing the lexical antonyms, the random effect of adjective type by-item needed to be dropped in order for the model to converge.
] 

<!-- One first hypothesis concerns the interpretation of morphological antonyms vs.\text{~}lexical antonyms in the absence of explicit alternatives (Figure$\thinspace$\ref{fig:experiment-slides}A). -->
<!-- We predict an interaction between type of negation (antonym vs.\text{~}negated positive) and type of antonym (morphological vs.\text{~}lexical). -->
<!-- Specifically, we predict that interpretations of lexical antonyms will be more negative than negated positives (e.g., somebody who is "sad" is less happy than someone who is "not happy"), whereas there will be no difference between morphological antonyms and negated positives (e.g., "unhappy" = "not happy"). -->


Our second main hypothesis is that context (single vs.\text{~}multiple utterances) modulates the interpretive difference between morphological antonyms and negated positives. 
Specifically, we predict that morphological antonyms will be interpreted more negatively than negated positives in a context with multiple  utterances; this effect would manifest as an interaction between adjective type (specifically, levels: antonym vs.\text{~}negated positive) and context.
To evaluate this hypothesis, we considered data only from the morphological antonyms conditions and built a linear mixed model predicting the raw, unnormalized ratings in terms of fixed effects of adjective type (Helmert coded in order: antonym, negated positive, negated antonym, positive), context (single vs. multiple utterances) and their interaction; the model also included random intercepts and random slopes of adjective type by-participant and by-item.
This interaction was also significant: $\beta = `r round(rs2.morph.coef["conditionexplicit:adj_type1","Estimate"],3)`$, $SE =  `r round(rs2.morph.coef["conditionexplicit:adj_type1","Std. Error"],4)`$, t$(`r round(rs2.morph.coef["conditionexplicit:adj_type1","df"], 1)`) = `r round(rs2.morph.coef["conditionexplicit:adj_type1","t value"],2)`, p = `r format(rs2.morph.coef["conditionexplicit:adj_type1","Pr(>|t|)"], digits = 3, scientific = T)`$, and in the correct direction (see Fig.\text{~}\ref{fig:expt-results}C).

Finally, as an exploratory analysis we test the 3-way interaction between adjective type (specically, levels: antonym vs.\text{~}negated positive), antonym type (morphological vs.\text{~}lexical), and context (single vs.\text{~}multiple utterances), using a mixed-effects model with by-participant and by-item random effects of intercept and adjective type.
The 3-way interaction was not significant and numerically in the direction of the multiple utterances context making the difference between antonyms and negated positives more pronounced with lexical antonyms than for morphological antonyms:
$\beta = `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","Estimate"],3)`$, $SE =  `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","Std. Error"],4)`$, t$(`r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","df"], 1)`) = `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","t value"],2)`, p = `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","Pr(>|t|)"], 4)`$

# Discussion

Many dimensional scales have no units.
Speakers cannot say they are *42 units happy* like they can say they are *6'1" tall*.
Instead, speakers can modifiers and alternative utterances to carve more precise meanings from otherwise vague dimensions. 
Someone said to be *not unhappy* is neither sad nor truly happy, but residing in some marginally positive state that is difficult to refer to because degrees of happiness lack precise units.

This work resolves an outstanding puzzle in natural language understanding.
@Krifka2007:Negated-antonyms critiques previous pragmatic theories for either being underdetermined [@Blutner2004:pragmatics] or making the wrong prediction [@Horn1991:Duplex]. 
Using state-of-the-art models of pragmatic language understanding, we are able to precisely articulate the division of pragmatic labor between different utterances available to a speaker for conveying negation.
We hypothesized that uncertainty about the meaning of overt negation markers leads only to a partial ordering of affixal antonyms and their negations (e.g,. *not unhappy* $\approx$ *not happy*). 
It is noteworthy that we are able to recover, both in our model and empirically, the ordering predicted by @Krifka2007:Negated-antonyms for morphological antonyms (e.g., *unhappy*) when the listener hears multiple adjectival utterances in the same context (multiple utterances condition).
<!-- \mht{note also that we don't assume any ordering on interpretations in the semantics for bonafide antonyms. note null utterance? \mf{maybe footnote if we have the space?}} -->

Our formalization of lexical uncertainty about the meaning of natural language negation builds on a growing movement to treat the lexicon as not totally separable from the combinatorial rules of grammar [e.g., @bybee2006usage; @Odonnell2015productivity].
Recent psycholinguistic evidence supports the idea that utterances which are heavily used will be processed as unique lexical entries while less frequent phrases will be understood compositionally [@MorganLevy2016:binomials]. 
The two types of negation meaning we considered---contrary and contradiction opposition---can be seen as a *lexicalized* form of opposition (with the adjective receiving its own threshold variable) and a *compositional* rule (logical negation), respectively. 
In our modeling, we assumed all lexica (all logically-possible interpretations of negation) were equally likely: A further test of our negation uncertainty model would be to see if frequency can serve as a proxy for this prior over lexica on a by-item basis.

To negate is to make true false, but for statements that are truly vague, the behavior of negation is not so obvious. 
We present an explanation for why this is so, and provide empirical data that sheds new light on the age old question of meaning and opposition.

\mht{add limitations on generality: adjectives all about people}

\mht{discuss languages with "negative concord" (double negations acting as an intensifier)}

\mht{discuss the generality of negation across languages?}

\mht{need to explain what breaks the symmetry in the model}
<!-- \mht{politeness, further inferences? (not unhappy -- *normally unhappy in this situation*)} -->
  
# Acknowledgements

This work was supported in part by NSF Graduate Research Fellowship DGE-114747 to MHT.


<!-- Should we parse both types of negation compositionally, then indeed they have same meanings. However, language has the ability to create new lexical entries, with the tokenization of new semantic variables. For instance, \*not tall\* does not imply \"short\" because tall and short have different truth-conditional criteria. -->
    



<!-- To negate is to make true false, but what of statements that are truly vague? When meanings are underspecified, the behavior of negation is not so obvious. If a person is \"not happy\", does that entail they are \"unhappy\"? Natural language provides two kinds of negation: contrary (e.g., not happy) and contradiction (e.g., sad), yet additional forms exist (e.g., unhappy). Are the additional forms redundant, or do they allow speakers, with the help of context, to more finely carve otherwise vague meanings? We investigate basic inferences from natural language negation and double negation by elaborating a computational model of gradable adjective interpretation to handle different kinds of negation. We hypothesize that communicative reasoning and an uncertain *parsing model* combine for listeners to extract fine-grained meanings within vague dimensions. This hypothesis is borne out in, to our knowledge, the first experimental evidence concerning adult interpretation of different kinds of and double negation. -->


# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
