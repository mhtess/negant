---
title: "Not unreasonable: Carving vague dimensions with contraries and contradictions"
bibliography: negant.bib
csl: apa6.csl
document-params: "10pt, letterpaper"
header-includes:
  - \usepackage{tabularx}
  - \usepackage{multicol}
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \usepackage{booktabs}
  
author-information: > 
  \author{{\large \bf Michael Henry Tessler (mhtessler@stanford.edu)} \\ Department of Psychology, Stanford University 
  \AND {\large \bf Michael Franke (mchfranke@gmail.com)} \\ Department of Linguistics, University of T\"{u}bingen}

abstract: 
    "Formal logic provides two kinds of opposing meanings: contradictories, often expressed linguistically in particle negation (e.g., \"not happy\"), and contraries expressed as antonyms (e.g., \"sad\"), yet these are not the only options available to a speaker (e.g., \"unhappy\"). Rather than being redundant, we hypothesize that uncertainty about the intended *parse* of the message creates more precise meanings in context. We formalize this hypothesis in a probabilistic model of gradable adjectives (e.g., \"happy\"), and derive, as a special case, an ordering of unambiguous antonyms and their negations (\"sad\" $<$ \"not happy\" $<$ \"not sad\" $<$ \"happy\"). However, when there is uncertainty about how to parse a hypothetical antonym (e.g., \"unhappy\"), we predict interpretations should not be different from pure negations (e.g., \"not happy\"). Across two behavioral experiments and a preregistered replication, we confirm consistent orderings of interpretations that interacts with contexct. This promising support for our hypothesis suggests that in-the-moment pragmatic reasoning can off-load from grammar...something...something. "

keywords:
    "semantics; pragmatics; negation; Rational Speech Act; Bayesian cognitive model"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(cowplot)
library(tidyr)
library(dplyr)
library(magick)
library(ggthemes)
library(formatR)
library(bitops)
library(caTools)
#library(viridis)
theme_set(theme_few())
orange.purple.color.palette <- 
  #c("#fdb863", "#5e3c99", "#e66101", "#b2abd2")
  c( "#b2abd2", "#e66101", "#5e3c99","#fdb863")
orange.purple.blue.color.palette <- 
  #c("#fdb863", "#5e3c99", "#e66101", "#b2abd2")
  c("#74a9cf", "#0570b0","#5e3c99",  "#e66101", "#b2abd2","#fdb863")
```

\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}
\newcommand{\tableref}[1]{Table$\thinspace$\ref{#1}}
\newcommand{\figref}[1]{Figure$\thinspace$\ref{#1}}
\newcommand{\appref}[1]{Appendix \ref{#1}}
\newcommand{\sectionref}[1]{Section \ref{#1}}
\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}
\definecolor{grey}{RGB}{40,40,40}

\newcommand{\red}[1]{\textcolor{Red}{#1}}  
\newcommand{\mf}[1]{\textcolor{Green}{[mf: #1]}}  
\newcommand{\mht}[1]{\textcolor{Blue}{[mht: #1]}} 

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
  
  

# Introduction

If you hear "Jones is happy" you understand that Jones' happiness ---a *gradable property*--- exceeds a certain threshold which depends on the context of utterance and our prior expectations about Jones' likely happiness [@kennedy2005scale; @Kennedy2007].
But what about the compositional "Jones is not unhappy"? 
Do the two negatives make a positive?
@Jespersen1924 believed not:

\begin{quote}
\footnotesize
[T]wo negatives do not exactly cancel one another [$\ldots$]; the longer expression is always weaker: "this is not unknown to me" or "I am not ignorant of this" means "I am to some extent aware of it," etc. (p.$\thinspace$332)
\end{quote}

Negation is the semantic operation of forming an opposite, but there are multiple kinds of semantic opposition [@Horn1989:Natural]. 
A *contrary opposition* is one where both predicates cannot be true at the same time, but both can be false.
*Negative adjectives* (e.g., "sad", "rude") intuitively express contrary opposition to *positive adjectives* ("happy", "polite"): it is conceivable that Jones is neither happy nor sad; there is a neutral middle ground.
In contrast, a *contradictory opposition* (e.g., *even/odd (positive integer)*), is one where falsity of one predicate entails truth of the other. 
Contradictory opposition seems to manifest in *particle negation* (e.g., "not happy") and *antonyms* (e.g., "unhappy") because of its transparent mapping to proposition-level negation ($\neg$) in modern standard logic.^[
  We use a somewhat idiosyncratic terminology here so as to be concise in the distinctions most relevant for this paper.
  While "sad" is of course also an antonym of "happy", we speak of *negative* and *positive* adjectives, and reserve *antonym* for antonyms created by affixal negation (e.g., "un-"). 
  Also, we use *particle negation* for negation formed by "not" over the more accurate "adverbial negation", because of higher distinguishability from "affixal negation".
]
If this is so, however, combining the two devices should cancel each other out: "not unhappy" means "happy".
As @orwell1946politics argues:

\begin{quote}
\footnotesize
Banal statements are given an appearance of profundity by means of the "not un-" formation. [$\ldots$] It should be possible to laugh the "not un-" formation out of existence by memorizing this sentence: "A not unblack dog was chasing a not unsmall rabbit across a not ungreen field." (p.$\thinspace$357)
\end{quote}

Alterantively, antonyms created by affixal negation (*un-*, *in-*, etc.) could form a contrary, like a negative adjective.
Then, *happy* and *not unhappy* would be pragmatic alternatives; *not unhappy* could be pragmatically strengthened to be more specific than literally the negation of *unhappy*.
This logic alone, however, entails that *not unhappy* refers to a neutral or indifferent state [@Horn1991:Duplex], contra @Jespersen1924's intuition that *not unhappy* is a slightly positive state.
It seems that *not happy* could also be an alternative [@Blutner2004:pragmatics], but how pragmatics contextually strengthens *not happy* has not been fully spelled out [@Krifka2007:Negated-antonyms].
Furthermore, the meaning of *not happy* is at least as controversial as that of *unhappy*: @Jespersen1917:Negation and @Blutner2004:pragmatics argue that the two are basically identical in meaning (i.e., antonyms and negated positives are both contradictory in nature), but @Krifka2007:Negated-antonyms cites examples like the following (taken from the internet):

<!-- Here is an instance of an attested difference in meaning between negated positives and morphological antonyms (e.g., *not happy* and *unhappy*), taken from @Krifka2007:Negated-antonyms, taken from internet: -->
\begin{quote}
\footnotesize
It's an absolutely horrible feeling to be unhappy, and I don't even think I was unhappy, just not happy, if you know what I mean. 
\end{quote}

<!-- This example suggests that at least in the context of explicit alternative utterances (*not unhappy just not happy*), antonyms and negated positives can take on distinct meanings, even if they may not in isolation. -->
This multiplicity of interpretations, we posit, is the result of uncertainty about the meaning of overt negation markers ("un-", "not").
We propose a probabilistic speaker-listener pragmatic reasoning model in the Rational Speech Act tradition [@Franke2015a; @Goodman2016:RSA], by combining previous work deriving interpretations for gradable adjectives [@Lassiter2015; @Qing2014:Adjectives] with elements of lexical uncertainty [@Bergen2016].
This model predicts qualitative differences between scales described by positive \& negative adjective pairs (e.g., "tall"/"short") and those given by antonym pairs (e.g., "happy"/"unhappy").
Our lexical uncertainty model makes the further prediction that these differences between scale types should be sensitive to context, in particular, the presence of explicit alternative utterances (as suggested by the example above). 
We compare model predictions to novel data from three experiments that measure interpretations for different kinds of adjectives in different contexts, uncovering subtle but reliable differences.
These findings suggest that pragmatic reasoning can utilize uncertainty in logical meanings to derive finer-grained interpretations through the competiton of multiple interpretations of multiple alternative utterances.

<!-- \noindent We did not find such a difference in our experiment, but rather than conclude that no differnce exists, we note that the speaker in this example utterance chose to use both *unhappy* and *not happy* in the same utterance.  -->
<!-- We hypothesize that explicit comparisons between alternative utterances can draw out the difference in meaning between negated positives and morphological antonyms, which leads the morphological antonym to behave more like a bonafide antonym. -->

<!-- Given the manifold interpretations of antonyms and particle negation, we hypothesize that listeners represent these possibilities as uncertainty in meaning of overt negation markers and resolved it in context. -->
<!-- We propose a probabilistic speaker-listener pragmatic reasoning model in the Rational Speech Act tradition [@Franke2015a; @Goodman2016:RSA],  to model the indeterminacy about how to interpret overt negation markers.  -->
<!-- We combine previous work deriving interpretations for gradable adjectives by considerations of cooperative language use [@Lassiter2015; @Qing2014:Adjectives] with elements of lexical uncertainty [@Bergen2016]. -->
<!-- We compare model predictions to novel data from three experiments that measure interpretations for positive and negative adjectives (*happy*/*sad*) as well as antonyms (*unhappy*) and particle negations (*not happy/sad/unhappy*) in different contexts, uncovering subtle but reliable differences. -->
<!-- These findings suggest that pragmatic reasoning can utilize uncertainty in logical meanings to derive finer-grained interpretations through the competiton of multiple interpretations of multiple alternative utterances. -->
<!-- \mht{this last sentence is a behemoth \mf{is that a good thing? from Wikipedia: "Metaphorically, the name has come to be used for any extremely large or powerful entity."}}\mht{strictly speaking: I prefer my mythical creatures in metaphorically bite-size chunks} -->

<!-- In Experiment 1, we measure uncover this ordering for antonym pairs defined with unique lexical items (e.g., "tall"/"short") but not for morphological antonyms (e.g., "happy"/"unhappy").  -->
<!-- In Experiment 2, we show that morphological antonyms to create a reliable ordering when context clearly provides a speaker's alternatives utterances. -->
<!-- In a large-scale, preregistered study, we replicate these findings within sets of adjectives that allow both lexical and morphological antonyms (e.g., "happy" / "unhappy" / "sad").  -->


<!-- Classical, bivalent logic mandates that two negatives make a positive, but speakers can use double negation (e.g., "not" + "un-" + "reasonable") in a non-redundant manner. -->
<!-- As @Jespersen1924 noted: -->

<!-- > The two negatives do not exactly cancel one another... the longer expression is always weaker: "this is not unknown to me" or "I am not ignorant of this" means *I am to some extent aware of it*, etc. -->

<!-- This intuitions is surely shared for *negated antonyms* (e.g., "not sad") and is predicted to carve the underlying semantic scale is a relatively stable ordering: "sad" $<$ "not happy" $<$ "not sad" $<$ "happy" [@Horn1989:Natural; @Krifka2007:Negated-antonyms]. -->
<!-- But creating an opposite meaning through an *affixed morpheme* (e.g., "un-") does not unambiguously create an antonym. -->
<!-- As @orwell1946politics noted:  -->

<!-- > Banal statements are given an appearance of profundity by means of the "not un-" formation... It should be possible to laugh the "not un-" formation out of existence by memorizing this sentence: "A not unblack dog was chasing a not unsmall rabbit across a not ungreen field." -->



<!-- The answer to how listeners interpret different kinds of opposing meanings lies at the intersection between compositional semantics and vague language understanding. -->
<!-- We draw inspiration from usage-based theories of grammar \red{(cite: ODonell2015, Bybee 2011?)} to introduce uncertainty about how to parse *morphological antonyms* (e.g., "unhappy") into a probabilistic model of gradable adjective understanding.  -->
<!-- This *uncertain parser* model includes, as a special case, a sub-model that interprets antonyms and their negations, producing the hypothesized ordering (Figure 1). -->
<!-- In Experiment 1, we measure uncover this ordering for antonym pairs defined with unique lexical items (e.g., "tall"/"short") but not for morphological antonyms (e.g., "happy"/"unhappy").  -->
<!-- In Experiment 2, we show that morphological antonyms to create a reliable ordering when context clearly provides a speaker's alternatives utterances. -->
<!-- In a large-scale, preregistered study, we replicate these findings within sets of adjectives that allow both lexical and morphological antonyms (e.g., "happy" / "unhappy" / "sad").  -->
<!-- These findings suggest that pragmatic reasoning can utilize the tension between parsing utterances compositionally (e.g., "un-" + "happy") and interpreting them holistically ("unhappy") to derive fine-grained meanings in-the-moment. -->


<!-- We hypothesize that the conflict in the literature surrounding  -->


<!-- In logic, two negatives make a positive, but the same does not seem to hold in natural language.  -->
<!-- Somebody "not sad" is not necessarily "happy".  -->
<!-- "Sad" is an antonym, whereas the particle "not" simply negates the positive "happy". -->



<!-- Instead, antonyms and their negations appear to partition the underlying semantic scale in an ordering:  We show how this semantic ordering falls out of an information-theoretic model of adjective interpretation, without assuming that *unhappy* $<$ *happy*. We then empirically investigate the semantic ordering, finding that the ordering appears when participants are fully aware of the utterances a speaker could say for antonym pairs defined by morphological negation (*[un]happy*); the explicit presentation of alternatives is not necessary for the analogous ordering of antonym pairs of distinct lexical items (*tall* / *short*). These findings suggest a model of interpretation where listeners maintain uncertainty about the parsing of an utterance involving multiple negations." -->


<!-- , derive this intuitive ordering which we validate in an expt. -->


<!-- Jespersen's intuition is not universally shared, however.  -->
<!-- "Not" and "un-" can be two ways of saying the same thing.  -->
<!-- "Not unreasonable" might mean "reasonable". -->


<!-- Why does language provide multiple, seemingly identical ways of conveying the same meanings? -->
<!-- Classical logic distinguished statements that are contrary to one another (e.g., *antonyms*; "Sam is happy" vs. "Sam is sad") and those that are contradictory (e.g., using *negation particles*: "Sam is *not* happy"). -->
<!-- For Jespersen's intuition to hold, "unhappy" (*morphene negation*) must be a *contrary*, like "sad".  -->
<!-- Then, "not unhappy" can receive a restricted interpretation via its literal meaning and pragmatic competition with "happy" [@Horn1991:Duplex; @Horn1993:Economy]. -->
<!-- This model, however, renders "not unhappy" as neutral or indifferent, contrary to the intuition that "not unhappy" is a slightly positive state [@Krifka2007:Negated-antonyms]. -->



<!-- \mht{Recent breakthroughs in the probabilistic modeling tradition have put this within grasp.} -->
<!-- We use the tools of probabilistic pragmatics to formalize how negated and antonymous meanings should produce an ordering on interpretations: *sad* $<$ *not happy* $<$ *not sad* $<$ *happy*. -->
<!-- We then investigate the ordering with *morpheme negation* (e.g., "unhappy"), providing empirical evidence that it is treated the same as *particle negation* (e.g., "not happy") when the relevant alternative utterances are not salient to the listener. -->
<!-- We hypothesize that *parsing uncertainty* underlies this interpretative behavior idiosyncractic to morpheme negation. -->


<!-- - There are two kinds of negation. -->
<!-- - They can be used together while not cancelling out.  -->
<!-- - Yet more forms exist: unhappy. -->
<!--   - morphological antonyms have been of particular interest for their underspecification inmeaning (conflicting intuitions) -->
<!--   - we hypothesize that the conflict in the literature can be attributed to an uncertain parse of morphological negation. -->
<!-- - We formalize this hypothesis in a model of gradable adjectives. As a special case of this model, when there is no uncertainty about parsing, the model reduces to a model of antonyms and negations, which predicts a precise ordering. Instead the uncertain parse model does not differentiate between two kinds of negation. We thus predict an interaction between parsing uncertainty and the difference between antonymous negation and particle negation. -->

<!-- \mht{mention ordering?} -->

<!-- underespecified meanings for gradable adjectives interacts with negation to produce  -->
<!-- Probabilistic models of pragmatic reasoning have proved useful in formalizing the vagueness of gradable adjectives [e.g., "happy"; @GoodmanLassiter2015-handbook], and we adopt this formalism to better understand  -->
<!-- A speaker can use a particle (e.g., "not happy"), affix a morpheme (e.g., "unhappy"), or say an antonym (e.g., "sad") -->
<!-- Contra classical logic, however, these two ways of employing negation *do not* cancel each other out: someone "not unhappy" is not necessarily happy. -->

```{r happy-scale, fig.cap="Hypothesized ordering of sets of antonyms and their negations.", eval=F}
ggdraw() + draw_image("img/happy-scale.pdf") +
  theme(plot.margin = unit(c(0,0,0,0), "pt")) 
```

<!-- The plot thickens when we consider that lexically-distinct words also provide antagonistic meanings: "" -->

<!-- These two issues motivate our current approach. -->
<!-- First, competing intuitions concerning the meaning of what we will here call *particle negation* ("not happy") and *affix negation* ("unhappy") suggest that empirical data should be consulted before further theorizing about pragmatic mechanisms. -->
<!-- Second, the fact that the mechanisms of pragmatic strengthening of particle negation are not clear suggests a benefit from a formal modeling approach.  -->
<!-- We first elaborate a computational model of adjective interpretation to include antonyms and their negations: adjectives (e.g., "happy"), their antonyms (e.g., "sad"), and the negations of each ("not happy", "not sad"). -->
<!-- We then formalize a hypothesis that natural language negation passes through a probabilistic parsing model, which provides a novel prediction about the interpretations of different kinds of negation (e.g., "not happy", "unhappy", "sad"). -->
<!-- In a behavioral experiment, we investigate the hypothesized ordering of antonym quartets for antonyms with distinct lexical entries (e.g., "tall" and "short") and antonyms constructed by affix negation (e.g., "happy" and "unhappy"). -->

<!-- \begin{figure}[h] -->
<!-- \vspace{-2.5cm} -->
<!-- \includegraphics[width = \columnwidth]{figs/happy-scale-1}  -->
<!-- \vspace{-3cm} -->
<!-- \caption[Hypothesized ordering of sets of antonyms and their negations]{Hypothesized ordering of antonyms and negations.}\label{fig:happy-scale} -->
<!-- \end{figure} -->

# Computational model


Gradable adjectives (e.g., "tall", "happy") are vague decriptions of a quantitative scale (e.g., *height*, *happiness*).
Their meanings can be modeled using a threshold function: $\denote{happy} = \lambda e \thinspace . \thinspace \text{happiness}(e) > \theta$, whose threshold variable $\theta$ is supplied by the context [@Kennedy2007].
@Lassiter2015 give a model (Eqs.$\thinspace$\ref{eq:L1}-\ref{eq:L0}) that derives plausible values for $\theta$ from pragmatic reasoning [see also @Potts2008:Interpretive-Ec; @Qing2014:Adjectives]:
<!-- , and show how such a model can account for key aspects of vagueness: context-sensitivity and the admission of borderline cases (e.g., people who are both tall and not tall). -->
\vspace{-0.5cm}
\begin{align}
L_{1}(x, \theta \mid u) &\propto S_{1}(u \mid x, \theta) \cdot P(x) \cdot P(\theta) \label{eq:L1} \\
S_{1}(u \mid x, \theta) &\propto \exp{(\alpha \cdot \ln {L_{0}(x \mid u, \theta)} - \text{cost}(u))} \label{eq:S1}\\
L_{0}(x \mid u, \theta) &\propto {\delta_{x> \theta} \cdot P(x)} \label{eq:L0}
\end{align}

Eqs.$\thinspace$\ref{eq:L1}-\ref{eq:L0} are a Rational Speech Act (RSA) model, a recursive Bayesian model wherein a pragmatic listener $L_{1}$ tries to resolve the intended meaning of an utterance $u$ (e.g., "Jones is happy") by combining their prior beliefs $P(x)$ about the degree $x$ of Jones' happiness, with the generative process of the utterance, a speaker model $S_1$.
The speaker model $S_1$  describes an approximately rational Bayesian agent (with degree of rationality $\alpha$) trying to inform a naive listener $L_0$ (Eq.$\thinspace$\ref{eq:L0}) about the state of the world $x$.
<!-- In the context of adjective interpretation, the state of the world is given by the value of the scalar degree $x$ (e.g., the height of the referent). -->
The literal listener $L_0$ updates their prior beliefs $P(x)$ via an utterance's literal meaning, given by the threshold function described above.
The pragmatic listener has uncertainty about $\theta$, which comes from an uninformed prior and is resolved by jointly reasoning about the likely states of the world $P(x)$ and the likelihood $S_1(u \mid x, \theta)$ that a cooperative information-maximizing speaker would utter the adjective given a state $x$ and a threshold $\theta$.

\begin{table}[b]
  \centering
  \footnotesize
  \begin{tabular}{ll}
	\textbf{expression} & \textbf{interpretation options} \\ \midrule
    \emph{not happy} / \emph{unhappy} & $\lambda e \thinspace . \thinspace \neg (\mathit{happiness}(e) >
    \theta_{h})$ \\
    & $\lambda e \thinspace . \thinspace \mathit{happiness}(e) <
    \theta_{\tilde{h}}$ \\ \midrule
    \emph{not unhappy} & $\lambda e \thinspace . \thinspace \mathit{happiness}(e) >
    \theta_{h}$ \\
		& $\lambda e \thinspace . \thinspace \neg(\mathit{happiness}(e) <
    \theta_{\tilde{h}})$ \\ 
  \end{tabular}
  \caption{Logically possible interpretations of negated expressions.}
  \label{tab:Interpretations}
\end{table}


The proportionality in Eq.$\thinspace$\ref{eq:S1} implies normalization over a set of alternative utterances (potentially differentiated by their cost).
Our primary focus is on an alternative set composed of a positive adjective, its antonym, and their respective negations [e.g., \{*happy*, *not happy*, *unhappy*, *not unhappy*\}; @Blutner2004:pragmatics; @Krifka2007:Negated-antonyms].
<!-- We consider two such alternative sets: postives, negatives, and their negations (e.g., \{*tall*, *not tall*, *short*, *not short*\}) and positives, antonyms, and their negations  -->
We posit that listeners have uncertainty about whether each negation marker (*not*, *un-*) expresses contradictory or contrary opposition but maintain structural constraints on composition.
If $Hx$ expresses that $x$ is happy, contradictory opposition is standard, bivalent, proposition-level negation $\neg Hx$.
Contrary opposition is made by a predicate-forming operation $\tilde{H}x$ which introduces its own free threshold $\theta_{\tilde{H}}$ for gradable predicates.
The latter is not iterable [@Horn1989:Natural; @sep-negation], so while it makes sense to iterate $\neg \neg Hx$, it is impossible to iterated contrary negation. 
<!-- It is, however possible, to have $\neg \tilde{H}x$.  -->
<!-- But it is not possible to have $\neg$ in the scope of $\tilde{H}x$. -->
Consequently, *not happy* and *unhappy* can both be construed as either $\neg Hx$ or $\tilde{H}x$, while *not unhappy* can receive two interpretations, namely $\neg \neg Hx$ and $\neg \tilde{H}x$ (Table$\thinspace$\ref{tab:Interpretations}).
<!-- Negative adjectives (e.g., "short", discussed later) have no overt negation marker, and thus are assumed to be contraries $\tilde{H}x$, which receive their own thresholds $\theta_{\tilde{H}}$. -->


<!-- cases, distinguished by what antonym is assumed for a positive form like *happy*. -->
<!-- First, with a *lexical antonym* the set of alternative utterances is \{"happy", "not happy", "sad", "not sad"\}. -->
<!-- Second, with a *morphological (affix-negated) antonym* the set of alternative utterances is: \{"happy", "not happy", "unhappy", "not unhappy"\} [@Blutner2004:pragmatics; @Krifka2007:Negated-antonyms]. -->
<!-- The pragmatic listener assumes that affixal negation (e.g., *un-* or *in-*) and particle negation (e.g., *not*) can in principle both be used to express contradictory or contrary opposition.  -->
<!-- Rational pragmatic reasoning decides which interpretation of a negation marker is more likely, in conjunction with which thresholds to assign to any basic gradable expressions. -->



The listener's uncertainty about how to interpret negation markers is formally captured in our probabilistic model as uncertainty about the lexicon $\mathcal{L}$ the speaker is likely to use [@Bergen2016]. 
We consider the set of all combinations of logically possible interpretations of negated expressions in the alternative set as the set of possible lexica (Table$\thinspace$\ref{tab:Interpretations}), and assume, for simplicity, that the listener treats all lexica as equally likely *a priori*.
<!-- (even when we considers only a proper subset of the logically possible lexica, as in some model variants investigated below).  -->
Adding such lexical uncertainty to the threshold-inference model above, Eq.$\thinspace$\ref{eq:L1} becomes:

\vspace{-0.5cm}
\begin{align}
L_{1}(x, \theta, \mathcal{L} \mid u) &\propto S_{1}(u \mid x, \theta, \mathcal{L}) \cdot P(x) \cdot  P(\theta) \cdot P(\mathcal{L}) \label{eq:L1ant}
\end{align}

\noindent where $\mathbf{\theta}$ is a now a vector of relevant thresholds.
We consider two variants of this model as alternative hypotheses and examine their qualitative predictions in situations when they hear a single utterance in isolation (e.g., "Jones is unhappy") and when they multiple utterances from a speaker (e.g., "Jones is unhappy. Smith is not unhappy.").^[These model predictions assume the following model parameters: $P(x) = \mathcal{N}(0, 1); \alpha = 1; \text{cost}(\mathit{un}) = 1; \text{cost}(\mathit{not}) = 2$.]
To match our experimental setup, the multiple utterances situation corresponds to hearing all four adjective alternatives about four different individuals.


<!-- and evaluate them (and our *full uncertainty* model) in situations where they hear a single utterance from a speaker (e.g., "Jones is unhappy") and when they multiple utterances from a speaker (e.g., "Jones is unhappy. Smith is not unhappy."). -->


```{r modelPredictions, fig.cap="Predictions for the strengths of adjective interpretations for three model variants.", fig.env = "figure", fig.pos = "t", fig.width=3.5, fig.height=3, fig.align = "center"}
load('cached_results/rsa_model_predictions.RData') # rs.listener.wp.expectation

# new_type = ifelse(antonym_type == "lexical", 
#                            ifelse(adjective_type == "Antonym", "Negative", 
#                             ifelse(adjective_type == "Negated Antonym", "Negated negative", 
#                                    as.character(adjective_type))), as.character(adjective_type))

rs.listener.wp.expectation %>%
  mutate(utterance = factor(utterance, levels = c("Antonym", "Negated positive",
                         "Negated antonym", "Positive"),
                         labels = c("Antonym", "Negated\npositive",
                         "Negated\nantonym", "Positive")),
         src = factor(src, levels = c("george orwell", "bonafide contraries", "full uncertainty"),
                      labels = c("george orwell", "bonafide contraries", "full uncertainty")),
         utterances = factor(utterances, 
                             levels = c("independent", "simultaneous"),
                             labels = c("implicit", "explicit"))) %>%
  ggplot(., aes( x = src, y = interpretation,
                 fill = utterance))+
    geom_col(position = position_dodge(0.8), 
             width = 0.8, color = 'black')+
    scale_fill_manual(name="Adjective type",
                    values = orange.purple.color.palette,
                    guide = guide_legend(reverse=F,
                                         keywidth = 0.5,
                                         keyheight = 0.4,
                                         default.unit = "cm"))+
  facet_wrap(~utterances)+
  #xlab("Model")+
  ylab("Model interpretation")+
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 10, vjust = 0),
    axis.text.y = element_text(size = 9),
    #axis.text.x = element_text(size = 9, angle = 30, hjust = 0.8, vjust = 0.9), 
    axis.text.x = element_text(size = 9, angle = 45, hjust = 1, vjust = 1), 
        legend.position = 'bottom',
        legend.text = element_text(size = 9, hjust= 0),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(-7,0,0,-10),
        legend.title = element_blank(),
    panel.spacing = unit(0, "lines")
        #legend.key.size = unit(0.5, "cm"),
      #legend.key = element_rect(size = 10)
      )+
  scale_y_continuous(limits = c(-0.8, 0.85), breaks = c(-0.75, 0, 0.75))#+
  #guides(fill=guide_legend(nrow=2,byrow=TRUE))
```

The *George Orwell* (or, logical negation) model does not have lexical uncertainty about overt negation markers and is based on the intuition that negation markers only express contradictory opposition. 
This model, consequently, does not differentiate between negated antonyms (*not unhappy*) and positives (*happy*), nor negated positives and antonyms (Figure$\thinspace$\ref{fig:modelPredictions} left), even when the speaker uses the different utterances to describe different references (e.g., "Jones is not happy", "Smith is unhappy"; Figure$\thinspace$\ref{fig:modelPredictions} right).
\mht{explain why quantitative differences are exaggereted? maybe too much...}
<!-- However, in the context of explicit alternative utterances, the differences in interpretation between a positive adjective and its negation become quantitatively exaggerated ().  -->

The *bonafide contraries model* assumes that antonyms (*unhappy*) convey contrary opposition, while maintaining uncertainty about the meaning of particle negation (*not happy*).
This model provides stronger interpretations to positives than to negated antonyms, and stronger interpretations to antonyms than to negated positives.
That is, the *bonafide contraries* model produces a full ordering also predicted by @Krifka2007:Negated-antonyms: *unhappy* $\approx$ *not happy* $<$ *not unhappy* $<$ *happy*.
Remarkably, even though this model has *a priori* uncertainty about the correct interpretation of particle negation *not*, pragmatic reasoning infers that *not* should be interpreted as contradictory opposition $\neg$ so as to keep the lexicon non-redundant.

<!-- \mht{i wonder if we should talk about all model variants with the same alternative set (unhappy), and note at the end of this paragraph that the bonafide antonyms model we hypothesize is the correct model for lexical anotnyms} -->
<!-- alternative set \{*happy*, *not happy*, *sad*, *not sad*\}, where a *bonafide antonym* like *sad* receives its own independent threshold, since it unambiguously expresses contrary  opposition; alternatively, this model can be interpreted as a special case of alternatives \{*happy*, *not happy*, *unhappy*, *not unhappy*\} when the listener only considers *unhappy* as contrary opposition, thus treating *unhappy* as a *bonafide antonym* like *sad*. -->
<!-- We retain uncertainty about the meaning of particle negation. -->

Finally, the *full uncertainty model* considers the full set of logically possible lexica.
When hearing a single utterance in isolation, this model predicts a quasi-ordering: *unhappy* $\approx$ *not happy* $<$ *not unhappy* $<$ *happy*.
Even in this relatively impoverished context, when the model hears *not unhappy*, it reasons that a truly compositional, double negation is unlikely, contra George Orwell.
Furthermore, when the model hears all 4 utterances by the same speaker, it predicts the full ordering of @Krifka2007:Negated-antonyms.

To summarize, we hypothesize that overt negation markers ("un-", "not") come with uncertainty in meaning (contrary vs. contradictory negation) that produces a partial ordering for antonym pairs and their negations when heard in isolation (Figure$\thinspace$\ref{fig:modelPredictions} left, *full uncertainty model*).
This uncertainty can be fully resolved, producing a full ordering, by hearing multiple utterances from the same speaker (Figure$\thinspace$\ref{fig:modelPredictions} right, *full uncertainty model*).
We further predict that scales described by negative adjectives (e.g., "short") do not entertain the same uncertainty (since there is no overt negation involved), and will thus behave more like *bonafide contraries* model. 
We design our behavioral experiments to test these predictions.
\text{Expts$\thinspace$1 $\&$ 2} were exploratory and informed our computational modeling.
\text{Expt.$\thinspace$3} is a more powerful and more stringent, preregistered confirmatory replication.

# Behavioral experiments

The *full uncertainty model* predicts that antonyms created by affixal negation (*unhappy*) and negated positives (*not happy*) receive similar interpretations when evaluated in isolation, while negated antonyms (*not unhappy*) are interpreted more weakly than positive adjectives (*happy*).
We contrast this quasi-ordering for *antonym scales* (*unhappy* $\approx$ *not happy* $<$ *not unhappy* $<$ *happy*) with a full-ordering predicted for *negative scales* (*short* $<$ *not tall* $<$ *not short* $<$ *tall*) by the *bonafide contraries* model. 

## Experiment 1

### Methods

```{r expt1_subjInfo}
load("cached_results/time_summary_e1.RData") # d.expt1.time.summary
load("cached_results/english_summary_e1.RData") # d.l1.7.nativeEnglish
```

#### Participants

We recruited 120 participants from Amazon's Mechanical Turk (MTurk). 
This number was arrived at with the intention of getting approximately 25 ratings for each unique item in the experiment.
In all experiments, participants were restricted to those with U.S. IP addresses and at least a 95\% work approval rating. 
The experiment took on average `r round(d.expt1.time.summary[[1, "aveTime"]],1)` minutes and participants were compensated \$0.40 for their work.

#### Procedure and Materials

On each trial, participants read a statement introducing a character using a gradable adjective of one of eight **adjective types** that can be broken down into four adjectives for each of two different **opposite types** (*negatives* $\textsc{opposite}_\textsc{neg}$ e.g., "short" and *antonyms* $\textsc{opposite}_\textsc{ant}$ e.g., "unhappy").
The adjective types were $\textsc{positive}$ (e.g., "happy", "tall"), $\textsc{opposite}$ (e.g., "short", "unhappy"), and their respective negations (e.g., "not" + adj). 
Participants were asked to rate the character on a scale from "the most \textsc{positive} person" to "the most \{$\textsc{opposite}_\textsc{neg} / \textsc{opposite}_\textsc{ant}$\} person" (depending on the opposite type), using a slider bar (\figref{fig:experiment-slides}A).
Participants rated one sentence at a time (e.g., *Greg is not unhappy*) and saw items from both opposite types (antonym, negative) throughout the experiment. 

There were a total of 16 trials, with exactly 2 repetitions of each adjective type in each opposite type, always with items from distinct **adjective sets**.
Adjective sets described properties of people and were composed of a positive adjective, its opposite (either a negative adjective or an antonym), and their respective negations (e.g., one adjective set is *happy*, *unhappy*, *not happy*, *not unhappy*).
Items were constructed from an informal survey of the linguistics literature and taken from a list of ``common opposites'' available online\footnote{http://www.enchantedlearning.com/wordlist/opposites.shtml} (for a full list, see \tableref{tab:items12}).


```{r experiment-slides, fig.pos = "hb", fig.cap="Example experimental trials.", fig.height=2.75, fig.width = 3.5}
slide.expt.1 <- cowplot::ggdraw() + 
  cowplot::draw_image("img/expt1.jpeg", scale = 1) +
  theme(plot.margin = unit(c(0,0,0,0), "pt")) + 
  cowplot::panel_border()
slide.expt.2 <- cowplot::ggdraw() + 
  cowplot::draw_image("img/expt2.jpeg", scale = 1)+
  theme(plot.margin = unit(c(0,0,0,0), "pt")) + 
  cowplot::panel_border()

cowplot::plot_grid(
    cowplot::add_sub(slide.expt.1, "Experiment 1 (implicit alternatives)", size = 8), 
    cowplot::add_sub(slide.expt.2, "Experiment 2 (explicit alternatives)", size = 8), 
    labels = c("A", "B"), 
    nrow = 2)
```

```{r items12, results="asis"}
load(file = "cached_results/item_table_e12.RData")
print(tab1, type="latex", comment = F, table.placement = "H", size="\\fontsize{9pt}{10pt}\\selectfont", include.rownames=FALSE)
```

### Results

```{r}
load("cached_results/regression_antTypeXadjType_expt1.RData") # rs1.expt1.helmert.summary
rs1.expt1.coef <- rs1.expt1.helmert.summary[["coefficients"]]
```

`r sum(!d.l1.7.nativeEnglish$englishNative)` participants were excluded for self-reporting a native language other than English, leaving a remainder of `r sum(d.l1.7.nativeEnglish$englishNative)` participants for these analyses.

The predictions of our models concern the nature of the ordering of terms within a set of alternatives for different opposite types (negatives vs. antonyms).
To visualize the data, we compute normalized responses on a participant-wise basis (i.e., normalized response $r'_{ij} = \frac{r_{ij} - mean_j}{sd_j}$ for trial $i$ and participant $j$).
Figure \ref{fig:expt-results}A shows the mean normalized responses and bootstrapped 95\% confidence intervals for each of the four adjective types for both lexical and morphological antonyms. 
As predicted by the *bonafide contraries model*, adjective sets with *negative* opposites show a strict ordering: $\textsc{opposite}_\textsc{neg} < \textsc{negated positive} < \textsc{negated opposite}_\textsc{neg} < \textsc{positive}$.
Furthermore, as predicted by the *full uncertainty model* and consistent with the intuitions of @Jespersen1917:Negation and @Blutner2004:pragmatics, adjective sets with *antonyms* show only a partial ordering: $\textsc{opposite}_\textsc{ant} <  \textsc{negated positive} < \textsc{negated opposite}_\textsc{ant} < \textsc{positive}$.

To confirm these observations, we built a mixed-effects regression model with by-participant and by-item random effects of intercept and opposite type (\textsc{positive}, \textsc{antonym}, etc.) to predict the raw non-normalized ratings.^[
  This, and all subsequent regression models, were the maximal mixed-effects model that converged for the data set that additionally explained significantly more variance than models with simpler mixed-effects structures, using the \texttt{lme4} package in R [@lme4]. \mf{check name of second author?}
]
Consistent with our observations, the interaction between opposites vs.\text{~}negated positive *adjective type* and type of opposites (negatives vs.\text{~}antonyms) was significant: $\beta = `r round(rs1.expt1.coef["antonym_typelexical:st1","Estimate"],3)`$, $SE =  `r round(rs1.expt1.coef["antonym_typelexical:st1","Std. Error"],4)`$, t$(`r round(rs1.expt1.coef["antonym_typelexical:st1","df"], 1)`) = `r round(rs1.expt1.coef["antonym_typelexical:st1","t value"],2)`, p = `r round(rs1.expt1.coef["antonym_typelexical:st1","Pr(>|t|)"], 4)`$.

We additionally note that interpretations of negated antonyms (e.g., *not unhappy*) were appreciably weaker for than those of negated negatives (e.g., *not tall*).
Interpretations for negated antonyms gave rise to a bimodal distribution of ratings: The vast majority of ratings were slightly positive, while a clearly distinguishable minority distribution of ratings were slightly negative (e.g., *not dishonest* meaning that the person is below average in honesty).
\mf{Was this bimodality consistent between certain subjects or certain items? Does this violate assumptions of normality for the regression model?}
This interpretation may be attributable to politeness on behalf of the speaker, a phenomenon noted by @Horn1991:Duplex and predicted formally by a recent model of polite language understanding [@Yoon2017].

<!-- ### Discussion -->
<!-- Consistent with the intuition from all but George Orwell, the negated (morphological) antonyms were interpreted as slightly positive, though less-so that purely postive statements. -->
<!-- This interpretation is predicted by the *bonafide antonyms* model and the *uncertain parser* model.  -->
<!-- \text{Expt.$\thinspace$1} further confirmed our hypothesized asymmetry between lexical and morphological antonyms.  -->
<!-- In particular, interpretations of morphological antonyms were indistinguishable from those of negated positive statements, consistent with the intuition of @Jespersen1917:Negation and @Blutner2004:pragmatics as well as our *uncertain parser* model.  -->
<!-- Lexical antonyms, on the other hand, showed a clear ordering: ANT $<$ NEG POS $<$ NEG ANT $<$ POS.  -->


<!-- Differences in meaning between negated positives and morphological antonyms (e.g., *not happy* and *unhappy*) were not found.  -->
<!-- However, differences in meaning have been noted in such naturalistic examples as  -->
<!-- Here is an instance of an attested difference in meaning between negated positives and morphological antonyms (e.g., *not happy* and *unhappy*), taken from @Krifka2007:Negated-antonyms, taken from internet: -->
<!-- \begin{quote} -->
<!-- \footnotesize -->
<!-- It's an absolutely horrible feeling to be unhappy, and I don't even think I was unhappy, just not happy, if you know what I mean.  -->
<!-- \end{quote} -->

<!-- \noindent We did not find such a difference in our experiment, but rather than conclude that no differnce exists, we note that the speaker in this example utterance chose to use both *unhappy* and *not happy* in the same utterance.  -->
<!-- We hypothesize that explicit comparisons between alternative utterances can draw out the difference in meaning between negated positives and morphological antonyms, which leads the morphological antonym to behave more like a bonafide antonym. -->

## Experiment 2: Explicit alternatives 

In Experiment 1, we found positive evidence for the quasi-ordering of adjective sets defined with antonyms and for the full ordering of adjective sets defined by negatives. 
This experiment tests the effect of hearing alternatives utterances produced by the same speaker on interpretation.
The *full uncertainty* model predicts a full ordering of the adjective set when the multiple utterances are heard from the same speaker.

### Methods

#### Participants

We recruited 50 participants MTurk.
This number was arrived at with the intention of getting approximately 25 ratings for each unique item in the experiment.
The experiment took on average N minutes and participants were compensated \$N for their work.

#### Procedure and Materials

The experimental materials were the same as in \text{Expt.$\thinspace$1}. 
The procedure differed in that participants saw and rated all four sentence types simultaneously (\figref{fig:experiment-slides}B). 
In addition, the endpoints of the slider bars were relabeled to "the most \{\textsc{pos}, \textsc{ant}\} person *in the world*"; without "in the world", there is a salient interpretation of the endpoints as indicating  "the most \{\textsc{pos}, \textsc{ant}\} person (of these four)".

### Results

```{r regressionResultsExpt2}
load("cached_results/regression_antTypeXadjType_expt2.RData") # rs1.expt2.helmert.summary
load("cached_results/regression_simple_adjType_morph_expt2.RData") #rs1.expt2.simpleMorph.summary
rs1.expt2.coef <- rs1.expt2.helmert.summary[["coefficients"]]
rs1.expt2.simple.morph.coef <- rs1.expt2.simpleMorph.summary[["coefficients"]]
```

We hypothesized that attested differences in meaning between negated positives and morphological antonyms can be drawn out with explicit comparisons to alternative utterances.
In this experiment, with the alternatives explicit, we find that participants rate morphological antonyms as significantly more negative than negated positives: $\beta = `r round(rs1.expt2.simple.morph.coef["st1","Estimate"],3)`$, $SE =  `r round(rs1.expt2.simple.morph.coef["st1","Std. Error"],4)`$, t$(`r round(rs1.expt2.simple.morph.coef["st1","df"], 1)`) = `r round(rs1.expt2.simple.morph.coef["st1","t value"],2)`, p = `r round(rs1.expt2.simple.morph.coef["st1","Pr(>|t|)"], 4)`$.
The interaction between negation type (antonym vs.\text{~}negated positive) and type of antonym (morphological vs.\text{~}lexical) was also significant: $\beta = `r round(rs1.expt2.coef["antonym_typelexical:st1","Estimate"],3)`$, $SE =  `r round(rs1.expt2.coef["antonym_typelexical:st1","Std. Error"],4)`$, t$(`r round(rs1.expt2.coef["antonym_typelexical:st1","df"], 1)`) = `r round(rs1.expt2.coef["antonym_typelexical:st1","t value"],2)`, p = `r round(rs1.expt2.coef["antonym_typelexical:st1","Pr(>|t|)"], 4)`$, suggesting that the explicit alternatives exaggerates differences in interpretation for both kinds of adjective sets.
We again find a subset of responses to the negated morphological antonym (*not unhappy*) are appreciably below the midpoint, suggesting again a small effect of politeness on interpretation. 


```{r expt1results}
load("cached_results/oneSlider_bootstrappedCIs.RData") # df.oneSlider.ci

# fig.expt1 <- ggplot(df.oneSlider.ci %>%
#                       mutate(src = 'implicit'), aes(x = antonym_type,
#                       y = mean,
#                        ymin = ci_lower, ymax = ci_upper,
#                        fill = adjective_type,
#                       group = adjective_type
#               ))+
#   geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
#   geom_errorbar(position = position_dodge(0.8), color = 'black',
#                 width = 0.4)+
#   #coord_flip()+
#   facet_wrap(~src)+
#   xlab("")+
#   #scale_fill_viridis(discrete = T, name="Adjective type")+
#   scale_fill_manual(name="Adjective type",
#                     values = orange.purple.color.palette,
#                     guide = guide_legend(reverse=TRUE))+
#   ylab("mean normalized rating")+
#   theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ))+
#   scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))

fig.expt1 <- df.oneSlider.ci %>%
  ungroup() %>%
  mutate(
    new_type = ifelse(antonym_type == "lexical", 
                           ifelse(adjective_type == "Antonym", "Negative", 
                            ifelse(adjective_type == "Negated antonym", "Negated negative", 
                                   as.character(adjective_type))), as.character(adjective_type)),
    antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
                          labels = c("negative", "antonym")),
    src = 'implicit'
      ) %>%
  ggplot(., aes(x = antonym_type,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type,
                      group = adjective_type
              ))+
  geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
  geom_errorbar(position = position_dodge(0.8), color = 'black',
                width = 0.4)+
  #coord_flip()+
  facet_wrap(~src)+
  xlab("")+
  #scale_fill_viridis(discrete = T, name="Adjective type")+
  scale_fill_manual(name="Adjective type",
                    values = orange.purple.blue.color.palette,
                    guide = guide_legend(reverse=F),
                    breaks = c("Negative", "Negated negative", 
                               "Antonym", "Negated antonym", 
                               "Positive", "Negated positive"))+
  ylab("mean normalized rating")+
  theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ),
        legend.position = 'bottom')+
  scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))

```

```{r expt2results}
load("cached_results/fourSlider_bootstrappedCIs.RData") # df.fourSlider.ci
fig.expt2 <- ggplot(df.fourSlider.ci %>%
                      mutate(src = 'explicit',
                             new_type = ifelse(antonym_type == "lexical", 
                           ifelse(adjective_type == "Antonym", "Negative", 
                            ifelse(adjective_type == "Negated Antonym", "Negated negative", 
                                   as.character(adjective_type))), as.character(adjective_type)),
                               antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
                          labels = c("negative", "antonym"))), aes(x = antonym_type,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type,
                      group = adjective_type
              ))+
  geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
  geom_errorbar(position = position_dodge(0.8), color = 'black',
                width = 0.4)+
  #coord_flip()+
  xlab("Antonym type")+
  facet_wrap(~src)+
  xlab("")+
  #scale_fill_viridis(discrete = T, name="Adjective type")+
  scale_fill_manual(name="Adjective type",
                    values = orange.purple.blue.color.palette,
                    guide = guide_legend(reverse=TRUE)
                    )+
  ylab("mean normalized rating")+
    theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ))+
  scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))
```

```{r expt-results, fig.cap="Empirical ratings for scales defined with negative-form adjectives (e.g., \"sad\") and antonyms (e.g., \"unhappy\"). A, B: Expts. 1, 2, respectively; participants rated all adjective types. C: Four between-participants conditions. Left end-points of rating scales were defined by the scale type (negative vs. antonym).", fig.env = "figure*", fig.pos = "h", fig.width=7, fig.height=3.3, fig.align = "center", set.cap.width=T, num.cols.cap=2}

load(file = "cached_results/bootstrappedCIs.RData") # d.full.boot

fig.bs.ci <- d.full.boot %>%
  ungroup() %>%
  mutate(antonym_type = factor(antonym_type, 
                               levels = c(  "lexant", "morphant"),
                               labels = c("lexical", "morphological")),
         adjective_type_rescaled = 
           factor(adjective_type_rescaled,
              levels = c("antonym", "neg_positive", "neg_antonym","positive"),
              labels = c("Antonym", "Negated positive",
                         "Negated antonym", "Positive")),
         new_type = ifelse(antonym_type == "lexical", 
                           ifelse(adjective_type_rescaled == "Antonym", "Negative", 
                            ifelse(adjective_type_rescaled == "Negated antonym", "Negated negative", 
                                   as.character(adjective_type_rescaled))), as.character(adjective_type_rescaled)),
             antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
                          labels = c("negative", "antonym"))) %>%
  ggplot(., aes(x = antonym_type,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type,
                      group = adjective_type_rescaled
              ))+
  geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
  geom_errorbar(position = position_dodge(0.8), color = 'black',
                width = 0.4)+
  #coord_flip()+
  xlab("Antonym type")+
  #scale_fill_viridis(discrete = T, name="Adjective type")+
  scale_fill_manual(name="Adjective type",
                    values = orange.purple.blue.color.palette,
                    guide = guide_legend(reverse=F),
                    breaks = c("Negative", "Negated negative", 
                               "Antonym", "Negated antonym", 
                               "Positive", "Negated positive"))+
  facet_wrap(~condition, scales = 'free', nrow = 1)+
  ylab("mean normalized rating")+
  xlab("")+
    theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ))+
  #scale_y_reverse(limits = c(1.25, -1.1), breaks = c(1, 0, -1))
  scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))

legend <- get_legend(fig.bs.ci + theme(legend.position="bottom", legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(0,0,0,0)))
prow <- plot_grid( 
  fig.expt1 + theme(legend.position="none",
                                     plot.margin = unit(c(6,0,6,0), "pt")),
   fig.expt2 + theme(legend.position="none",
                     plot.margin = unit(c(6,0,6,0), "pt")) + ylab(""),
   fig.bs.ci + theme(legend.position="none",
                     plot.margin = unit(c(6,0,6,0), "pt")) + ylab(""),
           align = 'vh',
           labels = c("A", "B", "C"),
           hjust = -1,
           nrow = 1, rel_widths = c(1,1,2)
           )
plot_grid( prow, legend, ncol = 1, rel_heights = c(1.2, .2))
```


## Experiment 3: Large-scale, within-scale replication

\text{Expts$\thinspace$1 \& 2} revealed an asymmetry between lexical and morphological antonyms. 
Whereas lexical antonyms are clearly distinguished from negated positives (e.g., *not happy*), morphological antonyms were not. 
In this experiment, we aim to replicate these findings while controlling for the semantic scale under consideration. 
Specifically, in \text{Expts.$\thinspace$1~\&~2}, our items varied both in terms of how antonyms manifested (lexical vs.\text{~}morphological) as well as the actual degree scales being described (e.g., height for *tall*/*short* vs.\text{~}happiness for *happy*/*unhappy*).
Many adjective sets have both lexical and morphological antonyms (e.g., *happy*/*unhappy*/*sad*) and we use these sets to test our hypothesis within-scale. 

## Methods

```{r expt3_subjInfo}
load("cached_results/time_summary.RData") # d.time.summary
load("cached_results/english_summary.RData") #d.full.nativeEnglish
```

### Participants

We recruited 750 participants from Amazon's Mechanical Turk (MTurk).
The experiment comprised of four between-subjects experimental conditions arranged in a 2x2 Latin Square design: *antonym type (morphological vs.\text{~}lexical)* X *alternatives (explicit vs.\text{~}implicit)*.
300 participants were assigned to each of the *implicit alternatives* conditions, and 75 participants were assigned to each of the *explicit alternatives* conditions.
These numbers follow from the intention of getting approximately 45 ratings for each unique adjective in the experiment.

Participants were restricted to those with U.S. IP addresses and at least a 95\% work approval rating. 
The *implicit alternatives* task took on average `r round(filter(d.time.summary, condition == "implicit")[[1,"aveTime"]], 1)` minutes and participants were compensated \$0.40; the *explicit alternatives* task took on average `r round(filter(d.time.summary, condition == "explicit")[[1,"aveTime"]], 1)` minutes and participants were compensated \$0.80.
In addition, participants who self-reported a native language other than English were excluded.
This exclusion criterion and our planned sample size, along with the procedure and analysis described below, were preregistered: \url{osf.io/p7f25/}.

### Materials

<!-- Our pilot testing revealed differences between lexical and morphological antonym sets (e.g., "tall"/"short" and "happy"/"unhappy"). -->

To best isolate the contribution of lexical vs.\text{~}morphological antonyms, we curated *adjective sets* consisting of words for properties of people, such that both lexical and morphological antonyms exist for the same positive-form adjective (e.g., *happy* $\rightarrow$ *unhappy*, *sad*; Table$\thinspace$3).
Lexical antonyms were selected from a set of possibilities produced from a small survey (n=18) on MTurk eliciting "opposites" for a list of 30 positive-form adjectives, which had morphological antonyms (asking participants e.g., "What is the opposite of *forgiving*?").
From the list of freely-produced opposites (the vast majority of which were not morphological antonyms), the first author chose the one that intuitively best conveyed the same scalar dimension as the morphological antonym and which was not already used as a lexical antonym for another item (e.g., opposite of *forgiving* $\rightarrow$ *resentful*; opposite of *kind* $\rightarrow$ *cruel*, because opposite of *friendly* $\rightarrow$ *mean*).
Ten out of the original 30 items were dropped for not having such a well-suited lexical antonym (e.g., *moral*) or for having a well-suited lexical antonym that conflicted with another item (e.g., *compassionate* $\rightarrow$ *cold*, but also *affectionate* $\rightarrow$ *cold*).

<!-- For a list of the 20 positive-adjectives and their lexical and morphological antonyms used in the experiment, see Table \@ref(tab:items). -->

<!-- We used **adjective sets** of size 6 composed of positive-form gradable adjectives (\textsc{POS}; e.g., *happy*), their negation (\textsc{NEG POS}; e.g., *not happy*), antonyms constructed by altering the morphology of the adjective (\textsc{MORPH ANT}; e.g., *unhappy*), anotnyms with a distinct lexical entry (\textsc{LEX ANT}; e.g., *sad*) and their respective negations (e.g., *not unhappy*, *not sad*). -->
<!-- Antonyms were either created by morphological negation (\emph{morphological antonyms}; e.g., *unhappy* for *happy*) or were distinct lexical entries (\emph{lexical antonyms}; e.g., *short*, for *tall*). -->
<!-- All adjectives were individual-level predicates that applied to people; items were constructed from an informal survey of the linguistics literature and taken from list of *common opposites* available online\footnote{http://www.enchantedlearning.com/wordlist/opposites.shtml} (for a full list, see \tableref{tab:items}. -->


```{r items, results="asis"}
load(file = "cached_results/item_table.RData")
print(tab1, type="latex", comment = F, table.placement = "H", size="\\fontsize{9pt}{10pt}\\selectfont", include.rownames=FALSE)
```

### Procedure



<!-- Participants rated adjective sets made with either lexical or morphological antonyms. -->
<!-- In addition, participants provided ratings with alternative utterances either explicit or implicit.  -->

The procedure was similar to that of \text{Expts.$\thinspace$1~\&~2}.
<!-- On each trial, participants read a statement introducing a character using a gradable adjective of one of four **adjective types** (e.g., "Greg is \{POS, ANT, NEG POS, NEG ANT\}"). -->
<!-- Participants were asked rate the character on a scale from "the most POS person in the world" to "the most ANT person in the world", using a slider bar (\figref{fig:expt1}). -->
<!-- In the *lexical antonyms* conditions, ANT (and NEG ANT) were antonyms with distinct lexical entries (e.g., "sad", "not sad" for POS = "happy"). -->
<!-- In the *morphological antonyms* conditions, ANT (and NEG ANT) were antonyms created by adding a negation-inducing prefix (e.g., "unhappy", "not unhappy" for POS = "happy"). -->
In the *implicit alternatives* conditions, participants rated one sentence at a time (e.g., *Greg is not unhappy*), each from a unique adjective set (e.g., never rated both *unhappy* and *not happy*), completing a total of 12 trials, with exactly 3 repetitions of each adjective type (\textsc{pos}, \textsc{ant}, \textsc{neg pos}, \textsc{neg ant}).
In the *explicit alternatives* conditions, participants completed 12 trials, rating four sentences at a time from the same adjective set.
In contrast to the first two experiments, *antonym type* (morphological vs.\text{~}lexical) was a between-participants manipulation.
As well, the end-points for slider bars used in the "...*in the world*" label of \text{Expt.$\thinspace$2}.

<!-- Again, there were 12 trials. -->

## Results 

```{r loadRegressionResults}
load("cached_results/regression_antTypeXadjType_implicitCond.RData") # rs1.helmert.implicit.summary
load("cached_results/regression_adjTypeXcontext_morph.RData") #rs2.helmert.morph.summary
load("cached_results/regression_antTypeXadjTypeXcontext.RData") # rs3.3way.summary
rs1.implicit.coef <- rs1.helmert.implicit.summary[["coefficients"]]
rs2.morph.coef <- rs2.helmert.morph.summary[["coefficients"]]
rs3.3way.coef <- rs3.3way.summary[["coefficients"]]
```

`r sum(!d.full.nativeEnglish$englishNative)` participants were excluded for self-reporting a native language other than English, leaving a remainder of `r sum(d.full.nativeEnglish$englishNative)` participants for these analyses.

As we did in \text{Expt.$\thinspace$1}, we evaluate our hypothesis that lexical antonyms behave like the *bonafide antonyms* model (i.e., show a true ordering) and morphological antonyms behave like predicted by the *uncertain parsing* model (i.e., show a partial ordering). To do so we considered data only from the *implicit alternatives* conditions \mf{check me if that is true} and built a mixed-effects regression model with by-participant and by-item random effects of intercept and adjective type.
\mf{Please state more clearly what the model is. Predicting normalized slider ratings in terms of fixed factors XYZ and random intercepts for XYZ, as well as random slopes XYZ. I don't understand what "adjective type" should do in a random effect structure because it is a between-subject factor??}
Consistent with this hypothesis, the interaction between negation type (antonym vs.\text{~}negated positive) and type of antonym (morphological vs.\text{~}lexical) was significant: $\beta = `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","Estimate"],3)`$, $SE =  `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","Std. Error"],4)`$, t$(`r round(rs1.implicit.coef["antonym_typelexant:adj_type1","df"], 1)`) = `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","t value"],2)`, p = `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","Pr(>|t|)"], 4)`$. \mf{We should mention what the coding of factor levels was; only for some coding schemes could this result be interpretable for our purposes. Also, even then we need more than just a significant interaction here. To argue that the predictions of the full uncertainty model are correct, we would need to say, e.g., that with morphological antonym as reference level for factor \emph{antonym type} and antonym as reference level for \emph{adjective type} there is no significant difference for factor level "negated antonym" of \emph{adjective type}.}

<!-- One first hypothesis concerns the interpretation of morphological antonyms vs.\text{~}lexical antonyms in the absence of explicit alternatives (Figure$\thinspace$\ref{fig:experiment-slides}A). -->
<!-- We predict an interaction between type of negation (antonym vs.\text{~}negated positive) and type of antonym (morphological vs.\text{~}lexical). -->
<!-- Specifically, we predict that interpretations of lexical antonyms will be more negative than negated positives (e.g., somebody who is "sad" is less happy than someone who is "not happy"), whereas there will be no difference between morphological antonyms and negated positives (e.g., "unhappy" = "not happy"). -->


Our second main hypothesis is that context (implicit vs.\text{~}explicit alternatives) modulates the interpretive difference between antonyms and negated positives, at least within morphological antonyms (e.g., *unhappy*). 
Specifically, we predict that morphological antonyms will be interpreted more negatively (i.e., more strongly in the negative direction) than negated positives (e.g., *not happy*) when the alternatives are explicit, which would manifest as an interaction between negation type (antonym vs.\text{~}negated positive) and context (implicit vs.\text{~}explicit alternatives).
To evaluate this hypothesis, we considered the full data set \mf{check me if that is true} and built a mixed-effects regression model with by-participant random effects of intercept and by-item random effects of intercept and adjective type.\mf{same as above: model specification unclear}
This interaction was also significant: $\beta = `r round(rs2.morph.coef["conditionexplicit:adj_type1","Estimate"],3)`$, $SE =  `r round(rs2.morph.coef["conditionexplicit:adj_type1","Std. Error"],4)`$, t$(`r round(rs2.morph.coef["conditionexplicit:adj_type1","df"], 1)`) = `r round(rs2.morph.coef["conditionexplicit:adj_type1","t value"],2)`, p = `r format(rs2.morph.coef["conditionexplicit:adj_type1","Pr(>|t|)"], digits = 3, scientific = T)`$. \mf{We would need more to show that this effect goes in the right direction; but here we might also just point to the plots?}

Finally, as an exploratory analysis we test the 3-way interaction between negation type (antonym vs.\text{~}negated positive), antonym type (morphological vs.\text{~}lexical), and context (implicit vs.\text{~}explicit), using a mixed-effects model with by-participant and by-item random effects of intercept and adjective type.
The 3-way interaction was not significant but numerically in the right direction:
$\beta = `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","Estimate"],3)`$, $SE =  `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","Std. Error"],4)`$, t$(`r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","df"], 1)`) = `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","t value"],2)`, p = `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","Pr(>|t|)"], 4)`$

# Discussion

Many dimensional scales are without units.
Speakers cannot say they are *42 units happy* like they can say they *6'1" tall*.
Instead, speakers can use modifiers and alternative utterances to carve more precise meanings from otherwise vague dimensions. 
Someone said to be *not unhappy* is neither sad nor truly happy, but residing in some marginally positive state that is difficult to refer to because degrees of happiness lack precise units.
\mht{$\leftarrow$ well... *somewhat happy* also allows you to refer to that region}

This work resolves an outstanding puzzle in natural language understanding.
@Krifka2007:Negated-antonyms critiques previous pragmatic theories for either being underdetermined [@Blutner2004:pragmatics] or making the wrong prediction [@Horn1991:Duplex]. 
Using state-of-the-art models of pragmatic language understanding, we are able to precisely articulate the division of pragmatic labor between different utterances available to a speaker for conveying negation.
We hypothesized that uncertainty about the meaning of overt negation markers leads only to a partial ordering of antonyms and their negations when the role of the antonym is filled by affixal negation (e.g,. *not unhappy*). 
It is noteworthy that we are able to recover the ordering predicted by @Krifka2007:Negated-antonyms even when the model has uncertainty about the meaning of particle negation (e.g., *not happy*) when a lexical antonym was an alternative utterance.
\mht{note also that we don't assume any ordering on interpretations in the semantics for bonafide antonyms. note null utterance? \mf{maybe footnote if we have the space?}}

Our formalization of lexical uncertainty about the meaning of natural language negation is consistent with a growing movement in theories of language to treat the lexicon (the meaning of words) as not totally separable from the combinatorial rules of grammar [e.g., @bybee2006usage].
The two types of negation meaning we considered---contrary and contradiction opposition---correspond to a *lexicalized* form of oppositition and a *compositional* rule, respectively. 
Thus, our model can be seen as an instance of the balance between productivity and reuse [e.g., @Odonnell2015productivity].
\mf{I don't understand this. But I'm not unhappy to have it in here. Maybe elaborate?}
A further test of our negation uncertainty model would be to see if usage-based metrics (e.g., frequency) correlated with the asymmetries explored here, namely the interpretative difference between an affixal negation and particle negation.

\mht{politeness, further inferences? (not unhappy -- *normally unhappy in this situation*)}
  
# Acknowledgements

This work was supported in part by NSF Graduate Research Fellowship DGE-114747 to MHT.


<!-- Should we parse both types of negation compositionally, then indeed they have same meanings. However, language has the ability to create new lexical entries, with the tokenization of new semantic variables. For instance, \*not tall\* does not imply \"short\" because tall and short have different truth-conditional criteria. -->
    



<!-- To negate is to make true false, but what of statements that are truly vague? When meanings are underspecified, the behavior of negation is not so obvious. If a person is \"not happy\", does that entail they are \"unhappy\"? Natural language provides two kinds of negation: contrary (e.g., not happy) and contradiction (e.g., sad), yet additional forms exist (e.g., unhappy). Are the additional forms redundant, or do they allow speakers, with the help of context, to more finely carve otherwise vague meanings? We investigate basic inferences from natural language negation and double negation by elaborating a computational model of gradable adjective interpretation to handle different kinds of negation. We hypothesize that communicative reasoning and an uncertain *parsing model* combine for listeners to extract fine-grained meanings within vague dimensions. This hypothesis is borne out in, to our knowledge, the first experimental evidence concerning adult interpretation of different kinds of and double negation. -->


# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
