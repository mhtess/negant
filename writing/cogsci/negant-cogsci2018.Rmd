---
title: "Not unreasonable: Carving vague dimensions with contraries and contradictions"
bibliography: negant.bib
csl: apa6.csl
document-params: "10pt, letterpaper"
header-includes:
  - \usepackage{tabularx}
  - \usepackage{multicol}
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \usepackage{booktabs}
  - \usepackage{caption}
  - \setlength{\belowcaptionskip}{-0.4cm} 
  
author-information: > 
  \author{{\large \bf Michael Henry Tessler (mhtessler@stanford.edu)} \\ Department of Psychology, Stanford University 
  \AND {\large \bf Michael Franke (mchfranke@gmail.com)} \\ Department of Linguistics, University of T\"{u}bingen}

abstract: 
    "Language provides multiple ways of conveying the opposite: A person *not happy* can be *unhappy*, *sad*, or perhaps neither, just *not happy*. Rather than being redundant, we hypothesize that uncertainty about the meaning of negation markers allows listeners to derive fine-grained distinctions among these various alternatives. We formalize this hypothesis in a probabilistic model of gradable adjectives (e.g., *happy*), and use this to address an outstanding puzzle: how to interpret double negations (e.g., *not unhappy*). Our model makes surprising additional predictions about a putative difference between antonyms created by affixal negation (*unhappy*) and negated positives (*not happy*): when forms are presented in isolation, we predict no interpretation difference; when confronted with the whole set of alternatives, listeners should judge *unhappy* as more sad than *not happy*. Two behavioral experiments confirm consistent orderings of interpretations that interact with the presentational context in the way predicted. These findings support the hypothesis that listeners represent uncertainty about the most logical element of language: negation. "

keywords:
    "semantics; pragmatics; negation; Bayesian cognitive model; Rational Speech Act"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(cowplot)
library(tidyr)
library(dplyr)
library(magick)
library(ggthemes)
library(formatR)
library(bitops)
library(caTools)
library(png)
#library(viridis)
theme_set(theme_few())
orange.purple.color.palette <- 
  #c("#fdb863", "#5e3c99", "#e66101", "#b2abd2")
  c( "#b2abd2", "#e66101", "#5e3c99","#fdb863")
orange.purple.blue.color.palette <- 
  #c("#fdb863", "#5e3c99", "#e66101", "#b2abd2")
  c("#74a9cf", "#0570b0","#5e3c99",  "#e66101", "#b2abd2","#fdb863")
```

```{r expt3_subjInfo, cache = F}
load("cached_results/time_summary.RData") # d.time.summary
load("cached_results/english_summary.RData") #d.full.nativeEnglish
```

\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}
\newcommand{\tableref}[1]{Table$\thinspace$\ref{#1}}
\newcommand{\figref}[1]{Fig.$\thinspace$\ref{#1}}
\newcommand{\appref}[1]{Appendix \ref{#1}}
\newcommand{\sectionref}[1]{Section \ref{#1}}
\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}
\definecolor{grey}{RGB}{40,40,40}

\newcommand{\red}[1]{\textcolor{Red}{#1}}  
\newcommand{\mf}[1]{\textcolor{Green}{[mf: #1]}}  
\newcommand{\mht}[1]{\textcolor{Blue}{[mht: #1]}} 

\newcommand{\wrapmf}[1]{#1}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
  
  
<!-- title: "Not unreasonable: Conveying the opposite and its opposite" -->
<!-- title: "Not unreasonable: Carving vague dimensions with contraries and contradictions" -->

# Introduction

<!-- If "Jones is happy" you understand that Jones' happiness -- a *gradable property* -- exceeds a certain threshold, which depends on the context and prior expectations about Jones' likely happiness [@kennedy2005scale; @Kennedy2007]. -->
<!-- But what about the compositional "Jones is not unhappy"?  -->
<!-- Do the two negatives make a positive? -->
If "Jones is not unhappy", does that mean that Jones is happy?
@Jespersen1924 believed not:

\begin{quote}
\footnotesize
[T]wo negatives do not exactly cancel one another [$\ldots$]; the longer expression is always weaker: ``this is not unknown to me'' or ``I am not ignorant of this'' means ``I am to some extent aware of it,'' etc. (p.$\thinspace$332)
\end{quote}

*Negated antonyms* (e.g., *not unhappy*) are thought to occupy a particular region of their associated scale (e.g., happiness), below  *positive adjectives* (*happy*) but above *negated positives* (*not happy*) and *antonyms* (*unhappy*) [Fig.$\thinspace$\ref{fig:happy-scale}; @Krifka2007:Negated-antonyms].
<!-- What is the logic of natural language negation such that two negatives don't make positive? -->
<!-- How negated antonyms are interpretated as slightly positive, or even that they are as @Jespersen1924 suggests, is a matter of some controversy. -->
A straight-forward, compositional analysis, however, would map morphological negation via affixation (e.g., *un-*) and negation particles (e.g., adverbial *not*) to proposition-level negation ($\neg$) of modern standard logic. 
Such a logically-transparent theory would predict that the two overt negation markers cancel each other out: *not unhappy* means $\neg \neg \textit{happy}$, or just *happy*.
@orwell1946politics voices this opinion:

\begin{quote}
\footnotesize
Banal statements are given an appearance of profundity by means of the ``not un-'' formation. [$\ldots$] It should be possible to laugh the ``not un-'' formation out of existence by memorizing this sentence: ``A not unblack dog was chasing a not unsmall rabbit across a not ungreen field.'' (p.$\thinspace$357)
\end{quote}

Alternatively, morphological antonyms (*unhappy*) could behave like lexical antonyms (*sad*) which seem clearly to express *contrary opposition*. 
Contraries cannot both be true but they can both be false [@Horn1989:Natural]: Jones may be neither happy nor sad, neither tall nor short. 
*Not unhappy*, then, would compete with *happy* as a pragmatic alternative and so would be contextually strengthened to a more specific interpretation, namely to a neutral or indifferent state [@Horn1991:Duplex], contra @Jespersen1924's intuition that *not unhappy* is a slightly positive state.
It's been noted that *not happy* should also be an alternative [@Blutner2004:pragmatics], but how pragmatics contextually strengthens *not happy* has yet to be fully spelled out [@Krifka2007:Negated-antonyms].
Furthermore, the meaning of *not happy* is at least as controversial as that of *unhappy*: @Jespersen1917:Negation and @Blutner2004:pragmatics argue that the two are basically identical in meaning, while @Krifka2007:Negated-antonyms cites examples like the following (taken from the internet):

\begin{quote}
\footnotesize
It's an absolutely horrible feeling to be unhappy, and I don't even think I was unhappy, just not happy, if you know what I mean. 
\end{quote}


```{r happy-scale, fig.pos = "t", fig.align = "center", fig.cap="Possible ordering of antonyms and their negations."}
happy_scale <- png::readPNG("img/happy-scale.png")
grid::grid.raster(happy_scale)
```

```{r old2_happy-scale, fig.height=2, fig.width=3.5, fig.align = "center", eval = F, fig.cap="Possible ordering of antonyms and their negations."}
happy.scale <- data.frame(
  adjective = c("happy", "not unhappy", "not happy", "unhappy"),
  low = c(0.75, 0.5, 0.25, 0),
  high = c(1, 0.75, 0.5, 0.25),
  x = 1,
  y = c(0.875, 0.625, 0.375, 0.125)
) %>%
  mutate(adjective = factor(adjective, levels = c("happy", "not unhappy", "not happy", "unhappy")))

ggplot(happy.scale, aes(x = x, y=y, ymin = low, ymax = high, color = adjective,
                        label = adjective))+
  geom_linerange(size = 5)+
  scale_color_manual(name="Adjective",
                    values = orange.purple.color.palette,
                    guide = guide_legend(reverse=TRUE))+
  coord_flip()+
  geom_label(x = 1.015, label.size = 0.5, size = 3)+
  guides(color = F)+
  scale_y_continuous(limits = c(0,1), breaks = c(0, 1))+
  scale_x_continuous(limits = c(0.9, 1.1))+
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        panel.border = element_blank())
```

<!-- Negation is the semantic operation of forming an opposite, but there are multiple kinds of semantic opposition -->
<!-- A *contrary* opposition is one where both predicates cannot be true at the same time, but both can be false. -->
<!-- <!-- "Happy" (a *positive* adjective) and "sad" (a *negative* adjective) or "polite" and "rude" are two such examples: it is conceivable that Jones is neither happy nor sad, but in a neutral middle ground. -->
<!-- In contrast, a *contradictory* opposition (e.g., *even/odd* positive integer), is one where falsity of one predicate entails truth of the other. -->
<!-- "Not happy" (a *negated positive*) or "unhappy" (an *antonym*) seem like good contenders to express contradictory opposition because each maps transparently to proposition-level negation ($\neg$) in modern standard logic.^[ -->
<!--   While "sad" is of course also an antonym of "happy", we speak of *negative* and *positive* adjectives, and reserve *antonym* for antonyms created by affixal negation (e.g., "un-").  -->
<!--   Also, we use *particle negation* or *negated X* for negation formed by "not" over the more accurate "adverbial negation". -->
<!--   We use a somewhat idiosyncratic terminology so as to be concise in the distinctions most relevant for this paper. -->
<!-- ] -->
<!-- If this is so, however, combining the two contradictory devices should cancel each other out: "not unhappy" means "happy". -->
<!-- Alterantively, antonyms created by affixal negation (*un-*, *in-*, etc.) could form a contrary, like a negative adjective. -->

<!-- Here is an instance of an attested difference in meaning between negated positives and morphological antonyms (e.g., *not happy* and *unhappy*), taken from @Krifka2007:Negated-antonyms, taken from internet: -->


<!-- This example suggests that at least in the context of explicit alternative utterances (*not unhappy just not happy*), antonyms and negated positives can take on distinct meanings, even if they may not in isolation. -->
How does such a logical linguistic device---negation---give rise to a multiplicity of meanings?
We posit that uncertainty about the meaning of overt negation markers (*un-*, *not*) interacts with communicative reasoning principles to give rise to fine-grained interpretations in the moment.
We propose a probabilistic model of pragmatic reasoning in the Rational Speech Act tradition [@Franke2015a; @Goodman2016:RSA], combining previous work on gradable adjectives [e.g., *tall*; @Lassiter2015; @Qing2014:Adjectives] with elements of lexical uncertainty [@Bergen2016].
Our model interprets *not unhappy* as a slightly positive state and predicts qualitative differences between morphological antonyms (e.g., \{*happy*, *unhappy*\}) and lexical antonyms which lack overt negation markers (e.g., \{*tall, short*\}).
These differences are shown to be sensitive to the presence of explicit alternative utterances, as exists in Krifkas's example above. 
We compare model predictions to novel data from two experiments that measure interpretations for different kinds of adjectives in different contexts, uncovering subtle but reliable differences.
<!-- These findings suggest that uncertainty in logical meanings can be exploited by pragmatic reasoning to signal fine-grained meaning on otherwise vague dimensions.  -->

<!-- \noindent We did not find such a difference in our experiment, but rather than conclude that no differnce exists, we note that the speaker in this example utterance chose to use both *unhappy* and *not happy* in the same utterance.  -->
<!-- We hypothesize that explicit comparisons between alternative utterances can draw out the difference in meaning between negated positives and morphological antonyms, which leads the morphological antonym to behave more like a bonafide antonym. -->

<!-- Given the manifold interpretations of antonyms and particle negation, we hypothesize that listeners represent these possibilities as uncertainty in meaning of overt negation markers and resolved it in context. -->
<!-- We propose a probabilistic speaker-listener pragmatic reasoning model in the Rational Speech Act tradition [@Franke2015a; @Goodman2016:RSA],  to model the indeterminacy about how to interpret overt negation markers.  -->
<!-- We combine previous work deriving interpretations for gradable adjectives by considerations of cooperative language use [@Lassiter2015; @Qing2014:Adjectives] with elements of lexical uncertainty [@Bergen2016]. -->
<!-- We compare model predictions to novel data from three experiments that measure interpretations for positive and negative adjectives (*happy*/*sad*) as well as antonyms (*unhappy*) and particle negations (*not happy/sad/unhappy*) in different contexts, uncovering subtle but reliable differences. -->
<!-- These findings suggest that pragmatic reasoning can utilize uncertainty in logical meanings to derive finer-grained interpretations through the competiton of multiple interpretations of multiple alternative utterances. -->
<!-- \mht{this last sentence is a behemoth \mf{is that a good thing? from Wikipedia: "Metaphorically, the name has come to be used for any extremely large or powerful entity."}}\mht{strictly speaking: I prefer my mythical creatures in metaphorically bite-size chunks} -->

<!-- In Experiment 1, we measure uncover this ordering for antonym pairs defined with unique lexical items (e.g., *tall*/*short*) but not for morphological antonyms (e.g., "happy"/"unhappy").  -->
<!-- In Experiment 2, we show that morphological antonyms to create a reliable ordering when context clearly provides a speaker's alternatives utterances. -->
<!-- In a large-scale, preregistered study, we replicate these findings within sets of adjectives that allow both lexical and morphological antonyms (e.g., "happy" / "unhappy" / "sad").  -->


<!-- Classical, bivalent logic mandates that two negatives make a positive, but speakers can use double negation (e.g., "not" + "un-" + "reasonable") in a non-redundant manner. -->
<!-- As @Jespersen1924 noted: -->

<!-- > The two negatives do not exactly cancel one another... the longer expression is always weaker: "this is not unknown to me" or "I am not ignorant of this" means *I am to some extent aware of it*, etc. -->

<!-- This intuitions is surely shared for *negated antonyms* (e.g., "not sad") and is predicted to carve the underlying semantic scale is a relatively stable ordering: "sad" $<$ "not happy" $<$ "not sad" $<$ "happy" [@Horn1989:Natural; @Krifka2007:Negated-antonyms]. -->
<!-- But creating an opposite meaning through an *affixed morpheme* (e.g., "un-") does not unambiguously create an antonym. -->
<!-- As @orwell1946politics noted:  -->

<!-- > Banal statements are given an appearance of profundity by means of the "not un-" formation... It should be possible to laugh the "not un-" formation out of existence by memorizing this sentence: "A not unblack dog was chasing a not unsmall rabbit across a not ungreen field." -->



<!-- The answer to how listeners interpret different kinds of opposing meanings lies at the intersection between compositional semantics and vague language understanding. -->
<!-- We draw inspiration from usage-based theories of grammar \red{(cite: ODonell2015, Bybee 2011?)} to introduce uncertainty about how to parse *morphological antonyms* (e.g., "unhappy") into a probabilistic model of gradable adjective understanding.  -->
<!-- This *uncertain parser* model includes, as a special case, a sub-model that interprets antonyms and their negations, producing the hypothesized ordering (Figure 1). -->
<!-- In Experiment 1, we measure uncover this ordering for antonym pairs defined with unique lexical items (e.g., "tall"/"short") but not for morphological antonyms (e.g., "happy"/"unhappy").  -->
<!-- In Experiment 2, we show that morphological antonyms to create a reliable ordering when context clearly provides a speaker's alternatives utterances. -->
<!-- In a large-scale, preregistered study, we replicate these findings within sets of adjectives that allow both lexical and morphological antonyms (e.g., "happy" / "unhappy" / "sad").  -->
<!-- These findings suggest that pragmatic reasoning can utilize the tension between parsing utterances compositionally (e.g., "un-" + "happy") and interpreting them holistically ("unhappy") to derive fine-grained meanings in-the-moment. -->


<!-- We hypothesize that the conflict in the literature surrounding  -->


<!-- In logic, two negatives make a positive, but the same does not seem to hold in natural language.  -->
<!-- Somebody "not sad" is not necessarily "happy".  -->
<!-- "Sad" is an antonym, whereas the particle "not" simply negates the positive "happy". -->



<!-- Instead, antonyms and their negations appear to partition the underlying semantic scale in an ordering:  We show how this semantic ordering falls out of an information-theoretic model of adjective interpretation, without assuming that *unhappy* $<$ *happy*. We then empirically investigate the semantic ordering, finding that the ordering appears when participants are fully aware of the utterances a speaker could say for antonym pairs defined by morphological negation (*[un]happy*); the explicit presentation of alternatives is not necessary for the analogous ordering of antonym pairs of distinct lexical items (*tall* / *short*). These findings suggest a model of interpretation where listeners maintain uncertainty about the parsing of an utterance involving multiple negations." -->


<!-- , derive this intuitive ordering which we validate in an expt. -->


<!-- Jespersen's intuition is not universally shared, however.  -->
<!-- "Not" and "un-" can be two ways of saying the same thing.  -->
<!-- "Not unreasonable" might mean "reasonable". -->


<!-- Why does language provide multiple, seemingly identical ways of conveying the same meanings? -->
<!-- Classical logic distinguished statements that are contrary to one another (e.g., *antonyms*; "Sam is happy" vs. "Sam is sad") and those that are contradictory (e.g., using *negation particles*: "Sam is *not* happy"). -->
<!-- For Jespersen's intuition to hold, "unhappy" (*morphene negation*) must be a *contrary*, like "sad".  -->
<!-- Then, "not unhappy" can receive a restricted interpretation via its literal meaning and pragmatic competition with "happy" [@Horn1991:Duplex; @Horn1993:Economy]. -->
<!-- This model, however, renders "not unhappy" as neutral or indifferent, contrary to the intuition that "not unhappy" is a slightly positive state [@Krifka2007:Negated-antonyms]. -->



<!-- \mht{Recent breakthroughs in the probabilistic modeling tradition have put this within grasp.} -->
<!-- We use the tools of probabilistic pragmatics to formalize how negated and antonymous meanings should produce an ordering on interpretations: *sad* $<$ *not happy* $<$ *not sad* $<$ *happy*. -->
<!-- We then investigate the ordering with *morpheme negation* (e.g., "unhappy"), providing empirical evidence that it is treated the same as *particle negation* (e.g., "not happy") when the relevant alternative utterances are not salient to the listener. -->
<!-- We hypothesize that *parsing uncertainty* underlies this interpretative behavior idiosyncractic to morpheme negation. -->


<!-- - There are two kinds of negation. -->
<!-- - They can be used together while not cancelling out.  -->
<!-- - Yet more forms exist: unhappy. -->
<!--   - morphological antonyms have been of particular interest for their underspecification inmeaning (conflicting intuitions) -->
<!--   - we hypothesize that the conflict in the literature can be attributed to an uncertain parse of morphological negation. -->
<!-- - We formalize this hypothesis in a model of gradable adjectives. As a special case of this model, when there is no uncertainty about parsing, the model reduces to a model of antonyms and negations, which predicts a precise ordering. Instead the uncertain parse model does not differentiate between two kinds of negation. We thus predict an interaction between parsing uncertainty and the difference between antonymous negation and particle negation. -->

<!-- \mht{mention ordering?} -->

<!-- underespecified meanings for gradable adjectives interacts with negation to produce  -->
<!-- Probabilistic models of pragmatic reasoning have proved useful in formalizing the vagueness of gradable adjectives [e.g., "happy"; @GoodmanLassiter2015-handbook], and we adopt this formalism to better understand  -->
<!-- A speaker can use a particle (e.g., "not happy"), affix a morpheme (e.g., "unhappy"), or say an antonym (e.g., "sad") -->
<!-- Contra classical logic, however, these two ways of employing negation *do not* cancel each other out: someone "not unhappy" is not necessarily happy. -->

```{r old-happy-scale, fig.cap="Hypothesized ordering of sets of antonyms and their negations.", eval=F}
ggdraw() + draw_image("img/happy-scale.pdf") +
  theme(plot.margin = unit(c(0,0,0,0), "pt")) 
```

<!-- The plot thickens when we consider that lexically-distinct words also provide antagonistic meanings: "" -->

<!-- These two issues motivate our current approach. -->
<!-- First, competing intuitions concerning the meaning of what we will here call *particle negation* ("not happy") and *affix negation* ("unhappy") suggest that empirical data should be consulted before further theorizing about pragmatic mechanisms. -->
<!-- Second, the fact that the mechanisms of pragmatic strengthening of particle negation are not clear suggests a benefit from a formal modeling approach.  -->
<!-- We first elaborate a computational model of adjective interpretation to include antonyms and their negations: adjectives (e.g., "happy"), their antonyms (e.g., "sad"), and the negations of each ("not happy", "not sad"). -->
<!-- We then formalize a hypothesis that natural language negation passes through a probabilistic parsing model, which provides a novel prediction about the interpretations of different kinds of negation (e.g., "not happy", "unhappy", "sad"). -->
<!-- In a behavioral experiment, we investigate the hypothesized ordering of antonym quartets for antonyms with distinct lexical entries (e.g., "tall" and "short") and antonyms constructed by affix negation (e.g., "happy" and "unhappy"). -->

<!-- \begin{figure}[h] -->
<!-- \vspace{-2.5cm} -->
<!-- \includegraphics[width = \columnwidth]{figs/happy-scale-1}  -->
<!-- \vspace{-3cm} -->
<!-- \caption[Hypothesized ordering of sets of antonyms and their negations]{Hypothesized ordering of antonyms and negations.}\label{fig:happy-scale} -->
<!-- \end{figure} -->

# Computational model


Negation is the semantic operation of forming an opposite, but there are multiple kinds of semantic opposition.
A *contrary* opposition is one where both predicates cannot be true at the same time, but both can be false (e.g., *tall* and *short*).
A *contradictory* opposition is one where the falsity of one predicate entails the truth of the other  (e.g., *even/odd* positive integer).
We posit that listeners have uncertainty about whether negation markers (*not*, *un-*) express contradictory or contrary opposition, and examine its effect on the interpretation of negated gradable adjectives (e.g., *tall*, *happy*).

Formal linguistic theories capture the meaning of gradable adjectives as a threshold function: $\denote{happy} = \lambda e \thinspace . \thinspace \text{happiness}(e) > \theta$, whose threshold variable $\theta$ is supplied by the context [@Kennedy2007]. 
Here, we introduce contrary and contradictory negations into a pragmatic model that reasons about a speaker's likely values for $\theta$ [@Lassiter2015]. 
Formally, if $Hx$ expresses that $x$ is happy, contradictory opposition is standard, bivalent, proposition-level negation $\neg Hx$.
Contrary opposition is a predicate-forming operation $\tilde{H}x$ which introduces its own free threshold $\theta_{\tilde{H}}$ for gradable predicates.
The latter is not iterable [@Horn1989:Natural; @sep-negation], so while it makes sense to iterate $\neg \neg Hx$, it is impossible to iterate contrary negation. 
<!-- It is, however possible, to have $\neg \tilde{H}x$.  -->
<!-- But it is not possible to have $\neg$ in the scope of $\tilde{H}x$. -->
As a result, *not happy* and *unhappy* can be construed as either $\neg Hx$ or $\tilde{H}x$, while *not unhappy* may be $\neg \neg Hx$ or $\neg \tilde{H}x$ (Fig.$\thinspace$\ref{fig:lexicon-model}).
<!-- Negative adjectives (e.g., "short", discussed later) have no overt negation marker, and thus are assumed to be contraries $\tilde{H}x$, which receive their own thresholds $\theta_{\tilde{H}}$. -->

<!-- \begin{table}[b] -->
<!--   \vspace{-0.25cm} -->
<!--   \centering -->
<!--   \footnotesize -->
<!--   \begin{tabular}{ll} -->
<!-- 	\textbf{expression} & \textbf{interpretation options} \\ \midrule -->
<!--     \emph{not happy} / \emph{unhappy} & $\lambda e \thinspace . \thinspace \neg (\mathit{happiness}(e) > -->
<!--     \theta_{h})$ \\ -->
<!--     & $\lambda e \thinspace . \thinspace \mathit{happiness}(e) < -->
<!--     \theta_{\tilde{h}}$ \\ \midrule -->
<!--     \emph{not unhappy} & $\lambda e \thinspace . \thinspace \mathit{happiness}(e) > -->
<!--     \theta_{h}$ \\ -->
<!-- 		& $\lambda e \thinspace . \thinspace \neg(\mathit{happiness}(e) < -->
<!--     \theta_{\tilde{h}})$ \\  -->
<!--   \end{tabular} -->
<!--   \caption{Logically possible interpretations of negated expressions.} -->
<!--   \label{tab:Interpretations} -->
<!-- \end{table} -->

Listener uncertainty about the interpretation of negation markers can be modeled as uncertainty about the speaker's lexicon $\mathcal{L}$ [@Bergen2016].
We combine this technique with the model of @Lassiter2015 that derives plausible thresholds $\theta$ for gradable adjective interpretation:

\vspace*{-0.5cm}
\begin{align}
L_{1}(x, \theta, \mathcal{L} \mid u) &\propto S_{1}(u \mid x, \theta, \mathcal{L}) \cdot P(x) \cdot  P(\theta) \cdot P(\mathcal{L}) \label{eq:L1} \\
S_{1}(u \mid x, \theta, \mathcal{L}) &\propto \exp{(\alpha \cdot \ln {L_{0}(x \mid u, \theta, \mathcal{L})} - \text{cost}(u))} \label{eq:S1}\\
L_{0}(x \mid u, \theta, \mathcal{L}) &\propto \mathcal{L}(u, x, \theta) \cdot P(x) \label{eq:L0}
\end{align}


```{r lexicon-model, fig.pos = "b", fig.cap="Hypothesis space of lexica for the \\emph{uncertain negation} model. The hypothesis space is restricted to the interpretations that are circled for the \\emph{logical negation} and \\emph{bonafide contraries} model."}
# cowplot::ggdraw() +  
#   cowplot::draw_image("img/lexicon-model.pdf", scale = 1.3) +
#   theme(plot.margin = unit(c(0,0,0,0), "pt"))
img <- png::readPNG("img/lexicon-model.png")
grid::grid.raster(img)
```

Eqs.$\thinspace$\ref{eq:L1}-\ref{eq:L0} are a Rational Speech Act (RSA) model, a recursive reasoning model wherein a pragmatic listener $L_{1}$ tries to resolve the intended meaning of an utterance $u$ (e.g., "Jones is not unhappy") by combining its prior beliefs about the degree of Jones' happiness $P(x)$, with the generative process of the utterance, a speaker model $S_1$.
The speaker model $S_1$ describes an approximately rational agent (with degree of rationality $\alpha$) trying to inform a naive listener $L_0$ about the degree $x$.
<!-- In the context of adjective interpretation, the state of the world is given by the value of the scalar degree $x$ (e.g., the height of the referent). -->
The literal listener $L_0$ updates its prior beliefs $P(x)$ via an utterance's literal meaning in lexicon $\mathcal{L}$, 
where $\mathcal{L}(u, x, \theta)$ gives the truth-value of $u$ in lexicon $\mathcal{L}$ applied to state $x$ under threshold $\theta$.
The pragmatic listener has uncertainty about $\theta$, which comes from an uninformed prior and is resolved by jointly reasoning about the likely degree $P(x)$, the likely lexicon $P(\mathcal{L})$, and the likelihood $S_1(u \mid x, \theta, \mathcal{L})$ that a cooperative information-maximizing speaker would utter the adjective given a degree $x$, threshold $\theta$, and lexicon $\mathcal{L}$.

Does this model predict that $L_1$ would infer any qualitative differences between positive adjectives (*happy*), antonyms (*unhappy*), negated positives (*not happy*) and negated antonyms (*not unhappy*)?
Predictions depend on two additional features: the prior over lexica and what utterances to condition on (Fig.$\thinspace$\ref{fig:modelPredictions}). 
There are three natural possibilities for priors to assign probability to various hypotheses about negation markers (*un-*, *not*; Fig.$\thinspace$\ref{fig:lexicon-model}).
Our main object of interest is the *uncertain negation* model because it considers all logical possibility at equal probability.
The *bonafide contraries* submodel interprets morphological negation (*un-*) as expressing true contrary opposition, but maintains uncertainty about how to interpret particle negation (*not*).
This prior structure is also the natural choice when the antonym is not derived by morphological negation (e.g., *sad*).
The *logical negation* (or *George Orwell*) submodel assigns probability zero to lexica with contrary interpretations of negation. 

When listeners reason about which lexicon best explains the observed speaker utterance, it matters whether only a single utterance or multiple utterances are observed from the same speaker.
Given a richly structure domain of lexical uncertainty, multiple utterances heard in the same context can help resolve the meaning of each, and thus yield different interpretations than if the utterances are heard in isolation.
To match our experimental setup described later, multiple utterances predictions from Fig.$\thinspace$\ref{fig:modelPredictions} stem from conditioning $L_1$ on the observation of a speaker who used all four adjective alternatives to talk about four different individuals.

Upon hearing *not unhappy*, the *uncertain negation* model reasons that a truly compositional $\neg \neg \textit{happy}$ is implausible (intuitively because the speaker could have said the simpler *happy*) and interprets the utterance as signalling a slightly positive state (Fig.$\thinspace$\ref{fig:modelPredictions}).^[Model predictions assume the following model parameters: $P(x) = \mathcal{N}(0, 1); \alpha = 1; \text{cost}(\mathit{un}) = 1; \text{cost}(\mathit{not}) = 2$.]
When conditioning on a single utterance, our *uncertain negation* model does not differentiate antonyms (*unhappy*) from negated positives (*not happy*), as @Jespersen1917:Negation and @Blutner2004:pragmatics surmised.
But when it hears multiple utterances in the same context, the model predicts that *unhappy* is less happy than *not happy*, producing the ordering hypothesized by @Krifka2007:Negated-antonyms as shown in Fig.\ref{fig:happy-scale}.
The *bonafide contraries* submodel also interprets negated antonyms as slightly positive, but predicts Krifka's ordering for both single and multiple utterance conditioning. 
The *logical negation* submodel does not differentiate between negated antonyms and positives, nor between negated positives and antonyms.
All models have more extreme interpretations when they condition on multiple utterances.
<!-- The *uncertain negation* model, though, uniquely differentiates itself from the single utterance simulation: It now predicts a difference between negated positives and antonyms, and the ordering in Fig.$\thinspace$\ref{fig:happy-scale} . -->





<!-- The proportionality in Eq.$\thinspace$\ref{eq:S1} implies normalization over a set of alternative utterances (potentially differentiated by their cost). -->
<!-- Our primary focus is on an alternative set composed of a positive adjective, its antonym, and their respective negations [e.g., \{*happy*, *not happy*, *unhappy*, *not unhappy*\}; @Blutner2004:pragmatics; @Krifka2007:Negated-antonyms]. -->



<!-- \mht{explain why quantitative differences are exaggereted? maybe too much...} -->
<!-- However, in the context of explicit alternative utterances, the differences in interpretation between a positive adjective and its negation become quantitatively exaggerated ().  -->

<!-- \mht{i wonder if we should talk about all model variants with the same alternative set (unhappy), and note at the end of this paragraph that the bonafide antonyms model we hypothesize is the correct model for lexical anotnyms} -->
<!-- alternative set \{*happy*, *not happy*, *sad*, *not sad*\}, where a *bonafide antonym* like *sad* receives its own independent threshold, since it unambiguously expresses contrary  opposition; alternatively, this model can be interpreted as a special case of alternatives \{*happy*, *not happy*, *unhappy*, *not unhappy*\} when the listener only considers *unhappy* as contrary opposition, thus treating *unhappy* as a *bonafide antonym* like *sad*. -->
<!-- We retain uncertainty about the meaning of particle negation. -->












<!-- We consider two such alternative sets: postives, negatives, and their negations (e.g., \{*tall*, *not tall*, *short*, *not short*\}) and positives, antonyms, and their negations  -->


<!-- cases, distinguished by what antonym is assumed for a positive form like *happy*. -->
<!-- First, with a *lexical antonym* the set of alternative utterances is \{"happy", "not happy", "sad", "not sad"\}. -->
<!-- Second, with a *morphological (affix-negated) antonym* the set of alternative utterances is: \{"happy", "not happy", "unhappy", "not unhappy"\} [@Blutner2004:pragmatics; @Krifka2007:Negated-antonyms]. -->
<!-- The pragmatic listener assumes that affixal negation (e.g., *un-* or *in-*) and particle negation (e.g., *not*) can in principle both be used to express contradictory or contrary opposition.  -->
<!-- Rational pragmatic reasoning decides which interpretation of a negation marker is more likely, in conjunction with which thresholds to assign to any basic gradable expressions. -->

```{r old_modelPredictions, fig.cap="Predictions for the strengths of adjective interpretations for three model variants.", fig.env = "figure", fig.pos = "t", fig.width=3.5, fig.height=3, fig.align = "center", eval = F}
load('cached_results/rsa_model_predictions.RData') # rs.listener.wp.expectation

# new_type = ifelse(antonym_type == "lexical", 
#                            ifelse(adjective_type == "Antonym", "Negative", 
#                             ifelse(adjective_type == "Negated Antonym", "Negated negative", 
#                                    as.character(adjective_type))), as.character(adjective_type))

rs.listener.wp.expectation %>%
  mutate(utterance = factor(utterance, levels = c("Antonym", "Negated positive",
                         "Negated antonym", "Positive"),
                         labels = c("Antonym", "Negated\npositive", "Negated\nantonym", "Positive")),
         src = factor(src, levels = c("george orwell", "bonafide contraries", "full uncertainty"),
                      labels = c("george orwell", "bonafide contraries", "full uncertainty")),
         utterances = factor(utterances, 
                             levels = c("independent", "simultaneous"),
                             labels = c("implicit", "explicit"))) %>%
  ggplot(., aes( x = src, y = interpretation,
                 fill = utterance))+
    geom_col(position = position_dodge(0.8), 
             width = 0.8, color = 'black')+
    scale_fill_manual(name="Adjective type",
                    values = orange.purple.color.palette,
                    guide = guide_legend(reverse=F,
                                         keywidth = 0.5,
                                         keyheight = 0.4,
                                         default.unit = "cm"))+
  facet_wrap(~utterances)+
  #xlab("Model")+
  ylab("Model interpretation")+
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 10, vjust = 0),
    axis.text.y = element_text(size = 9),
    #axis.text.x = element_text(size = 9, angle = 30, hjust = 0.8, vjust = 0.9), 
    axis.text.x = element_text(size = 9, angle = 45, hjust = 1, vjust = 1), 
        legend.position = 'bottom',
        legend.text = element_text(size = 9, hjust= 0),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(-7,0,0,-10),
        legend.title = element_blank(),
        panel.spacing = unit(0, "lines")
        #legend.key.size = unit(0.5, "cm"),
      #legend.key = element_rect(size = 10)
      )+
  scale_y_continuous(limits = c(-0.8, 0.85), breaks = c(-0.75, 0, 0.75))#+
  #guides(fill=guide_legend(nrow=2,byrow=TRUE))
```


<!-- and evaluate them (and our *full uncertainty* model) in situations where they hear a single utterance from a speaker (e.g., "Jones is unhappy") and when they multiple utterances from a speaker (e.g., "Jones is unhappy. Smith is not unhappy."). -->

# Behavioral experiments


The *uncertain negation model* predicts a partial ordering for antonyms and their negations when heard in isolation (with negated positives undifferentiated from antonyms), but a full ordering when present in the same context (Fig.$\thinspace$\ref{fig:modelPredictions}).
As a control condition, we examine antonyms which do not have overt negation markers (e.g., *short*), for which the the lexica prior should be that of the *bonafide antonyms* case which predicts a full ordering regardless of context. 
Behavioral experiments aim to test these predictions.
<!-- \text{Expts.$\thinspace$1 $\&$ 2} were exploratory and informed our computational modeling. -->
\text{Expt.$\thinspace$1} was exploratory to inform computational modeling.
\text{Expt.$\thinspace$2} is a larger, more stringent, preregistered (\url{osf.io/p7f25/}) replication.
<!-- \mht{i feel like this paragraph and the one right after it could be merged somehow..} -->
<!-- \mf{what about the official preregistration as OSF?} -->



<!-- The *uncertain negation model* predicts that antonyms created by affixal negation (*unhappy*) and negated positives (*not happy*) receive similar interpretations when evaluated in isolation, but are drawn apart when heard in the same context. -->
<!-- <!-- while negated antonyms (*not unhappy*) are interpreted more weakly than positive adjectives (*happy*). -->
<!-- We contrast this context-sensitive quasi-ordering for *morphological antonyms* (*unhappy* $\approx$ *not happy* $<$ *not unhappy* $<$ *happy*) with a full-ordering predicted when overt negation is not present in antonyms (*bonafide contraries* model), as for *lexical antonyms* (*short* $<$ *not tall* $<$ *not short* $<$ *tall*), the latter of which is predicted even when utterances are presented in isolation.  -->



```{r modelPredictions, fig.cap="Listener model expected values for adjective interpretations on a normalized scale for the \\emph{uncertain negation} model and the \\emph{bonafide antonyms} and \\emph{logical negation} submodels. Paddles are vertically offset when overlapping.", fig.env = "figure", fig.pos = "t", fig.width=3.5, fig.align = "center"}
load('cached_results/rsa_model_predictions.RData') # rs.listener.wp.expectation

rs.listener.wp.expectation <- rs.listener.wp.expectation %>%
  mutate(utterance = factor(utterance, levels = c("Antonym", "Negated positive",
                         "Negated antonym", "Positive"),
                         labels = c("Antonym", "Negated positive",
                         "Negated antonym", "Positive")),
         src = factor(src, levels = c("george orwell", "bonafide contraries", "full uncertainty"),
                      labels = c("logical negation", "bonafide contraries", "uncertain negation")),
         src_numeric = ifelse(as.character(src) == "uncertain negation", 1,
                              ifelse(as.character(src) == "bonafide contraries", 0.5, 0)),
         utterances = factor(utterances, 
                             levels = c("independent", "simultaneous"),
                             labels = c("single utterance", "multiple utterances")))

ggplot(rs.listener.wp.expectation %>%
           filter(!(src == "logical negation" | (src == "uncertain negation" & utterance %in% c("Negated positive", "Antonym") & 
                                                    utterances == "single utterance"))), 
         aes(xmin = src_numeric-0.075, xmax = src_numeric+0.075,
              ymin = interpretation-0.05, ymax = interpretation+0.05,
                       fill = utterance))+
    xlab("")+
    coord_flip()+
    geom_rect(xmin = -0.05,
              xmax = 0.05, ymin = -1, ymax = 1, inherit.aes = F, alpha = 0.05,
              color = 'grey38')+
    geom_rect(xmin = 0.45,
              xmax = 0.55, ymin = -1, ymax = 1, inherit.aes = F, alpha = 0.05,
              fill = 'grey38', color = 'black')+
    geom_rect(xmin = 0.95,
              xmax = 1.05, ymin = -1, ymax = 1, inherit.aes = F, alpha = 0.05,
              fill = 'grey38', color = 'black')+
    geom_rect(color = 'black')+
    geom_rect(data = rs.listener.wp.expectation %>%
           filter(src == "logical negation", utterance %in% c("Negated positive", "Positive")),
             inherit.aes = F, aes(xmin = src_numeric-0.1, xmax = src_numeric+0.025,
                       ymin = interpretation-0.05, ymax = interpretation+0.05,
                       fill = utterance), color = 'black')+
    geom_rect(data = rs.listener.wp.expectation %>%
           filter(src == "logical negation", utterance %in% c("Negated antonym", "Antonym")),
             inherit.aes = F, aes(xmin = src_numeric-0.025, xmax = src_numeric+0.1,
                       ymin = interpretation-0.05, ymax = interpretation+0.05,
                       fill = utterance), color = 'black')+
    geom_rect(data = rs.listener.wp.expectation %>%
           filter(src == "uncertain negation" & utterance == "Negated positive", utterances == "single utterance"),
             inherit.aes = F, aes(xmin = src_numeric-0.1, xmax = src_numeric+0.025,
                       ymin = interpretation-0.05, ymax = interpretation+0.05,
                       fill = utterance), color = 'black')+
    geom_rect(data = rs.listener.wp.expectation %>%
           filter(src == "uncertain negation", utterance == "Antonym", utterances == "single utterance"),
             inherit.aes = F, aes(xmin = src_numeric-0.025, xmax = src_numeric+0.1,
                       ymin = interpretation-0.05, ymax = interpretation+0.05,
                       fill = utterance), color = 'black')+
    geom_text(x = -0.2, y = 0.4, 
              aes(label = words),
              inherit.aes = F,
              color = 'darkblue', size = 3, family = "Palatino",
              data = data.frame(utterances = c("single utterance", "multiple utterances"),
                                words = c("", "logical negation")))+
    geom_text(x = 0.3, y = 0.3, 
              aes(label = words),
              inherit.aes = F,
              color = 'darkblue', size = 3, family = "Palatino",
              data = data.frame(utterances = c("single utterance", "multiple utterances"),
                                words = c("", "bonafide antonyms")))+
    geom_text(x = 0.8, y = 0.3, 
              aes(label = words),
              inherit.aes = F,
              color = 'darkblue', size = 3, family = "Palatino",
              data = data.frame(utterances = c("single utterance", "multiple utterances"),
                                words = c("", "uncertain negation")))+
    geom_text(aes(x = x, y= y,label = words),
              inherit.aes = F,
              color = 'black', size = 2.2, family = "Palatino",
              data = data.frame(utterances = c(rep("single utterance",4), rep("multiple utterances", 4)),
                                words = c("unhappy", "not happy", "not unhappy", "happy", "", "", "", ""),
                                x = c(0.82, 0.7,0.82, 0.86),
                                y = c(-0.6, -0.1, 0.3, 0.78)))+
    #geom_text(x = -0.05, y = 0.8, label = 'lexical antonyms', color = 'black', alpha = 0.6, size = 4, family = "Palatino")+
    #geom_text(x = -0.1, y = -0.5, label = 'SINGLE UTTERANCE', color = 'black', alpha = 0.8, family = "Palatino",
              #fontface = 'italic', size = 3)+
  facet_wrap(~utterances)+
    scale_fill_manual(name="Adjective type",
                    values =  c(  "#5e3c99","#fdb863", "#b2abd2","#e66101"),
                    guide = guide_legend(reverse=F)
                    # breaks = c("Morphological antonym", "Negated morphological antonym", 
                    #            "Lexical antonym", "Negated lexical antonym", 
                    #            "Positive", "Negated positive"
                    #            )
                    )+
    ylab("model interpretation")+
    scale_x_continuous(limits = c(-0.27, 1.1))+
    scale_y_continuous(limits = c(-0.8, 0.9), breaks = c(-0.5, 0, 0.5))+
    theme(axis.text.y = element_blank(), 
          axis.ticks.y = element_blank(),
      legend.position = 'bottom',
        legend.text = element_text(size = 8, hjust= 0),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(-10,0,0,0),
        legend.title = element_blank(),
        panel.spacing = unit(0, "lines"),
        axis.text.x = element_text(size = 8),
      axis.title.x = element_text(size = 8), 
      legend.key.size = unit(0.25, "cm"))
```






## Experiment 1: Single utterances

<!-- ### Methods -->

```{r expt1_subjInfo}
load("cached_results/time_summary_e1.RData") # d.expt1.time.summary
load("cached_results/english_summary_e1.RData") # d.l1.7.nativeEnglish
```

### Participants

We recruited 120 participants from Amazon's Mechanical Turk (MTurk). 
This number was arrived at with the intention of getting approximately 25 ratings for each unique item in the experiment.
In all experiments, participants were restricted to those with U.S. IP addresses and at least a 95\% work approval rating. 
The experiment took on average `r round(d.expt1.time.summary[[1, "aveTime"]],1)` minutes and participants were compensated \$0.40.

### Procedure

On each trial, participants read a statement introducing a person using a gradable adjective of one of four *adjective types*: 
<!-- $\textsc{positives}$ -->
positives (e.g., *happy*, *tall*), 
<!-- $\textsc{opposites}$  -->
antonyms (e.g., *short*, *unhappy*), and their respective negations (e.g., *not* X). 
There were two *antonym types* (mophological, e.g., *unhappy*; and lexical, e.g., *short*).
Participants were asked to rate the character on a scale from "the most \textsc{positive} person" to "the most \textsc{antonym} person", which depended on the item, using a slider bar (\figref{fig:experiment-slides}A).
Participants rated one sentence at a time (e.g., "Greg is not unhappy") and saw items from both antonym types throughout the experiment. 
Each participant completed a total of 16 trials, with exactly 2 repetitions of each adjective type for each antonym type.

### Materials 

We used adjectives that described properties of people.
We refer to a collection of the four associated adjective forms---positives, antonyms (morphological or lexical), and their negations using the particle "not"---that have the same positive adjective as an *adjective set* (e.g., one adjective set is *happy*, *unhappy*, *not happy*, *not unhappy*).
10 adjective sets were constructed for each antonym type (total 20) from an informal survey of the linguistics literature and taken from a list of "common opposites" available online (Table 2).^[http://www.enchantedlearning.com/wordlist/opposites.shtml]
Each trial of the experiment used an adjective from a distinct adjective set (e.g., if a participant rated *unhappy*, they rated no other adjective from the \{*happy*, *unhappy*, ...\} set).


```{r old-experiment-slides, fig.pos = "hbt", fig.cap="Example experimental trials.", fig.env = "figure*", fig.width=7, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, eval = F}
slide.expt.1 <- cowplot::ggdraw() + 
  cowplot::draw_image("img/expt1.jpeg", scale = 1) +
  theme(plot.margin = unit(c(0,0,0,0), "pt")) + 
  cowplot::panel_border()
slide.expt.2 <- cowplot::ggdraw() + 
  cowplot::draw_image("img/expt2.jpeg", scale = 1)+
  theme(plot.margin = unit(c(0,0,0,0), "pt")) + 
  cowplot::panel_border()

cowplot::plot_grid(
    cowplot::add_sub(slide.expt.1, "Experiment 1 (implicit alternatives)", size = 8), 
    cowplot::add_sub(slide.expt.2, "Experiment 2 (explicit alternatives)", size = 8), 
    labels = c("A", "B"), 
    nrow = 1)
```


```{r items12, results="asis"}
load(file = "cached_results/item_table_e12.RData")
print(tab1, type="latex", comment = F, table.placement = "H", size="\\fontsize{9pt}{10pt}\\selectfont", include.rownames=FALSE)
```


### Results

```{r regression_expt1}
load("cached_results/regression_antTypeXadjType_expt1.RData") # rs1.expt1.helmert.summary
rs1.expt1.coef <- rs1.expt1.helmert.summary[["coefficients"]]
```

`r sum(!d.l1.7.nativeEnglish$englishNative)` participants were excluded for self-reporting a native language other than English, leaving a remainder of `r sum(d.l1.7.nativeEnglish$englishNative)` participants for these analyses.

The qualitative predictions of our models concern the ordering within a set of alternatives for different antonym types (morphological vs. lexical).
To visualize the data, we compute normalized responses on a participant-wise basis (i.e., normalized response $r'_{ij} = \frac{r_{ij} - mean_j}{sd_j}$ for trial $i$ and participant $j$).
\figref{fig:expt-results}A shows the mean normalized responses and bootstrapped 95\% confidence intervals for each of the four adjective types for morphological and lexical antonyms.
Critically, as predicted by the uncertain negation model, adjective sets with morphological antonyms show only a partial ordering, while those with lexical antonyms show a full ordering.
<!-- : $\textsc{opposite}_\textsc{neg} < \textsc{negated positive} < \textsc{negated opposite}_\textsc{neg} < \textsc{positive}$. -->

To confirm these observations, we built a linear mixed model predicting the raw, unnormalized ratings in terms of fixed effects of *antonym type* (morphological vs. lexical), *adjective type* (Helmert coded in order: antonym, negated positive, negated antonym, positive)^[
 Throughout, we code adjective type using Helmert coding, which compares levels of a factor to the average of preceding levels, in order to compare anotnym vs. negated positive levels of the adjective type factor.
], and their interaction; the model also included random intercepts and random slopes of *adjective type* by-participant and by-item.^[
  This, and all subsequent regression models, were the maximal mixed-effects model that converged for the data set that additionally explained significantly more variance than models with simpler mixed-effects structures, using the \texttt{lme4} package in R [@lme4].]
Consistent with our observations, the difference between the *antonym* vs. *negated positive* levels of adjective type interacted significantly with antonym type (morphological vs.\text{~}lexical): $\beta = `r round(rs1.expt1.coef["antonym_typelexical:st1","Estimate"],3)`$, $SE =  `r round(rs1.expt1.coef["antonym_typelexical:st1","Std. Error"],3)`$, t$(`r round(rs1.expt1.coef["antonym_typelexical:st1","df"], 1)`) = `r round(rs1.expt1.coef["antonym_typelexical:st1","t value"],2)`, p = `r round(rs1.expt1.coef["antonym_typelexical:st1","Pr(>|t|)"], 3)`$.

We also observe that negated morphological antonyms (e.g., *not unhappy*) were rated lower than negated lexical antonyms (e.g., *not tall*; \figref{fig:expt-results}A). 
<!-- \mf{I don't understand the previous sentence.} -->
Closer investigation of responses revealed that negated antonyms (and not other adjective types) received a bimodal distribution: The vast majority of ratings were slightly positive, while a clearly distinguishable minority distribution of ratings were slightly negative (e.g., *not dishonest* meaning *not honest*).
This weakly negative interpretation for negated antonyms was seen at least somewhat in every item and in most participants.
This interpretation may be the result of participants attributing politeness to the speaker: *Not dishonest* may be an indirect way of saying that a person is not honest [@Yoon2017].
<!-- \mf{is it fair to say: no clear systematic pattern discernible? if so, let's do that} -->

```{r experiment-slides, fig.pos = "hbt", fig.align ="center", fig.cap="Example experimental trials for (A) single utterance (Expts. 1, 2) and (B) multiple utterances conditions (Expt. 2). \``in the world\'' wording for endpoints was used in Expt. 2. (A) shows a trial from a morphological antonym set while (B) shows a lexical antonym set."}
expt.img <- png::readPNG("img/expt-schematic.png")
grid::grid.raster(expt.img)
```

<!-- ### Discussion -->
<!-- Consistent with the intuition from all but George Orwell, the negated (morphological) antonyms were interpreted as slightly positive, though less-so that purely postive statements. -->
<!-- This interpretation is predicted by the *bonafide antonyms* model and the *uncertain parser* model.  -->
<!-- \text{Expt.$\thinspace$1} further confirmed our hypothesized asymmetry between lexical and morphological antonyms.  -->
<!-- In particular, interpretations of morphological antonyms were indistinguishable from those of negated positive statements, consistent with the intuition of @Jespersen1917:Negation and @Blutner2004:pragmatics as well as our *uncertain parser* model.  -->
<!-- Lexical antonyms, on the other hand, showed a clear ordering: ANT $<$ NEG POS $<$ NEG ANT $<$ POS.  -->


<!-- Differences in meaning between negated positives and morphological antonyms (e.g., *not happy* and *unhappy*) were not found.  -->
<!-- However, differences in meaning have been noted in such naturalistic examples as  -->
<!-- Here is an instance of an attested difference in meaning between negated positives and morphological antonyms (e.g., *not happy* and *unhappy*), taken from @Krifka2007:Negated-antonyms, taken from internet: -->
<!-- \begin{quote} -->
<!-- \footnotesize -->
<!-- It's an absolutely horrible feeling to be unhappy, and I don't even think I was unhappy, just not happy, if you know what I mean.  -->
<!-- \end{quote} -->

<!-- \noindent We did not find such a difference in our experiment, but rather than conclude that no differnce exists, we note that the speaker in this example utterance chose to use both *unhappy* and *not happy* in the same utterance.  -->
<!-- We hypothesize that explicit comparisons between alternative utterances can draw out the difference in meaning between negated positives and morphological antonyms, which leads the morphological antonym to behave more like a bonafide antonym. -->

```{r expt1results}
load("cached_results/oneSlider_bootstrappedCIs.RData") # df.oneSlider.ci

# fig.expt1 <- ggplot(df.oneSlider.ci %>%
#                       mutate(src = 'implicit'), aes(x = antonym_type,
#                       y = mean,
#                        ymin = ci_lower, ymax = ci_upper,
#                        fill = adjective_type,
#                       group = adjective_type
#               ))+
#   geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
#   geom_errorbar(position = position_dodge(0.8), color = 'black',
#                 width = 0.4)+
#   #coord_flip()+
#   facet_wrap(~src)+
#   xlab("")+
#   #scale_fill_viridis(discrete = T, name="Adjective type")+
#   scale_fill_manual(name="Adjective type",
#                     values = orange.purple.color.palette,
#                     guide = guide_legend(reverse=TRUE))+
#   ylab("mean normalized rating")+
#   theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ))+
#   scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))

# fig.expt1 <- df.oneSlider.ci %>%
#   ungroup() %>%
#   mutate(
#     new_type = ifelse(antonym_type == "lexical", 
#                            ifelse(adjective_type == "Antonym", "Negative", 
#                             ifelse(adjective_type == "Negated antonym", "Negated negative", 
#                                    as.character(adjective_type))), as.character(adjective_type)),
#     antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
#                           labels = c("negative", "antonym")),
#     src = 'implicit'
#       ) %>%
#   ggplot(., aes(x = antonym_type,
#                       y = mean,
#                        ymin = ci_lower, ymax = ci_upper,
#                        fill = new_type,
#                       group = adjective_type
#               ))+
#   geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
#   geom_errorbar(position = position_dodge(0.8), color = 'black',
#                 width = 0.4)+
#   #coord_flip()+
#   facet_wrap(~src)+
#   xlab("")+
#   #scale_fill_viridis(discrete = T, name="Adjective type")+
#   scale_fill_manual(name="Adjective type",
#                     values = orange.purple.blue.color.palette,
#                     guide = guide_legend(reverse=F),
#                     breaks = c("Negative", "Negated negative", 
#                                "Antonym", "Negated antonym", 
#                                "Positive", "Negated positive"))+
#   ylab("mean normalized rating")+
#   theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ),
#         legend.position = 'bottom')+
#   scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))


df.oneSlider.ci <- df.oneSlider.ci %>%
  ungroup() %>%
  mutate(
    new_type = ifelse(antonym_type == "lexical", 
                     ifelse(adjective_type == "Antonym", "Lexical antonym", 
                      ifelse(adjective_type == "Negated antonym", "Negated lexical antonym", 
                             as.character(adjective_type))), as.character(adjective_type)),
     new_type = ifelse(antonym_type == "morphological", 
                     ifelse(new_type == "Antonym", "Morphological antonym", 
                      ifelse(new_type == "Negated antonym", "Negated morphological antonym", 
                             as.character(new_type))), as.character(new_type)),
    new_type = factor(new_type, levels = c( "Morphological antonym", "Lexical antonym", "Positive",
                                           "Negated morphological antonym", "Negated lexical antonym", "Negated positive")),
    antonym_type = factor(antonym_type, levels = c("lexical", "morphological")),
    condition_numeric = ifelse(as.character(antonym_type) == "lexical", 0, 0.2),
    src = 'implicit'
  )


fig.expt1 <- ggplot(df.oneSlider.ci %>%
           filter(!(antonym_type == "morphological" & adjective_type %in% c("Negated positive", "Antonym"))), 
         aes(xmin = condition_numeric-0.03, xmax = condition_numeric+0.03,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type))+
    xlab("")+
    coord_flip()+
    geom_rect(xmin = -0.025, 
              xmax = 0.025, ymin = -1.5, ymax = 1.5, inherit.aes = F, alpha = 0.05,
              color = 'black')+
    geom_rect(xmin = 0.2-0.025, 
              xmax = 0.225, ymin = -1.5, ymax = 1.5, inherit.aes = F, alpha = 0.05,
              fill = 'darkblue', color = 'black')+
    geom_rect(color = 'black')+
    geom_rect(data = df.oneSlider.ci %>% filter(antonym_type == "morphological" & adjective_type == "Negated positive"),
             inherit.aes = F, aes(xmin = condition_numeric-0.04, xmax = condition_numeric+0.02,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type), color = 'black')+
    geom_rect(data = df.oneSlider.ci %>% filter(antonym_type == "morphological" & adjective_type == "Antonym"),
               inherit.aes = F,
           aes(xmin = condition_numeric-0.02, xmax = condition_numeric+0.04,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type), color = 'black')+
    geom_text(x = 0.15, y = 0.5, label = 'morphological antonyms', color = 'darkblue', size = 4, family = "Palatino")+
    geom_text(x = -0.05, y = 0.8, label = 'lexical antonyms', color = 'black', alpha = 0.6, size = 4, family = "Palatino")+
    geom_text(x = -0.1, y = -0.5, label = 'SINGLE UTTERANCE', color = 'black', alpha = 0.8, family = "Palatino",
              fontface = 'italic', size = 3)+
    scale_fill_manual(name="Adjective type",
                    values = c("#5e3c99",  "#0570b0",  "#b2abd2", "#74a9cf","#fdb863","#e66101"),
                    guide = guide_legend(reverse=F),
                    breaks = c("Morphological antonym", "Negated morphological antonym", 
                               "Lexical antonym", "Negated lexical antonym", 
                               "Positive", "Negated positive"
                               ))+
    ylab("mean normalized rating")+
    scale_x_continuous(limits = c(-0.1, 0.3))+
    scale_y_continuous(limits = c(-1.1,1.3), breaks = c(-1, 0, 1))+
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
          legend.position = 'bottom')
```

```{r expt2results, eval = F}
load("cached_results/fourSlider_bootstrappedCIs.RData") # df.fourSlider.ci
fig.expt2 <- ggplot(df.fourSlider.ci %>%
                      mutate(src = 'explicit',
                             new_type = ifelse(antonym_type == "lexical", 
                           ifelse(adjective_type == "Antonym", "Negative", 
                            ifelse(adjective_type == "Negated Antonym", "Negated negative", 
                                   as.character(adjective_type))), as.character(adjective_type)),
                               antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
                          labels = c("negative", "antonym"))), aes(x = antonym_type,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type,
                      group = adjective_type
              ))+
  geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
  geom_errorbar(position = position_dodge(0.8), color = 'black',
                width = 0.4)+
  #coord_flip()+
  xlab("Antonym type")+
  facet_wrap(~src)+
  xlab("")+
  #scale_fill_viridis(discrete = T, name="Adjective type")+
  scale_fill_manual(name="Adjective type",
                    values = orange.purple.blue.color.palette,
                    guide = guide_legend(reverse=TRUE)
                    )+
  ylab("mean normalized rating")+
  theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ))+
  scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))
```

```{r expt-results-legend}
load(file = "cached_results/bootstrappedCIs.RData") # d.full.boot

d.full.boot <- d.full.boot %>%
  ungroup() %>%
  mutate(antonym_type = factor(antonym_type, 
                               levels = c("lexant", "morphant"),
                               labels = c("lexical", "morphological")),
         adjective_type_rescaled = 
           factor(adjective_type_rescaled,
              levels = c("antonym", "neg_positive", "neg_antonym","positive"),
              labels = c("Antonym", "Negated positive",
                         "Negated antonym", "Positive")),
    new_type = ifelse(antonym_type == "lexical", 
                     ifelse(adjective_type_rescaled == "Antonym", "Lexical antonym", 
                      ifelse(adjective_type_rescaled == "Negated antonym", "Negated lexical antonym", 
                             as.character(adjective_type_rescaled))), as.character(adjective_type_rescaled)),
     new_type = ifelse(antonym_type == "morphological", 
                     ifelse(new_type == "Antonym", "Morphological antonym", 
                      ifelse(new_type == "Negated antonym", "Negated morphological antonym", 
                             as.character(new_type))), as.character(new_type)),
    new_type = factor(new_type, levels = c( "Morphological antonym", "Lexical antonym", "Positive",
                                           "Negated morphological antonym", "Negated lexical antonym", "Negated positive")),
         condition = factor(condition, levels = c("explicit", "implicit"),
                            labels=c("multiple utterances", "single utterance")),
          condition_numeric = ifelse(as.character(antonym_type) == "lexical", 0, 0.2),
          new_type = factor(new_type, levels = c( "Morphological antonym", "Lexical antonym", "Positive",
                                           "Negated morphological antonym", "Negated lexical antonym", "Negated positive"))) 



df.expt2.single <- d.full.boot %>% filter(condition == "single utterance")
df.expt2.multiple <- d.full.boot %>% filter(condition == "multiple utterances")

fig.expt2.multiple.legend <- ggplot(df.expt2.multiple %>%
           filter(!(antonym_type == "morphological" & adjective_type_rescaled %in% c("Negated positive", "Antonym"))), 
         aes(x = condition_numeric, y = mean, ymin = ci_lower, ymax = ci_upper, color = new_type))+
    xlab("")+
    coord_flip()+
    geom_vline(xintercept = 0,  size = 5, alpha = 0.1)+
    geom_vline(xintercept = 0.2,  size = 5, alpha = 0.1, color = 'darkblue') +
    geom_linerange(size = 4, alpha = 1)+
    geom_linerange(data = df.expt2.multiple %>%
           filter(antonym_type == "morphological" & adjective_type_rescaled %in% c("Negated positive", "Antonym")),
           aes(x = condition_numeric,
                       ymin = ci_lower, ymax = ci_upper,
                       color = new_type), size = 4)+
    geom_text(x = 0.15, y = 0.9, label = 'morphological antonyms', color = 'darkblue', size = 4, family = "Palatino")+
    geom_text(x = -0.05, y = 1.05, label = 'lexical antonyms', color = 'black', alpha = 0.6, size = 4, family = "Palatino")+
    geom_text(x = -0.09, y = -0.75, label = 'MULTIPLE UTTERANCES', color = 'black', alpha = 0.8, family = "Palatino",
              fontface = 'italic', size = 4)+
    scale_color_manual(name="Adjective type",
                    values = c("#5e3c99",  "#0570b0",  "#b2abd2", "#74a9cf","#fdb863","#e66101"),
                    guide = guide_legend(reverse=F),
                    breaks = c("Morphological antonym", "Negated morphological antonym", 
                               "Lexical antonym", "Negated lexical antonym", 
                               "Positive", "Negated positive"
                               ))+
    ylab("mean normalized rating")+
    scale_x_continuous(limits = c(-0.1, 0.3))+
    scale_y_continuous(limits = c(-1.1,1.3), breaks = c(-1, 0, 1))+
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
          legend.position = 'bottom')
```

```{r expt2-subfigs}


fig.expt2.single <- ggplot(df.expt2.single %>%
           filter(!(antonym_type == "morphological" & adjective_type_rescaled %in% c("Negated positive", "Antonym"))), 
         aes(xmin = condition_numeric-0.03, xmax = condition_numeric+0.03,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type))+
    xlab("")+
    coord_flip()+
    geom_rect(xmin = -0.025, 
              xmax = 0.025, ymin = -1.5, ymax = 1.5, inherit.aes = F, alpha = 0.05,
              color = 'black')+
    geom_rect(xmin = 0.2-0.025, 
              xmax = 0.225, ymin = -1.5, ymax = 1.5, inherit.aes = F, alpha = 0.05,
              fill = 'darkblue', color = 'black')+
    geom_rect(color = 'black')+
    geom_rect(data = df.expt2.single %>% filter(antonym_type == "morphological" & adjective_type_rescaled == "Negated positive"),
             inherit.aes = F, aes(xmin = condition_numeric-0.04, xmax = condition_numeric+0.02,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type), color = 'black')+
    geom_rect(data = df.expt2.single %>% filter(antonym_type == "morphological" & adjective_type_rescaled == "Antonym"),
               inherit.aes = F,
           aes(xmin = condition_numeric-0.02, xmax = condition_numeric+0.04,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type), color = 'black')+
    geom_text(x = 0.15, y = 0.5, label = 'morphological antonyms', color = 'darkblue', size = 4, family = "Palatino")+
    geom_text(x = -0.05, y = 0.8, label = 'lexical antonyms', color = 'black', alpha = 0.6, size = 4, family = "Palatino")+
    geom_text(x = -0.1, y = -0.5, label = 'SINGLE UTTERANCE', color = 'black', alpha = 0.8, family = "Palatino",
              fontface = 'italic', size = 3)+
    scale_fill_manual(name="Adjective type",
                    values = c("#5e3c99",  "#0570b0",  "#b2abd2", "#74a9cf","#fdb863","#e66101"),
                    guide = guide_legend(reverse=F),
                    breaks = c("Morphological antonym", "Negated morphological antonym", 
                               "Lexical antonym", "Negated lexical antonym", 
                               "Positive", "Negated positive"
                               ))+
    ylab("mean normalized rating")+
    scale_x_continuous(limits = c(-0.1, 0.3))+
    scale_y_continuous(limits = c(-1.1,1.3), breaks = c(-1, 0, 1))+
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
          legend.position = 'bottom')




fig.expt2.multiple <- ggplot(df.expt2.multiple %>%
           filter(!(antonym_type == "morphological" & adjective_type_rescaled %in% c("Negated positive", "Antonym"))), 
         aes(xmin = condition_numeric-0.03, xmax = condition_numeric+0.03,
                      y = mean,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type))+
    xlab("")+
    coord_flip()+
    geom_rect(xmin = -0.025, 
              xmax = 0.025, ymin = -1.5, ymax = 1.5, inherit.aes = F, alpha = 0.05,
              color = 'black')+
    geom_rect(xmin = 0.2-0.025, 
              xmax = 0.225, ymin = -1.5, ymax = 1.5, inherit.aes = F, alpha = 0.05,
              fill = 'darkblue', color = 'black')+
    geom_rect(color = 'black')+
    geom_rect(data = df.expt2.multiple %>% filter(antonym_type == "morphological" & adjective_type_rescaled == "Negated positive"),
             inherit.aes = F, aes(xmin = condition_numeric-0.03, xmax = condition_numeric+0.03,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type), color = 'black')+
    geom_rect(data = df.expt2.multiple %>% filter(antonym_type == "morphological" & adjective_type_rescaled == "Antonym"),
               inherit.aes = F,
           aes(xmin = condition_numeric-0.03, xmax = condition_numeric+0.03,
                       ymin = ci_lower, ymax = ci_upper,
                       fill = new_type), color = 'black')+
    geom_text(x = 0.15, y = 0.5, label = 'morphological antonyms', color = 'darkblue', size = 4, family = "Palatino")+
    geom_text(x = -0.05, y = 0.8, label = 'lexical antonyms', color = 'black', alpha = 0.6, size = 4, family = "Palatino")+
    geom_text(x = -0.1, y = -0.35, label = 'MULTIPLE UTTERANCES', color = 'black', alpha = 0.8, family = "Palatino",
              fontface = 'italic', size = 3)+
    scale_fill_manual(name="Adjective type",
                    values = c("#5e3c99",  "#0570b0",  "#b2abd2", "#74a9cf","#fdb863","#e66101"),
                    guide = guide_legend(reverse=F),
                    breaks = c("Morphological antonym", "Negated morphological antonym", 
                               "Lexical antonym", "Negated lexical antonym", 
                               "Positive", "Negated positive"
                               ))+
    ylab("mean normalized rating")+
    scale_x_continuous(limits = c(-0.1, 0.3))+
    scale_y_continuous(limits = c(-1.1,1.3), breaks = c(-1, 0, 1))+
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
          legend.position = 'bottom')

```

```{r expt-results, fig.cap="Empirical ratings for adjective sets with morphological antonyms (e.g., \``unhappy\'') and lexical antonyms (e.g., \``sad\''). Width of paddle denotes a bootstrapped 95\\% confidence interval. Paddles are vertically-offset when overlapping. A: Expt. 1: Participants rated  adjectives in isolation; a single participant saw both morphological and lexical antonym items. B: Expt. 2: Participants rated adjectives in isolation (left) or simultaneously (right); each ribbon denotes a between-participant condition.", fig.env = "figure*", fig.pos = "h", fig.width=8.5, fig.asp = 0.4, out.width = "95%", fig.align = "center", set.cap.width=T, num.cols.cap=2}

load(file = "cached_results/bootstrappedCIs.RData") # d.full.boot

# fig.bs.ci <- d.full.boot %>%
#   ungroup() %>%
#   mutate(antonym_type = factor(antonym_type, 
#                                levels = c(  "lexant", "morphant"),
#                                labels = c("lexical", "morphological")),
#          adjective_type_rescaled = 
#            factor(adjective_type_rescaled,
#               levels = c("antonym", "neg_positive", "neg_antonym","positive"),
#               labels = c("Antonym", "Negated positive",
#                          "Negated antonym", "Positive")),
#          new_type = ifelse(antonym_type == "lexical", 
#                            ifelse(adjective_type_rescaled == "Antonym", "Negative", 
#                             ifelse(adjective_type_rescaled == "Negated antonym", "Negated negative", 
#                                    as.character(adjective_type_rescaled))), as.character(adjective_type_rescaled)),
#              antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
#                           labels = c("negative", "antonym"))) %>%
#   ggplot(., aes(x = antonym_type,
#                       y = mean,
#                        ymin = ci_lower, ymax = ci_upper,
#                        fill = new_type,
#                       group = adjective_type_rescaled
#               ))+
#   geom_col(position = position_dodge(0.8), width = 0.8, color = 'black')+
#   geom_errorbar(position = position_dodge(0.8), color = 'black',
#                 width = 0.4)+
#   #coord_flip()+
#   xlab("Antonym type")+
#   #scale_fill_viridis(discrete = T, name="Adjective type")+
#   scale_fill_manual(name="Adjective type",
#                     values = orange.purple.blue.color.palette,
#                     guide = guide_legend(reverse=F),
#                     breaks = c("Negative", "Negated negative", 
#                                "Antonym", "Negated antonym", 
#                                "Positive", "Negated positive"))+
#   facet_wrap(~condition, scales = 'free', nrow = 1)+
#   ylab("mean normalized rating")+
#   xlab("")+
#     theme(axis.text.x = element_text(angle = 45, vjust =1 ,hjust =1 ))+
#   #scale_y_reverse(limits = c(1.25, -1.1), breaks = c(1, 0, -1))
#   scale_y_continuous(limits = c(-1.1, 1.25), breaks = c(-1, 0, 1))

# 
# fig.bs.ci <- d.full.boot %>%
#   ungroup() %>%
#   mutate(antonym_type = factor(antonym_type, 
#                                levels = c(  "lexant", "morphant"),
#                                labels = c("lexical", "morphological")),
#          adjective_type_rescaled = 
#            factor(adjective_type_rescaled,
#               levels = c("antonym", "neg_positive", "neg_antonym","positive"),
#               labels = c("Antonym", "Negated positive",
#                          "Negated antonym", "Positive")),
#          new_type = ifelse(antonym_type == "lexical", 
#                            ifelse(adjective_type_rescaled == "Antonym", "Negative", 
#                             ifelse(adjective_type_rescaled == "Negated antonym", "Negated negative", 
#                                    as.character(adjective_type_rescaled))), as.character(adjective_type_rescaled)),
#              antonym_type = factor(antonym_type, levels = c("lexical", "morphological"),
#                           labels = c("negative", "antonym")),
#          condition = factor(condition, levels = c("explicit", "implicit"),
#                             labels=c("multiple utterances", "single utterance"))) %>%
#   
#   ggplot(., aes( x = condition, y = mean, ymin = ci_lower, 
#     ymax = ci_upper, color = new_type, group = antonym_type ))+
#     xlab("")+
#     coord_flip()+
#     geom_linerange(position = position_jitterdodge(dodge.width = 0.75,
#                                     jitter.height = 0,
#                                     jitter.width = 0), size = 10, alpha = 1)+
#   
#     geom_vline(xintercept = 0.81,  size = 5, alpha = 0.1, color = 'darkgreen')+
#     geom_vline(xintercept = 1.19,  size = 5, alpha = 0.1) +
#     geom_vline(xintercept = 1.81,  size = 5, alpha = 0.1, color = 'darkgreen')+
#     geom_vline(xintercept = 2.19,  size = 5, alpha = 0.1) +
#     geom_text(x = 2.0, y = 1.17, label = 'lexical antonyms', color = 'darkgreen', size = 2.5)+
#     geom_text(x = 2.4, y = 1.07, label = 'morphological antonyms', color = 'black', alpha = 0.6, size = 2.5)+
#     geom_text(x = 2.45, y = 0.1, label = 'single utterance condition', color = 'black', size = 3)+
#     geom_text(x = 1.45, y = 0.1, label = 'multiple utterances condition', color = 'black', size = 3)+
#     scale_color_manual(name="Adjective type",
#                     values = orange.purple.blue.color.palette,
#                     guide = guide_legend(reverse=F),
#                     breaks = c("Negative", "Negated negative", 
#                                "Antonym", "Negated antonym", 
#                                "Positive", "Negated positive"))+
#     ylab("mean normalized rating")+
#     scale_y_continuous(limits = c(-1.1,1.3), breaks = c(-1, 0, 1))+
#     theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

legend <- get_legend(fig.expt2.multiple.legend + 
                       theme(legend.position="bottom", legend.margin=margin(0,0,0,0), legend.box.margin=margin(0,0,0,0),
                             legend.direction = "horizontal",
                              # legend.key.width = unit(0.000005, "cm"),
                              # legend.key.height = unit(0.000005, "cm"),
                             #legend.title = element_text(size = 4),
                             legend.text = element_text(size = 10)
                             ))


prow <- plot_grid(
   fig.expt1 + theme(legend.position="none", plot.margin = unit(c(6,0,6,6), "pt"),
                    axis.title.x = element_blank()),
   fig.expt2.single + theme(legend.position="none",
                     plot.margin = unit(c(6,0,6,0), "pt")),
   fig.expt2.multiple + theme(legend.position="none",
                     plot.margin = unit(c(6,0,6,0), "pt"),
                     axis.title.x = element_blank()),
           align = 'vh',
           labels = c("A", "B", ""),
           hjust = -1,
           nrow = 1, rel_widths = c(1,1,1)
           )



# prow <- plot_grid(
#   fig.expt1 + theme(legend.position="none",
#                                      plot.margin = unit(c(6,0,6,0), "pt")),
#    # fig.expt2 + theme(legend.position="none",
#    #                   plot.margin = unit(c(6,0,6,0), "pt")) + ylab(""),
#    fig.bs.ci + theme(legend.position="none",
#                      plot.margin = unit(c(6,0,6,0), "pt")) + ylab(""),
#            align = 'vh',
#            labels = c("A", "B", "C"),
#            hjust = -1,
#            nrow = 1, rel_widths = c(1,2)
#            )

plot_grid(legend, prow,  ncol = 1, rel_heights = c(.25, 1))

# fig.expt2.multiple+ 
#                        theme(legend.position="bottom", legend.margin=margin(0,0,0,0), legend.box.margin=margin(0,0,0,0),
#                              legend.direction = "horizontal",
#                              legend.key.width = unit(0.0005, "cm"),
#                              legend.key.height = unit(0.0005, "cm"),
#                              #legend.title = element_text(size = 4),
#                              legend.text = element_text(size = 8)
#                              )
#prow
#fig.bs.ci
```





## Experiment 2: Single and multiple utterances

<!-- \text{Expts$\thinspace$1 \& 2} revealed an asymmetry between opposites with overt negation markers (*affixal antonyms* e.g., "unhappy") and those with (*negative adjectives* e.g., "short"). -->
\text{Expt.$\thinspace$1} revealed an asymmetry: Lexical antonyms (e.g., *short*) were clearly distinguished from negated positives (e.g., *not tall*), whereas morphological antonyms were not (e.g., *unhappy* $\approx$ *not happy*).
<!-- , unless a speaker used multiple distinct alternatives in the same context (Expt.$\thinspace$2).  -->
In \text{Expt.$\thinspace$1}, our adjective sets varied both in terms of their antonym type (morphological vs.\text{~}lexical) as well as the actual degree scales being described (e.g., height for *tall*/*short* vs.\text{~}happiness for *happy*/*unhappy*).
Many adjective sets have both morphological and lexical antonyms (e.g., *happy*/*unhappy*/*sad*).
Here, we aim to replicate the asymmetry findings using adjectives that describe the same semantic scales.
<!-- Specifically, in \text{Expts.$\thinspace$1~\&~2}, our adjective sets varied both in terms of their opposites (negatives vs.\text{~}antonyms) as well as the actual degree scales being described (e.g., height for *tall*/*short* vs.\text{~}happiness for *happy*/*unhappy*). -->
Also, we test our second prediction that hearing multiple utterances in the same context will produce the full ordering for morphological antonym sets (Fig.$\thinspace$\ref{fig:modelPredictions}).

<!-- ## Methods -->

### Participants

We recruited 750 participants from MTurk.
The experiment comprised of four between-subjects experimental conditions arranged in a 2x2 Latin Square design: *antonym type (morphological vs.\text{~}lexical)* X *context (single vs.\text{~}multiple utterances)*.
300 participants were assigned to each of the *single utterance* conditions, and 75 participants were assigned to each of the *multiple utterances* conditions.
These numbers follow from the intention of getting approximately 45 ratings for each unique adjective in the experiment.

The *single utterance* task took on average `r round(filter(d.time.summary, condition == "implicit")[[1,"aveTime"]], 1)` minutes and participants were compensated \$0.40; *multiple utterances* took on average `r round(filter(d.time.summary, condition == "explicit")[[1,"aveTime"]], 1)` minutes and participants were compensated \$0.80.
Participants who self-reported a native language other than English were excluded.
This exclusion criterion, our planned sample size, the procedure, and the analysis described below were preregistered: \url{osf.io/p7f25/}.

### Materials

<!-- Our pilot testing revealed differences between lexical and morphological antonym sets (e.g., "tall"/"short" and "happy"/"unhappy"). -->

To best isolate the contribution of morphological vs.\text{~}lexical antonyms, we curated adjective sets consisting of words for properties of people, such that both types of antonyms existed for the same positive adjective (e.g., *happy* $\rightarrow$ *unhappy*, *sad*; \text{Table$\thinspace$3}).
Lexical antonyms were selected from a set of possibilities produced from a small survey (n=18) on MTurk eliciting "opposites" for a list of 30 positive-form adjectives which had morphological antonyms (asking participants in the same experimental context as our interpretation studies, "What is the opposite of e.g., *forgiving*?").
From the list of freely-produced opposites (the vast majority of which were not morphological), the first author chose the one that intuitively best conveyed the same scalar dimension as the morphological antonym and which was not already used as a lexical antonym for another item (e.g., opposite of *forgiving* $\rightarrow$ *resentful*; opposite of *kind* $\rightarrow$ *cruel*, because opposite of *friendly* $\rightarrow$ *mean*).
Ten out of the original 30 items were dropped for either not having such a well-suited lexical antonym (e.g., *moral*) or for having a well-suited lexical antonym that conflicted with another item (e.g., *compassionate* $\rightarrow$ *cold*, but also *affectionate* $\rightarrow$ *cold*).

<!-- For a list of the 20 positive-adjectives and their lexical and morphological antonyms used in the experiment, see Table \@ref(tab:items). -->

<!-- We used **adjective sets** of size 6 composed of positive-form gradable adjectives (\textsc{POS}; e.g., *happy*), their negation (\textsc{NEG POS}; e.g., *not happy*), antonyms constructed by altering the morphology of the adjective (\textsc{MORPH ANT}; e.g., *unhappy*), anotnyms with a distinct lexical entry (\textsc{LEX ANT}; e.g., *sad*) and their respective negations (e.g., *not unhappy*, *not sad*). -->
<!-- Antonyms were either created by morphological negation (\emph{morphological antonyms}; e.g., *unhappy* for *happy*) or were distinct lexical entries (\emph{lexical antonyms}; e.g., *short*, for *tall*). -->
<!-- All adjectives were individual-level predicates that applied to people; items were constructed from an informal survey of the linguistics literature and taken from list of *common opposites* available online\footnote{http://www.enchantedlearning.com/wordlist/opposites.shtml} (for a full list, see \tableref{tab:items}. -->






### Procedure

<!-- Participants rated adjective sets made with either lexical or morphological antonyms. -->
<!-- In addition, participants provided ratings with alternative utterances either explicit or implicit.  -->

<!-- On each trial, participants read a statement introducing a character using a gradable adjective of one of four **adjective types** (e.g., "Greg is \{POS, ANT, NEG POS, NEG ANT\}"). -->
<!-- Participants were asked rate the character on a scale from "the most POS person in the world" to "the most ANT person in the world", using a slider bar (\figref{fig:expt1}). -->
<!-- In the *lexical antonyms* conditions, ANT (and NEG ANT) were antonyms with distinct lexical entries (e.g., "sad", "not sad" for POS = "happy"). -->
<!-- In the *morphological antonyms* conditions, ANT (and NEG ANT) were antonyms created by adding a negation-inducing prefix (e.g., "unhappy", "not unhappy" for POS = "happy"). -->

In the *multiple utterances* conditions, participants rated all four adjective types simultaneously, each referring to a different person (\figref{fig:experiment-slides}B), for a total of 12 trials.
The *single utterances* conditions were similar to of that \text{Expt.$\thinspace$1}: Participants rated one sentence at a time (e.g., "Greg is not unhappy"), each from a unique adjective set (e.g., never rated both *unhappy* and *not happy*), completing a total of 12 trials, with exactly 3 repetitions of each adjective type (positive, antonym, and their negations).
In contrast to \text{Expt.$\thinspace$1}, *antonym type* (morphological vs.\text{~}lexical) was a between-participants factor.
In addition, the slider bar endpoints were relabeled to "the most \{*positive*, *negative*\} person *in the world*"; without "in the world", there is a salient interpretation of the endpoints indicating  "the most \{*positive*, *negative*\} person (of these four)" in the multiple utterances conditions.

<!-- The procedure was similar to that of \text{Expts.$\thinspace$1~\&~2}. -->
<!-- In the *implicit alternatives* conditions, participants rated one sentence at a time (e.g., *Greg is not unhappy*), each from a unique adjective set (e.g., never rated both *unhappy* and *not happy*) *a la* \text{Expt.$\thinspace$1}, completing a total of 12 trials, with exactly 3 repetitions of each adjective type (\textsc{positive}, \textsc{opposite}, and their negations). -->

<!-- Again, there were 12 trials. -->


```{r items, results="asis"}
load(file = "cached_results/item_table.RData")
print(tab1, type="latex", comment = F, table.placement = "h", size="\\fontsize{9pt}{10pt}\\selectfont", include.rownames=FALSE)
```



### Results 

```{r loadRegressionResults}
# regression 1: opposite vs. negated positive X opposite type (implicit only)
load("cached_results/regression_antTypeXadjType_implicitCond.RData") # rs1.helmert.implicit.summary
## simple effects
load("cached_results/regression_simple_adjType_morph_implicit.RData") #rs1.simple.morph.implicit.summary
load("cached_results/regression_simple_adjType_lex_implicit.RData") #rs1.simple.lex.implicit.summary

load("cached_results/regression_adjTypeXcontext_morph.RData") #rs2.helmert.morph.summary
load("cached_results/regression_antTypeXadjTypeXcontext.RData") # rs3.3way.summary

rs1.implicit.coef <- rs1.helmert.implicit.summary[["coefficients"]]
rs1.implicit.simple.morph.coef <- rs1.simple.morph.implicit.summary[["coefficients"]]
rs1.implicit.simple.lex.coef <- rs1.simple.lex.implicit.summary[["coefficients"]]
rs2.morph.coef <- rs2.helmert.morph.summary[["coefficients"]]
rs3.3way.coef <- rs3.3way.summary[["coefficients"]]
```

`r sum(!d.full.nativeEnglish$englishNative)` participants were excluded for self-reporting a native language other than English, leaving `r sum(d.full.nativeEnglish$englishNative)` participants for these analyses.
Mean normalized responses for each adjective type in each condition are shown in \figref{fig:expt-results}B. 
<!-- The patterns visually mirror those of the first two experiments. -->

As we did in \text{Expt.$\thinspace$1}, we evaluate our hypothesis that morphological antonyms behave as predicted by the *uncertain negation* model (i.e., show a partial ordering) while lexical antonyms show a true ordering (like *bonafide contraries*).
To do so, we considered data only from the *single utterances* conditions and built a linear mixed model predicting the raw, unnormalized ratings in terms of fixed effects of *antonym type* (morphological vs. lexical), *adjective type* (Helmert coded in order: antonym, negated positive, negated antonym, positive)
<!-- ^[ -->
<!--  We coded adjective type using Helmert coding, which compares levels of a factor to the average of preceding levels, in order to compare *opposite* vs. *negated positive* levels of the adjective type factor. -->
<!-- ]),  -->
and their interaction; the model also included random intercepts and random slopes of *adjective type* by-participant and by-item.
Consistent with our hypothesis, the interaction between the *antonym* vs. *negated positive* levels of adjective type and antonym type (morphological vs.\text{~}lexical) was significant: $\beta = `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","Estimate"],3)`$, $SE =  `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","Std. Error"],4)`$, t$(`r round(rs1.implicit.coef["antonym_typelexant:adj_type1","df"], 1)`) = `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","t value"],2)`, p = `r round(rs1.implicit.coef["antonym_typelexant:adj_type1","Pr(>|t|)"], 4)`$. 
We then analyzed the simple effects.
Morphological antonyms were not significantly different than negated positives $\beta = `r format(rs1.implicit.simple.morph.coef["adj_type1","Estimate"], digits = 2, scientific = T)`$, $SE =  `r round(rs1.implicit.simple.morph.coef["adj_type1","Std. Error"],4)`$, t$(`r round(rs1.implicit.simple.morph.coef["adj_type1","df"], 1)`) = `r round(rs1.implicit.simple.morph.coef["adj_type1","t value"],2)`, p = `r round(rs1.implicit.simple.morph.coef["adj_type1","Pr(>|t|)"], 2)`$, lexical antonyms were significantly more negative than negated positives $\beta = `r -1*round(rs1.implicit.simple.lex.coef["adj_type1","Estimate"],3)`$, $SE =  `r round(rs1.implicit.simple.lex.coef["adj_type1","Std. Error"],3)`$, 
<!-- t$(`r round(rs1.implicit.simple.lex.coef["adj_type1","df"], 1)`) = `r round(rs1.implicit.simple.lex.coef["adj_type1","t value"],2)`,$ -->
$p = `r round(rs1.implicit.simple.lex.coef["adj_type1","Pr(>|t|)"], 4)`$.^[
  The random effect structure for the simple effects models mirrored the full model. The only difference was that in analyzing the lexical antonyms, the random effect of adjective type by-item needed to be dropped in order for the model to converge.
] 

<!-- One first hypothesis concerns the interpretation of morphological antonyms vs.\text{~}lexical antonyms in the absence of explicit alternatives (Figure$\thinspace$\ref{fig:experiment-slides}A). -->
<!-- We predict an interaction between type of negation (antonym vs.\text{~}negated positive) and type of antonym (morphological vs.\text{~}lexical). -->
<!-- Specifically, we predict that interpretations of lexical antonyms will be more negative than negated positives (e.g., somebody who is "sad" is less happy than someone who is "not happy"), whereas there will be no difference between morphological antonyms and negated positives (e.g., "unhappy" = "not happy"). -->


Our second main hypothesis is that context (single vs.\text{~}multiple utterances) modulates the interpretive difference between morphological antonyms and negated positives. 
Specifically, we predict that morphological antonyms will be interpreted more negatively than negated positives in a context with multiple  utterances.
<!-- ; this effect would manifest as an interaction between adjective type (specifically, levels: antonym vs.\text{~}negated positive) and context. -->
To evaluate this hypothesis, we considered data only from the morphological antonyms conditions and built a linear mixed model predicting the raw, unnormalized ratings in terms of adjective type,
<!-- (Helmert coded in order: antonym, negated positive, negated antonym, positive),  -->
context (single vs. multiple utterances) and their interaction; the model also included random intercepts and random slopes of adjective type by-participant and by-item.
This interaction was also significant: $\beta = `r round(rs2.morph.coef["conditionexplicit:adj_type1","Estimate"],3)`$, $SE =  `r round(rs2.morph.coef["conditionexplicit:adj_type1","Std. Error"],4)`$, t$(`r round(rs2.morph.coef["conditionexplicit:adj_type1","df"], 1)`) = `r round(rs2.morph.coef["conditionexplicit:adj_type1","t value"],2)`, p = `r format(rs2.morph.coef["conditionexplicit:adj_type1","Pr(>|t|)"], digits = 3, scientific = T)`$, and in the correct direction (see Fig.\text{~}\ref{fig:expt-results}B).

<!-- Finally, as an exploratory analysis we test the 3-way interaction between adjective type (specically, levels: antonym vs.\text{~}negated positive), antonym type (morphological vs.\text{~}lexical), and context (single vs.\text{~}multiple utterances), using a mixed-effects model with by-participant and by-item random effects of intercept and adjective type. -->
<!-- The 3-way interaction was not significant and numerically in the direction of the multiple utterances context making the difference between antonyms and negated positives more pronounced with lexical antonyms than for morphological antonyms: -->
<!-- $\beta = `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","Estimate"],3)`$, $SE =  `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","Std. Error"],4)`$, t$(`r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","df"], 1)`) = `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","t value"],2)`, p = `r round(rs3.3way.coef["adj_type1:antonym_typelexant:conditionexplicit","Pr(>|t|)"], 4)`$. -->
<!-- \mf{how important is this paragraph? maybe skip?} -->

# Discussion

Many dimensional scales lack units.
Speakers cannot say they are *42 units happy* like they can say they are *6'1" tall*.
Instead, speakers can use modifiers and morphemes to carve more precise meanings from otherwise vague dimensions. 
A person *not unhappy* is neither sad nor truly happy, but residing in some marginally positive state that is difficult to refer to because degrees of happiness lack precise units.

This work resolves an outstanding puzzle in natural language understanding: How to interpret double negatives (e.g., *not unhappy*).
@Krifka2007:Negated-antonyms critiques previous pragmatic theories for either being underdetermined [@Blutner2004:pragmatics] or making the wrong prediction [@Horn1991:Duplex]. 
Here, we propose a theory of negated antonym interpretation by introducing negation into a pragmatic model of adjective interpretation. 
But morphological antonyms (*unhappy*) do not behave like bonafide antonyms (*sad*).
We discovered and confirmed a surprising empirical result that challenges ``established'' intuitions in linguistics: *unhappy* and *not happy* are not immediately differentiated, except when both are present in the same context.
Our model that represents uncertainty about how to parse overt negation markers (*un-*, *not*) predicts this very result, while alternative models that treat negation with a fixed meaning fall short.
While the items used in our experiment were all evaluative statements about people, we think it is not unreasonable to expect the asymmetries observed in our data to generalize to other negated antonyms.

It is noteworthy that we are able to recover, both in our model and empirically, the ordering predicted by @Krifka2007:Negated-antonyms for morphological antonyms when the listener hears multiple adjectival utterances in the same context (multiple utterances condition).
This work thus carries with it an interesting account of a robust linguistic intuition: Potentially equivalent expressions receive differential interpretations when observed uttered by the same speaker in close proximity.
Reasoning about lexical ambiguity, listeners conclude that a choice of different expressions may be most likely for a speaker who differentiates meanings.
This might provide an interesting rationale for *mutual exclusivity biases* [@Clark2009:Lexical-Meaning], something future work could help explore.

Our formalization of lexical uncertainty about the meaning of natural language negation builds on a growing movement to treat the combinatorial rules of grammar as not totally separable from the lexicon [e.g., @bybee2006usage; @Odonnell2015productivity].
Recent psycholinguistic evidence supports the idea that utterances which are heavily used will be processed as unique lexical entries while less frequent phrases will be understood compositionally [@MorganLevy2016:binomials]. 
The two types of negation meaning we considered---contrary and contradiction opposition---can be seen as a *lexicalized* form of opposition (with the adjective receiving its own threshold variable) and a *compositional* rule (logical negation), respectively. 
In our modeling, we assumed all lexica (all logically-possible interpretations of negation) were equally likely: A further test of our negation uncertainty model would be to see if frequency can serve as a proxy for this prior over lexica.

To negate is to make true false, but for statements that are truly vague, the behavior of negation is not so obvious. 
We present a computational explanation for why this is so, and provide empirical data that sheds new light on the age old question of meaning and opposition.

<!-- @Krifka2007:Negated-antonyms critiques previous pragmatic theories for either being underdetermined [@Blutner2004:pragmatics] or making the wrong prediction [@Horn1991:Duplex].  -->
<!-- Using state-of-the-art models of pragmatic language understanding, we are able to precisely articulate the division of pragmatic labor between different utterances available to a speaker for conveying negation. -->
<!-- We hypothesized that uncertainty about the meaning of overt negation markers leads only to a partial ordering of affixal antonyms and their negations (e.g,. *not unhappy* $\approx$ *not happy*).  -->
<!-- We present an explanation for why this is so, and provide empirical data that sheds new light on the age old question of meaning and opposition. -->

<!-- \mht{note also that we don't assume any ordering on interpretations in the semantics for bonafide antonyms. note null utterance? \mf{maybe footnote if we have the space?}} -->

<!-- \mht{discuss languages with "negative concord" (double negations acting as an intensifier)} -->

<!-- \mht{discuss the generality of negation across languages?} -->

<!-- \mht{need to explain what breaks the symmetry in the model} -->

<!-- \mht{politeness, further inferences? (not unhappy -- *normally unhappy in this situation*)} -->
  

\vspace{1em} \fbox{\parbox[b][][c]{7.3cm}{\centering \footnotesize Experimental paradigms, computational models, and data for this paper can be found at \url{mhtess.github.io}.
}} \vspace{1em}
  
# Acknowledgements

This work was supported in part by NSF Graduate Research Fellowship DGE-114747 to MHT.


<!-- Should we parse both types of negation compositionally, then indeed they have same meanings. However, language has the ability to create new lexical entries, with the tokenization of new semantic variables. For instance, \*not tall\* does not imply \"short\" because tall and short have different truth-conditional criteria. -->
    



<!-- To negate is to make true false, but what of statements that are truly vague? When meanings are underspecified, the behavior of negation is not so obvious. If a person is \"not happy\", does that entail they are \"unhappy\"? Natural language provides two kinds of negation: contrary (e.g., not happy) and contradiction (e.g., sad), yet additional forms exist (e.g., unhappy). Are the additional forms redundant, or do they allow speakers, with the help of context, to more finely carve otherwise vague meanings? We investigate basic inferences from natural language negation and double negation by elaborating a computational model of gradable adjective interpretation to handle different kinds of negation. We hypothesize that communicative reasoning and an uncertain *parsing model* combine for listeners to extract fine-grained meanings within vague dimensions. This hypothesis is borne out in, to our knowledge, the first experimental evidence concerning adult interpretation of different kinds of and double negation. -->


# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
