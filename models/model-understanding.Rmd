---
title: "Understanding the model"
output: html_notebook
---


```{r}
library(rwebppl)
library(jsonlite)
library(ggthemes)
library(tidyverse)
library(knitr)
theme_set(theme_few())
```

```{r rsaBins}
rsaBinsCoarse <- '
var lowerBins = [
	0,
  0.01,
  0.1,
  0.2,
  0.3,
  0.4,
  0.5,
  0.6,
  0.7,
  0.8,
  0.9,
  0.99
];

var upperBins = [
  0.01,
  0.1,
  0.2,
  0.3,
  0.4,
  0.5,
  0.6,
  0.7,
  0.8,
  0.9,
  0.99,
  1
];
'
```

```{r rsaBinsFine}
rsaBinsFine <- '
var lowerBins = [
	0,
  0.01,
  0.05,
  0.1,
  0.15,
  0.2,
  0.25,
  0.3,
  0.35,
  0.4,
  0.45,
  0.5,
  0.55,
  0.6,
  0.65,
  0.7,
  0.75,
  0.8,
  0.85,
  0.9,
  0.95,
  0.99
];

var upperBins = [
  0.01,
  0.05,
  0.1,
  0.15,
  0.2,
  0.25,
  0.3,
  0.35,
  0.4,
  0.45,
  0.5,
  0.55,
  0.6,
  0.65,
  0.7,
  0.75,
  0.8,
  0.85,
  0.9,
  0.95,
  0.99,
  1
];
'
```

```{r utils}
utils <- '
var round = function(x){
  return Math.round(x*100)/100
}

var isNegation = function(utt){
  return (utt.split("_")[0] == "not")
};

var hasNegModifier = function(utt){
  return (utt.split("_")[0] == "not")
};
var hasNegMorph = function(utt){
  return (utt.indexOf("un") > -1)
};
var roundTo3 = function(x){
  return Math.round(x * 1000) / 1000
}

var midBins = map2(function(b1,b2){
  return roundTo3((b2 - b1)/2 + b1)
}, lowerBins, upperBins)

var thetaBins = map2(function(b1, b2){
  return roundTo3((b2-b1)/2 + b1);
}, midBins.slice(0, midBins.length-1), midBins.slice(1))

var avoidEnds = function(x){
  return x >= 1 ? 0.99 : x == 0 ? 0.01 : x
}

var lb = 0, ub = 1, diff = 0.05;
var bins = _.range(lb, ub + diff, diff)

var DiscreteGaussian = function(mu, sigma){
  Infer({model: function(){
    categorical({
      vs:midBins,
      ps:map(function(x){Math.exp(Gaussian({mu, sigma}).score(x))}, midBins)
    })
  }})
}

var DiscreteBeta = cache(function(a, b){
  Infer({model: function(){
    categorical({
      vs:midBins,
      ps:map(function(x){
        // var xi = x >= 1 ? 0.99 : x == 0 ? 0.01 : x
        Math.exp(Beta({a, b}).score(x))
      }, midBins)
    })
  }})
})
'
```

```{r meaningFn}
meaningFn <- '
var meaning = function(words, state, thresholds){
  return words == "happy" ? state > thresholds.happy :
  words == "not_happy" ? !(state > thresholds.happy) :
  words == "unhappy" ? state < thresholds.unhappy :
  words == "not_unhappy" ? !(state < thresholds.unhappy) :
  words == "sad" ? state < thresholds.sad :
  words == "not_sad" ? !(state < thresholds.sad) :
  words == "neither_nor" ? (
    !(state > thresholds.happy) &&
    !(state < thresholds.unhappy)
  ) :
  true
};
'
```

# Separate thresholds RSA

```{r rsa-separateThresholds}
rsa <- '
var utterances = [
  "happy",
  "not_unhappy",
  "not_happy",
  "unhappy",
  // "neither_nor"
];

var individualCosts = {
  happy: 0,
  unhappy: 0.5,
  not_happy: 1,
  not_unhappy: 1.5
}


var utteranceCost = function(u, cost_neg){
  var cost_yes = 1;
 return isNegation(u) ? cost_neg : cost_yes
}

// var uttCosts = map(function(u) {
  // return isNegation(u) ? Math.exp(-cost_neg) : Math.exp(-cost_yes)
  // return Math.exp(-individualCosts[u])
// }, utterances)

// var utterancePrior = Infer({model: function(){
  // return utterances[discrete(uttCosts)]
// }});


var listener0 = cache(function(utterance, thresholds) {
  Infer({model: function(){
    var state = sample(DiscreteBeta(1, 1));
    // var state = sample(DiscreteGaussian(0.5, 0.2));
    var m = meaning(utterance, state, thresholds);
    condition(m);
    return state;
  }})
}, 10000);

var singleAdj_speaker1 = cache(function(state, thresholds) {
  Infer({model: function(){
    var utterance = flip(0.4) ? "happy" : "silence";
    var L0 = listener0(utterance, thresholds);
    factor(speakerOptimality*L0.score(state));
    return utterance;
  }})
}, 10000);

var speaker1 = cache(function(state, thresholds, opts) {
  Infer({model: function(){
    var utterance = uniformDraw(utterances);
    var cost = utteranceCost(utterance, opts.cost_neg)
    var L0 = listener0(utterance, thresholds);
    var utility = opts.multiplicative_cost ? L0.score(state) * cost : L0.score(state) - cost;
    factor(opts.speaker_optimality*utility);
    return utterance;
  }})
}, 10000);

var greaterThanThresholdBins = _.range(lb, ub, diff)
var lessThanThresholdBins = _.range(lb+diff, ub+diff, diff)

var listener1 = cache(function(utterance, opts) {
  Infer({model: function(){
    var thresholds = {
      happy: uniformDraw(thetaBins),
      unhappy: uniformDraw(thetaBins)
    }

    var state = sample(DiscreteBeta(1, 1));
    // var state = sample(DiscreteGaussian(0.5, 0.2));

    var S1 = speaker1(state, thresholds, opts)
    observe(S1, utterance)
    return state
  }})
}, 10000);
'
```


```{r wpplCalls}
listenerCall <- '
var statePrior = DiscreteBeta(1, 1)
_.flatten(
  map(function(opts){
    map(function(u){
      // display(opts)
      var post = listener1(u, opts)
      map(function(s){
        return extend(opts, {utterance: u, state: s, posterior_prob: Math.exp(post.score(s))})
      }, sort(statePrior.support()))
    }, utterances)
  }, all_opts)
)
'

speakerCall <- '
_.flatten(_.flatten(
map(function(tH){
  map(function(tU){
    map(function(s){
       // console.log(s + " th " + tH + " tu " + tU)
      var speakProbs = speaker1(s, {happy: tH, unhappy: tU})
       return {  
          state: s,
          happy_theta:tH, 
          unhappy_theta:tU, 
          "happy": Math.exp(speakProbs.score("happy")),
          "unhappy": Math.exp(speakProbs.score("unhappy")),
          "not_unhappy": Math.exp(speakProbs.score("not_unhappy")),
          "not_happy": Math.exp(speakProbs.score("not_happy"))
        }
    }, midBins)
//   }, [0.5])
  }, thetaBins)
}, thetaBins)
))
'

singleAdjSpeakerCall <- '
_.flatten(
map(function(tH){
    map(function(s){
       // console.log(s + " th " + tH + " tu " + tU)
      var speakProbs = singleAdj_speaker1(s, {happy: tH, unhappy: -99})
       return {  
          state: s,
          happy_theta:tH, 
          "happy": Math.exp(speakProbs.score("happy")),
          "silence": Math.exp(speakProbs.score("silence"))
        }
    }, midBins)
}, thetaBins)
)
'

literalListenerCall <- '
_.flatten(map(function(tH){
    var listenerProbs = listener0("happy", {happy: tH, unhappy: -99})
    return map(function(s){
      return {  
            state: s,
            happy_theta:tH, 
            "l0": Math.exp(listenerProbs.score(s))
          }
    }, midBins)
}, thetaBins))
'
```

## Speaker and literal listener runs

```{r runSpeaker}
rs.wp <- webppl(paste(rsaBinsCoarse, utils, meaningFn, rsa, speakerCall,  sep = '\n'))

rs.tidy <- data.frame(rs.wp) %>%
  gather(utt, prob, -state, -happy_theta, -unhappy_theta)
```


```{r runliteral}
rs.wp.l0 <- webppl(paste(rsaBinsCoarse, utils, meaningFn, rsa, literalListenerCall,  sep = '\n'))
rs.wp.singleAdjSpeaker <- webppl(paste(rsaBinsCoarse, utils, meaningFn, rsa, singleAdjSpeakerCall,  sep = '\n'))
rs.tidy.singleAdjSpeaker <- data.frame(rs.wp.singleAdjSpeaker) %>%
  gather(utt, prob, -state, -happy_theta)
```



Faceting by thresholds
```{r facet-threshold}
ggplot(rs.tidy %>%
         # filter((happy_theta == 0.103 & unhappy_theta == 0.6) |
         #          (happy_theta == 0.6 & unhappy_theta == 0.103)) %>%
         filter((happy_theta == 0.3 & unhappy_theta == 0.6) |
                  (happy_theta == 0.6 & unhappy_theta == 0.3)) %>%
         mutate(utt = factor(utt,
                            levels = rev(c("not_unhappy",
                                       "not_happy",
                                       "unhappy",
                                       "happy")),
                          labels = rev(c("not unhappy","not happy",  "unhappy", "happy")))), 
       aes( x = state, y = prob, color = utt))+
  geom_line(size = 1.5, alpha = 0.9)+#aes(frame = happy_theta))+
  scale_color_solarized()+
  theme_black()+
  facet_wrap(~happy_theta+ unhappy_theta)+
  ylab("Speaker production probability")+
  xlab("Height")+
  scale_x_continuous(breaks = c(0, 1))+
  scale_y_continuous(breaks = c(0, 1))+
  theme(strip.text.y = element_text(angle = 0))

ggsave(paste(fig.path, "model_S1_fixedThetas_2configs.pdf",  sep = ""),
       width = 7, height = 3)
```

with fixed unhappy_theta

**Broken**

```{r}
rs.tidy %>%
  filter(unhappy_theta == 0.2) %>%
   mutate(utt = factor(utt,
                      levels = rev(c("not_unhappy",
                                 "not_happy",
                                 "unhappy",
                                 "happy")),
                    labels = rev(c("not unhappy","not happy",  "unhappy", "happy")))) %>% 
  ggplot(., aes( x = state, y = prob, color = utt))+
  geom_line(size = 2)+
  scale_color_solarized()+
  theme_black()+
  scale_x_continuous(breaks = c(0, 0.5, 1))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  theme(text = element_text(size = 16))+
  labs(title = "'unhappy' threshold = 0.2; 'happy' threshold =: {frame_time}", 
       x = "happiness (normalized scale)", y = "Speaker production probability") +
  transition_time(happy_theta) +
  ease_aes('linear')

#animate(fig.theta.marg, fps = 1/0.3, ani.width=500, ani.height=400)
# anim_save( paste(fig.path,"S1_unhappyTheta0.5.gif", sep = ""))

#ggsave("figs/S1_uttXstateXthetas_wCost.pdf", width = 20, height = 14)
```

### literal listener with moving happy threhsolds

```{r}
fig.l0.mov <- rs.wp.l0 %>%
  ggplot(., aes( x = state, y = l0, frame = happy_theta))+
  geom_line(size = 2)+
  #geom_vline(aes(xintercept = happy_theta), lty = 3)+
  scale_x_continuous(breaks = c(0, 0.5, 1))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  ggtitle("'tall' threshold = ")+
  ylab("Literal posterior probability")+
  xlab("Height (normalized scale)")+
  theme(text = element_text(size = 16))

# gganimate(fig.l0.mov, interval = 0.6, 
#           ani.width=500, ani.height=400, paste("~/Documents/research/talks/vagueness/frisem-2018-01/img/L0.gif", sep = ""))


rs.wp.l0 %>%
  filter(happy_theta %in% c(0.200, 0.5, 0.8)) %>%
  ggplot(., aes( x = state, y = l0 ))+
  geom_line(size = 2, color = 'white')+
  facet_wrap(~happy_theta) +
  theme_black()+
  #geom_vline(aes(xintercept = happy_theta), lty = 3)+
  scale_x_continuous(breaks = c(0, 1))+
  scale_y_continuous(breaks = c(0, 0.3))+
  ylab("Posterior probability mass")+
  xlab("Happiness (normalized scale)")+
  #ggtitle("Literal interpretations for 3 thresholds")+
  theme(text = element_text(size = 16))

#ggsave( paste(fig.path,"L0_3thetas.pdf", sep = ""), width = 7, height = 3)

```


```{r}
rs.tidy.singleAdjSpeaker %>%
    filter(happy_theta %in% c(0.200, 0.5, 0.8),
           !(state %in% c(0.005, 0.995))) %>%
      mutate(utt = factor(utt,
                            levels = c("happy",
                                       "silence"),
                          labels = c("happy", "null"))) %>%
  ggplot(., aes( x = state, y = prob, fill = utt))+
  geom_col(position = position_dodge())+
  scale_fill_solarized()+
  theme_black()+
  facet_wrap(~happy_theta)+
  scale_x_continuous(breaks = c(0, 1))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  ylab("Speaker production probability")+
  xlab("Degree of happiness")+
  theme(text = element_text(size = 16))
ggsave( paste(fig.path,"S1_3thetas.pdf", sep = ""), width = 7, height = 3.7)

```

### single adjective speaker with moving threshold

```{r}
fig.s1.singleadj.marg <- rs.tidy.singleAdjSpeaker %>%
      mutate(utt = factor(utt,
                            levels = c("happy",
                                       "silence"),
                          labels = c("happy", "null"))) %>%
  ggplot(., aes( x = state, y = prob, fill = utt))+
  geom_col(aes(frame = happy_theta), color = 'black', position = position_dodge())+
  scale_fill_solarized()+
  scale_x_continuous(breaks = c(0, 0.5, 1))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  ggtitle("'tall' threshold = ")+
  ylab("Speaker production probability")+
  xlab("Height (normalized scale)")+
  theme(text = element_text(size = 16))

# gganimate(fig.s1.singleadj.marg, interval = 0.3, 
#           ani.width=500, ani.height=400, paste("~/Documents/research/talks/vagueness/frisem-2018-01/img/S1_singleAdj.gif", sep = ""))

```

Marginalizing out thresholds

```{r marginalize.thresholds}
rs.marginal <- rs.tidy %>%
  group_by(state, utt) %>%
  summarize(marginalProb = mean(prob)) %>%
        mutate(utt = factor(utt,
                            levels = c("unhappy",
                                       "not_happy",
                                       "not_unhappy",
                                       "happy")))


ggplot(rs.marginal, aes( x = state, y = marginalProb, color = utt))+
  geom_line(size = 1.2)+
  scale_color_solarized()+
  xlab("Degree of happiness")+
  ylab("Speaker utterance production probability")+
  scale_x_continuous(breaks =c(0, 1))+
  scale_y_continuous(breaks = c(0, 0.5))

#ggsave("figs/S1_uttMarginals_wCost3_alpha1.png", width = 6, height = 3.7)
```



## Pragmatic listener runs

"Not Unhappy" is semantically equivalent to "happy". The higher the state, the more likely "happy" (and "not unhappy") is to be produced by a speaker (because it's more likely to be true, given the uniform priors on thresholdse). 

In the midpoint, "happy" / "not unhappy" is less true, and "unhappy"/ "not happy" is more true. 

```{r runListener}

pragListener.params <- expand.grid(
  speaker_optimality = c(1, 3, 5, 10),
  cost_neg = c(1, 3, 5, 10),
  multiplicative_cost = c(T, F)
)

rs.listener.wp.tidy <- webppl(paste(rsaBinsCoarse,utils, 
                               meaningFn, rsa, 
                               listenerCall,  sep = '\n'),
                         data = pragListener.params,
                         data_var = "all_opts")

rs.listener.wp.tidy.samples <- get_samples(bind_rows(rs.listener.wp.tidy) %>% rename(prob = posterior_prob), 10000) %>%
         mutate(utterance = factor(utterance,
                            levels = rev(c("not_unhappy",
                                       "not_happy",
                                       "unhappy",
                                       "happy")),
                          labels = rev(c("not unhappy","not happy",  "unhappy", "happy"))))




ggplot(rs.listener.wp.tidy.samples %>%
         filter(multiplicative_cost),
         # mutate(utterance = factor(utterance, levels = c("happy"),
         #                           labels = c("tall"))), 
       aes( x = state, fill = utterance, color = utterance))+
  # geom_density(alpha = 0.4, size = 1.3, aes(x=x),data = 
  #                data.frame(x = rnorm(n = 10000, 
  #                                     mean = 0.5, sd = 0.2),
  #                           utterance = "prior"))+
  geom_density(alpha = 0.5, size = 1.3, adjust = 3)+
  scale_fill_solarized()+
  scale_color_solarized()+
  facet_grid(speaker_optimality~cost_neg)+
  # scale_fill_manual(values = c("#e41a1c"))+
  # scale_color_manual(values = c("#e41a1c"))+
  #scale_color_manual(values = c("#268bd2", "#859900"))+
  #guides(fill = F, color = F)+
  xlab("Happiness (normalized scale)")+
  ylab("Posterior probability density")+
  #theme_black()+
  scale_x_continuous(breaks =c(0, 1), limits = c(0, 1))+
  #scale_y_continuous(breaks = c(0, 2))+
  theme(legend.title = element_blank())

# ggsave(paste(fig.path, "model_L1_wCost3_alpha1.pdf",  sep = ""),
#        width = 5.5, height = 3.5)
# ggsave(paste(fig.path, "model_L1_happy_wCost3_alpha1.pdf",  sep = ""),
#        width = 5.5, height = 3.5)
#ggsave(paste("~/Documents/research/talks/vagueness/frisem-2018-01/img/L1_singleAdj_gaussian.pdf", sep = ""), width = 6, height = 4)
#ggsave("figs/L1_posteriors_wCost3_alpha1.png", width = 6, height = 4)
```


```{r}
rs.listener.wp.tidy %>%
  group_by(utterance) %>%
  summarize(interpretation = sum(probs * support)) %>%
    mutate(utterance = factor(utterance,
                            levels = c("unhappy",
                                       "not_happy",
                                       "not_unhappy",
                                       "happy"))) %>%
  ggplot(., aes( x = utterance, y=interpretation,
                 fill = utterance, color = utterance))+
    geom_col(position = position_dodge(0.8), 
             width = 0.8,
             alpha =0.8, color = 'black')+
    #coord_flip()+
  geom_hline(yintercept = 0.5, lty = 3)+
  scale_fill_solarized()+
  guides(fill = F)+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  xlab("")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

#ggsave("figs/L1_means_wCost3_alpha1.png", width = 4, height = 3.5)
```

```{r}
rs.listener.wp.tidy %>%
  group_by(utterance) %>%
  summarize(interpretation = sum(probs * support)) %>%
  kable()
```



# Uncertain "has threshold" RSA

01/16/18: This is being refashioned to be analagous to the "uncertain parsing" model (yet to be implemented)

```{r rsa-uncertainHasThresholds}
uncertainHasThresholdsRSA <- '
var utterances = [
  "happy",
  "not_unhappy",
  "not_happy",
  "unhappy"
  // "silence"
  // "neither_nor"
];

var cost_yes = 0;
var cost_not = 2;
var cost_un = 2;

var uttCosts = map(function(u) {
  var notCost = hasNegModifier(u) ? cost_not : 0
  var unCost = hasNegMorph(u) ? cost_un : 0
  var totalCost = notCost + unCost
  return Math.exp(-totalCost)
}, utterances)

var utterancePrior = Infer({model: function(){
  return utterances[discrete(uttCosts)]
}});

var speakerOptimality = 1;
var speakerOptimality2 = 1;

var meaning = function(words, state, thresholds, parsing){
  words == "happy" ? state > thresholds.happy :
  words == "not_happy" ? parsing.compositional_not ? 
      !(state > thresholds.happy) :
      (state < thresholds.not_happy) :
  words == "unhappy" ? parsing.compositional_un ? 
      !(state > thresholds.happy) :
      (state < thresholds.unhappy) :
  // words == "not_unhappy" ? parsing.compositional_not ? 
  //    parsing.compositional_un ? (state > thresholds.happy) :
  //    !(state < thresholds.unhappy) : 
  //    (state > thresholds.not_unhappy) :
  words == "not_unhappy" ? parsing.compositional_un ? 
    (state > thresholds.happy) : !(state < thresholds.unhappy) : 
  words == "sad" ? state < thresholds.sad :
  words == "not_sad" ? !(state < thresholds.sad) :
  words == "neither_nor" ? (
    !(state > thresholds.happy) &&
    !(state < thresholds.unhappy)
  ) :
  true
};

var compositional_un_prior = 0.5;
var compositional_not_prior = 0.5;
// var compositional_un_prior = 1;
// var compositional_not_prior = 1;
// var un_not_lexical_prior = not_lexical_prior*un_lexical_prior;

var listener0 = cache(function(utterance, thresholds, parsing) {
  Infer({model: function(){
    var state = sample(DiscreteBeta(1, 1));
    // display(JSON.stringify(thresholds))
    // var state = sample(DiscreteGaussian(0, 0.5));
    var m = meaning(utterance, state, thresholds, parsing);
   // display("l0 " + state + " " + m + " " + JSON.stringify(parsing))
    condition(m);
    return state;
  }, method: "enumerate"})
}, 10000);

var speaker1 = cache(function(state, thresholds, parsing) {
  Infer({model: function(){
    var utterance = sample(utterancePrior);
    // display(utterance)
    var L0 = listener0(utterance, thresholds, parsing);
    factor(speakerOptimality*L0.score(state));
    return utterance;
  }, method: "enumerate"})
}, 10000);

var listener1 = cache(function(list_of_utterances) {
  Infer({model: function(){

    var happy_threshold = uniformDraw(thetaBins);
    var compositional_un = flip(compositional_un_prior)
    // var compositional_not = utterance == "not_unhappy" && compositional_un ? true :  flip(compositional_not_prior)
    var compositional_not = flip(compositional_not_prior)
    
    var unhappy_threshold = compositional_un ? "happy_threshold" : uniformDraw(thetaBins)
    var not_happy_threshold = compositional_not ? "happy_threshold" : uniformDraw(thetaBins);
    var not_unhappy_threshold = -99;
// compositional_not ? compositional_un ? "happy_threshold" : 
//  "unhappy_threshold" : uniformDraw(thetaBins)

    var thresholds = {
      happy: happy_threshold,
      unhappy: unhappy_threshold,
      not_happy: not_happy_threshold,
      not_unhappy: not_unhappy_threshold
    }

    var parsing = {compositional_un, compositional_not}

   // var state = sample(DiscreteBeta(1, 1));
    // var state = sample(DiscreteGaussian(0, 0.5));
   var state = repeat(list_of_utterances.length, 
      function(){ sample(DiscreteBeta(1, 1)) })
      
     map2(function(u, s){
      // display(s)
       var S1 = speaker1(s, thresholds, parsing)
      // display(u + " " + S1.score(u))
       observe(S1, u)
    }, list_of_utterances, state)

    return extend(parsing, {state: _.fromPairs(_.zip(list_of_utterances, state))})
    
    // var S1 = speaker1(state, thresholds, parsing)
    // observe(S1, list_of_utterances)
    // return extend(parsing, {state})
  }, method: "enumerate"})
}, 10000);
'
```

```{r wpplCalls-uncertainHasThresholds}
uncertainHasThresholdListenerCall <- '
_.fromPairs(map(function(u){
  display(u)
  var post = listener1([u])
  display(u + " __ Comp(un) = " + expectation(post, function(x){return x.compositional_un}))
  display(u + " __ Comp(not) = " + expectation(post, function(x){return x.compositional_not}))
  return [u, post]
//  return [u, marginalize(post, "state")]
}, utterances))
'
#uncertainHasThresholdListenerCall<- 'listener1("unhappy")'
```


```{r multipleUtterancesModelCall}
multipleUtterancesListenerCall <- '
// var post = listener1(["happy", "not_happy", "unhappy", "not_unhappy"])
//var post = listener1(["not_unhappy", "unhappy","not_happy", "happy"])
var post = listener1(["not_unhappy", "unhappy","not_happy", "happy"])
display(" __ comp(un) = " + expectation(post, function(x){return x.compositional_un }))
display(" __ comp(not) = " + expectation(post, function(x){return x.compositional_not }))
//marginalize(post, "state")
post
'
```

```{r runUncertainHasThresholdListener}
rs.listener.wp.2 <- webppl(paste(rsaBinsCoarse,
                                 utils, uncertainHasThresholdsRSA,
                                 #uncertainHasThresholdListenerCall, 
                                 multipleUtterancesListenerCall, # takes 6 min to run
                                 sep = '\n'))

# rs.listener.wp.tidy.2 <- bind_rows(
#   data.frame(rs.listener.wp.2$happy) %>%
#     mutate(utterance = "happy") %>%
#     rename(support.state = support.state.happy),
#   data.frame(rs.listener.wp.2$unhappy) %>%
#     mutate(utterance = "unhappy")%>%
#     rename(support.state = support.state.unhappy),
#   data.frame(rs.listener.wp.2$not_unhappy) %>%
#     mutate(utterance = "not_unhappy")%>%
#     rename(support.state = support.state.not_unhappy),
#   data.frame(rs.listener.wp.2$not_happy) %>%
#     mutate(utterance = "not_happy")%>%
#     rename(support.state = support.state.not_happy)
# ) %>%
#   rename(prob = probs)

rs.listener.wp.tidy.2 <- rs.listener.wp.2 %>%
  gather(utterance, support.state, starts_with("state")) %>%
  mutate(utterance = gsub("state.","", utterance))

rs.listener.wp.tidy.samples.2 <- get_samples(rs.listener.wp.tidy.2 %>% 
    group_by(utterance, support.state) %>%
    summarize(prob = sum(prob)) %>%
    ungroup(), 10000) %>%
    #rename(prob = probs), 10000) %>%
    mutate(utterance = factor(utterance,
                            levels = rev(c("not_unhappy",
                                       "not_happy",
                                       "unhappy",
                                       "happy")),
                          labels = rev(c("not unhappy","not happy",  "unhappy", "happy"))))

ggplot(rs.listener.wp.tidy.samples.2, 
       aes( x = support.state,fill = utterance, color = utterance))+
  geom_density(alpha = 0.4, size = 1.3, adjust = 3)+
  scale_fill_solarized()+
  theme_black()+
#  geom_histogram(alpha = 0.4, size = 1.3)+
  scale_color_solarized()+
  xlab("Degree of happiness")+
  #facet_wrap(~utterance)+
  ylab("Posterior probability density")+
  scale_x_continuous(breaks =c(0, 1))+
  scale_y_continuous(breaks = c(0, 2))

ggsave(paste(fig.path, "model_L1_uncertainNeg_wCost3_alpha1_4utts.pdf",  sep = ""),
       width = 5.5, height = 3.5)
#ggsave("figs/L1_posteriors_wCost3_alpha1.png", width = 6, height = 4)
```

```{r}

rs.listener.wp.tidy.2 %>%
  select(support.compositional_not, support.compositional_un, utterance, prob) %>%
  mutate(probs = as.numeric(as.character(prob))) %>%
  #unique() %>%
  gather(key, val, -utterance, -prob) %>%
  group_by(key, val, utterance) %>%
  summarize(marginalprob = sum(prob)) %>%
  ungroup() %>%
  mutate(parsed_meaning = factor(key,
                                 levels = c("support.compositional_not",
                                            "support.compositional_un"),
                                 labels = c("not...", "un-"))) %>%
      mutate(utterance = factor(utterance,
                            levels = rev(c("not_unhappy",
                                       "not_happy",
                                       "unhappy",
                                       "happy")),
                          labels = rev(c("not unhappy","not happy",  "unhappy", "happy")))) %>% 
  filter(val == TRUE) %>%
  ggplot(., aes(x = utterance, y = marginalprob, group = parsed_meaning, 
                alpha = parsed_meaning,
                fill = utterance))+
  geom_col(position = position_dodge(), color = 'white')+
  theme_black()+
  guides(alpha = guide_legend(title = ""))+
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "white")+
  scale_alpha_manual(values = c(0.6, 1))+
    scale_fill_solarized()+
  scale_y_continuous(limits = c(0, 0.75), breaks = c(0, 0.75))+
  ylab("Probability of compositional interpretation")

ggsave(paste(fig.path, "model_L1_uncNeg_lexicon_wCost3_alpha1.pdf",  sep = ""),
       width = 5.5, height = 4)

```

```{r}
rs.listener.wp.tidy.2 %>%
  group_by(utterance) %>%
  summarize(interpretation = sum(probs * support)) %>%
    mutate(utterance = factor(utterance,
                            levels = c("unhappy",
                                       "not_happy",
                                       "not_unhappy",
                                       "happy"))) %>%
  ggplot(., aes( x = utterance, y=interpretation,
                 fill = utterance, color = utterance))+
    geom_col(position = position_dodge(0.8), 
             width = 0.8,
             alpha =0.8, color = 'black')+
    #coord_flip()+
  geom_hline(yintercept = 0.5, lty = 3)+
  scale_fill_solarized()+
  guides(fill = F)+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  xlab("")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

#ggsave("figs/L1_means_wCost3_alpha1.png", width = 4, height = 3.5)
```
```{r}
rs.listener.wp.tidy.2 %>%
  group_by(utterance) %>%
  summarize(interpretation = sum(probs * support)) %>%
    mutate(utterance = factor(utterance,
                            levels = c("unhappy",
                                       "not_happy",
                                       "not_unhappy",
                                       "happy"))) %>% 
  kable(.)
```


#### parameters

- lower the lexical "un-" probability
  - the more "unhappy" and "not happy" get squished together, but also "not unhappy" and "happy"
- including "un" cost
  - bring "unhappy" and "not happy" closer together than "happy" and "not unhappy"
  - with speaker opt = 1
    - "happy" looks kind of weak?
  - with higher speaker optimality:
    - "not unhappy" > "happy" (because super costly)



# Uncertain alternatives RSA

```{r rsa-uncertainAlternatives}
uncertainAlternativesRSA <- '
 var forms = [
  "pos",
  "ant",
  "neg_pos",
  "neg_ant",
  "neither_nor"
 ];

var form_costs = {
  pos: 0,
  ant: 0,
  neg_pos: 1.5,
  neg_ant: 1.5
}

var meaning = function(form, state, thresholds){
  return form == "pos" ? state > thresholds.pos :
  form == "neg_pos" ? !(state > thresholds.pos) :
  form == "ant" ? state < thresholds.ant :
  form == "neg_ant" ? !(state < thresholds.ant) :
  form == "neither_nor" ? (
    !(state > thresholds.pos) &&
    !(state < thresholds.ant)
  ) :
  true
};

var AlternativesPrior = Categorical({
  vs :[
    // {happy: "pos", unhappy: "ant", not_happy: "neg_pos", not_unhappy: "neg_ant"},
    // {happy: "pos", sad: "ant", not_happy: "neg_pos", not_sad: "neg_ant"},
    // {happy: "pos", sad: "ant", unhappy: "neg_pos", not_sad: "neg_ant"},
    {utterances: {pos: "happy", ant: "unhappy", neg_pos: "not_happy", neg_ant: "not_unhappy"},
name: "alt1"},
    {utterances: {pos: "happy", ant: "sad", neg_pos: "not_happy", neg_ant: "not_sad"}, name: "alt2"},
    {utterances: {pos: "happy", ant: "sad", neg_pos: "unhappy", neg_ant: "not_sad"}, name: "alt3"}
  ],
  ps: alternativesPriorProbs // [1, 1, 1]
})

var getThresholds = function(utterances){
  var positiveForms = filter(function(u){
    return !(hasNegModifier(u))
  }, utterances)
  return _.fromPairs(map(function(u){
    return [u, uniformDraw(thetaBins)]
  }, positiveForms))
}

var cost_yes = 0;
var cost_not = 3;
var cost_un = 0;

// cost based on string
// var uttCosts = function(utterances){
//  return map(function(u) {
//    var notCost = hasNegModifier(u) ? cost_not : 0
//    var unCost = hasNegMorph(u) ? cost_un : 0
//    var totalCost = notCost + unCost
//    return Math.exp(-totalCost)
//  }, utterances)
//}

// cost based on form
var uttCosts = function(utterance_forms){
  return map(function(u) {
    return Math.exp(-form_costs[u])
  }, utterance_forms)
}

var getUtterancePrior = cache(function(utterance_forms){
  // var utterances = _.values(utterance_forms); // cost based on string
  var utterances = _.keys(utterance_forms); // cost based on form
  var uttProbs = uttCosts(utterances);
  return Categorical({vs: _.keys(utterance_forms), ps: uttProbs})
})

var speakerOptimality = 1;

var listener0 = cache(function(utterance_form, thresholds) {
  Infer({model: function(){
    var state = sample(DiscreteBeta(1, 1));
    // var state = sample(DiscreteGaussian(0, 0.5));
    var m = meaning(utterance_form, state, thresholds);
    condition(m);
    return state;
  }})
}, 10000);

var speaker1 = cache(function(state, thresholds, formToUttMapping) {
  Infer({model: function(){
    var UtterancePrior = getUtterancePrior(formToUttMapping);
    var utterance_form = sample(UtterancePrior);
    var utterance = formToUttMapping[utterance_form];
    // console.log(utterance)
    // console.log(utterance_form)
    var L0 = listener0(utterance_form, thresholds);
    factor(speakerOptimality*L0.score(state));
    return utterance;
  }})
}, 10000);

var listener1 = cache(function(utterance) {
  Infer({model: function(){

    var formToUttMapping = sample(AlternativesPrior)
    var thresholds = {pos: uniformDraw(thetaBins), ant: uniformDraw(thetaBins)}

    var state = sample(DiscreteBeta(1, 1));
    // var state = sample(DiscreteGaussian(0, 0.5));

    var S1 = speaker1(state, thresholds, formToUttMapping.utterances)
    observe(S1, utterance)
     return state
    // return  {alternativeSet: formToUttMapping.name, state: state}
  }})
}, 10000);
'
```

```{r wpplCalls-uncertainAlternatives}
uncertainAlternativesListenerCall <- '
_.fromPairs(map(function(u){
  var post = listener1(u)
  return [u, post]
}, ["happy", "unhappy", "not_unhappy", "not_happy"]))
'
```

```{r runUncertainAlternativesListener}
rs.listener.wp.2 <- webppl(paste(utils, uncertainAlternativesRSA, uncertainAlternativesListenerCall,  sep = '\n'),
                           data = c(1,5,5), data_var = "alternativesPriorProbs")
```


```{r}
rs.listener.wp.tidy.2 <- bind_rows(
  data.frame(rs.listener.wp.2$happy) %>% 
    mutate(utterance = "happy"),
  data.frame(rs.listener.wp.2$unhappy) %>% 
    mutate(utterance = "unhappy"),
  data.frame(rs.listener.wp.2$not_unhappy) %>% 
    mutate(utterance = "not_unhappy"),
  data.frame(rs.listener.wp.2$not_happy) %>% 
    mutate(utterance = "not_happy")
)

rs.listener.wp.tidy.samples.2 <- get_samples(
  rs.listener.wp.tidy.2 %>% rename(prob = probs), 10000) %>%
    mutate(utterance = factor(utterance,
                            levels = c("unhappy",
                                       "not_happy",
                                       "not_unhappy",
                                       "happy")))

# ggplot(rs.listener.wp.tidy.samples.2, 
#        aes( x = support.state, fill = support.alternativeSet, color = support.alternativeSet))+
#   geom_density(alpha = 0.4, size = 1.3)+
#   scale_fill_solarized()+
#   scale_color_solarized()+
#   facet_wrap(~utterance)+
#   xlab("Degree of happiness")+
#   ylab("Posterior probability density")+
#   scale_x_continuous(breaks =c(0, 1))+
#   scale_y_continuous(breaks = c(0, 2))

ggplot(rs.listener.wp.tidy.samples.2, 
       aes( x = support,fill = utterance, color = utterance))+
  geom_density(alpha = 0.4, size = 1.3)+
  scale_fill_solarized()+
  scale_color_solarized()+
  xlab("Degree of happiness")+
  ylab("Posterior probability density")+
  scale_x_continuous(breaks =c(0, 1))+
  scale_y_continuous(breaks = c(0, 2))

#ggsave("figs/L1_posteriors_wCost3_alpha1.png", width = 6, height = 4)
#head(rs.listener.wp.2)
```

Uncertainty about the alterantive set (and whether or not unhappy has its own threshold), does make "unhappy" have a weaker (negative) interpretation. However, the model infers that the "compositional unhappy" is relatively unlikely, which dampens this effect.


```{r}
rs.listener.wp.tidy.2 %>%
  group_by(utterance) %>%
  summarize(interpretation = sum(probs * support)) %>%
    mutate(utterance = factor(utterance,
                            levels = c("unhappy",
                                       "not_happy",
                                       "not_unhappy",
                                       "happy"))) %>%
  ggplot(., aes( x = utterance, y=interpretation,
                 fill = utterance, color = utterance))+
    geom_col(position = position_dodge(0.8), 
             width = 0.8,
             alpha =0.8, color = 'black')+
    #coord_flip()+
  geom_hline(yintercept = 0.5, lty = 3)+
  scale_fill_solarized()+
  guides(fill = F)+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  xlab("")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

#ggsave("figs/L1_means_wCost3_alpha1.png", width = 4, height = 3.5)
```



```{r}
rs.listener.wp.tidy.2 %>%
  group_by(utterance) %>%
  summarize(interpretation = sum(probs * support)) %>%
  kable()
```


## Parameter exploration

Fixed alternatives model: 
- cost to "un": makes "unhappy more extreme"


# Uncertain parser RSA

```{r rsa-uncertainParser}
uncertainAlternativesRSA <- '
 var forms = [
  "pos",
  "ant",
  "neg_pos",
  "neg_ant",
  "neither_nor"
 ];

var form_costs = {
  pos: 0,
  ant: 0,
  neg_pos: 1.5,
  neg_ant: 1.5
}

var meaning = function(form, state, thresholds){
  return form == "pos" ? state > thresholds.pos :
  form == "neg_pos" ? !(state > thresholds.pos) :
  form == "ant" ? state < thresholds.ant :
  form == "neg_ant" ? !(state < thresholds.ant) :
  form == "neither_nor" ? (
    !(state > thresholds.pos) &&
    !(state < thresholds.ant)
  ) :
  true
};

var utterances = [
  "happy", "un_happy", "not_happy", "not_un_happy"
]

var parse = function(utt){
  var split_utt = utt.split("_")

}

var AlternativesPrior = Categorical({
  vs :[
    // {happy: "pos", unhappy: "ant", not_happy: "neg_pos", not_unhappy: "neg_ant"},
    // {happy: "pos", sad: "ant", not_happy: "neg_pos", not_sad: "neg_ant"},
    // {happy: "pos", sad: "ant", unhappy: "neg_pos", not_sad: "neg_ant"},
    {utterances: {pos: "happy", ant: "unhappy", neg_pos: "not_happy", neg_ant: "not_unhappy"},
name: "alt1"},
    {utterances: {pos: "happy", ant: "sad", neg_pos: "not_happy", neg_ant: "not_sad"}, name: "alt2"},
    {utterances: {pos: "happy", ant: "sad", neg_pos: "unhappy", neg_ant: "not_sad"}, name: "alt3"}
  ],
  ps: alternativesPriorProbs // [1, 1, 1]
})

var getThresholds = function(utterances){
  var positiveForms = filter(function(u){
    return !(hasNegModifier(u))
  }, utterances)
  return _.fromPairs(map(function(u){
    return [u, uniformDraw(thetaBins)]
  }, positiveForms))
}

var cost_yes = 0;
var cost_not = 3;
var cost_un = 0;

// cost based on string
// var uttCosts = function(utterances){
//  return map(function(u) {
//    var notCost = hasNegModifier(u) ? cost_not : 0
//    var unCost = hasNegMorph(u) ? cost_un : 0
//    var totalCost = notCost + unCost
//    return Math.exp(-totalCost)
//  }, utterances)
//}

// cost based on form
var uttCosts = function(utterance_forms){
  return map(function(u) {
    return Math.exp(-form_costs[u])
  }, utterance_forms)
}

var getUtterancePrior = cache(function(utterance_forms){
  // var utterances = _.values(utterance_forms); // cost based on string
  var utterances = _.keys(utterance_forms); // cost based on form
  var uttProbs = uttCosts(utterances);
  return Categorical({vs: _.keys(utterance_forms), ps: uttProbs})
})

var speakerOptimality = 1;

var listener0 = cache(function(utterance_form, thresholds) {
  Infer({model: function(){
    var state = sample(DiscreteBeta(1, 1));
    // var state = sample(DiscreteGaussian(0, 0.5));
    var m = meaning(utterance_form, state, thresholds);
    condition(m);
    return state;
  }})
}, 10000);

var speaker1 = cache(function(state, thresholds, formToUttMapping) {
  Infer({model: function(){
    var UtterancePrior = getUtterancePrior(formToUttMapping);
    var utterance_form = sample(UtterancePrior);
    var utterance = formToUttMapping[utterance_form];
    // console.log(utterance)
    // console.log(utterance_form)
    var L0 = listener0(utterance_form, thresholds);
    factor(speakerOptimality*L0.score(state));
    return utterance;
  }})
}, 10000);

var listener1 = cache(function(utterance) {
  Infer({model: function(){

    var ParseDistribution = parse(utterance);
    var thresholds = {
        pos: uniformDraw(thetaBins), 
        ant: uniformDraw(thetaBins)
    }

    var state = sample(DiscreteBeta(1, 1));
    // var state = sample(DiscreteGaussian(0, 0.5));

    var S1 = speaker1(state, thresholds, formToUttMapping.utterances)
    observe(S1, utterance)
     return state
    // return  {alternativeSet: formToUttMapping.name, state: state}
  }})
}, 10000);
'
```

```{r wpplCalls-uncertainParser}
uncertainAlternativesListenerCall <- '
_.fromPairs(map(function(u){
  var post = listener1(u)
  return [u, post]
}, ["happy", "unhappy", "not_unhappy", "not_happy"]))
'
```

```{r runUncertainParseListener}
rs.listener.wp.2 <- webppl(paste(utils, uncertainAlternativesRSA, uncertainAlternativesListenerCall,  sep = '\n'),
                           data = c(1,5,5), data_var = "alternativesPriorProbs")
```


```{r}
rs.listener.wp.tidy.2 <- bind_rows(
  data.frame(rs.listener.wp.2$happy) %>% 
    mutate(utterance = "happy"),
  data.frame(rs.listener.wp.2$unhappy) %>% 
    mutate(utterance = "unhappy"),
  data.frame(rs.listener.wp.2$not_unhappy) %>% 
    mutate(utterance = "not_unhappy"),
  data.frame(rs.listener.wp.2$not_happy) %>% 
    mutate(utterance = "not_happy")
)

rs.listener.wp.tidy.samples.2 <- get_samples(
  rs.listener.wp.tidy.2 %>% rename(prob = probs), 10000) %>%
    mutate(utterance = factor(utterance,
                            levels = c("unhappy",
                                       "not_happy",
                                       "not_unhappy",
                                       "happy")))

# ggplot(rs.listener.wp.tidy.samples.2, 
#        aes( x = support.state, fill = support.alternativeSet, color = support.alternativeSet))+
#   geom_density(alpha = 0.4, size = 1.3)+
#   scale_fill_solarized()+
#   scale_color_solarized()+
#   facet_wrap(~utterance)+
#   xlab("Degree of happiness")+
#   ylab("Posterior probability density")+
#   scale_x_continuous(breaks =c(0, 1))+
#   scale_y_continuous(breaks = c(0, 2))

ggplot(rs.listener.wp.tidy.samples.2, 
       aes( x = support,fill = utterance, color = utterance))+
  geom_density(alpha = 0.4, size = 1.3)+
  scale_fill_solarized()+
  scale_color_solarized()+
  xlab("Degree of happiness")+
  ylab("Posterior probability density")+
  scale_x_continuous(breaks =c(0, 1))+
  scale_y_continuous(breaks = c(0, 2))

#ggsave("figs/L1_posteriors_wCost3_alpha1.png", width = 6, height = 4)
#head(rs.listener.wp.2)
```

Uncertainty about the alterantive set (and whether or not unhappy has its own threshold), does make "unhappy" have a weaker (negative) interpretation. However, the model infers that the "compositional unhappy" is relatively unlikely, which dampens this effect.


```{r}
rs.listener.wp.tidy.2 %>%
  group_by(utterance) %>%
  summarize(interpretation = sum(probs * support)) %>%
    mutate(utterance = factor(utterance,
                            levels = c("unhappy",
                                       "not_happy",
                                       "not_unhappy",
                                       "happy"))) %>%
  ggplot(., aes( x = utterance, y=interpretation,
                 fill = utterance, color = utterance))+
    geom_col(position = position_dodge(0.8), 
             width = 0.8,
             alpha =0.8, color = 'black')+
    #coord_flip()+
  geom_hline(yintercept = 0.5, lty = 3)+
  scale_fill_solarized()+
  guides(fill = F)+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  xlab("")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

#ggsave("figs/L1_means_wCost3_alpha1.png", width = 4, height = 3.5)
```



```{r}
rs.listener.wp.tidy.2 %>%
  group_by(utterance) %>%
  summarize(interpretation = sum(probs * support)) %>%
  kable()
```


## Parameter exploration

Fixed alternatives model: 
- cost to "un": makes "unhappy more extreme"

# QUD Change model


```{r rsa-qudChange}
fixedThresholdModel <- '
var utterances = [
  "happy",
  "not_unhappy",
  "not_happy",
  "unhappy"
  // "silence"
  // "neither_nor"
];

var cost_yes = 0;
var cost_not = 2;
var cost_un = 2;



var utterancePrior = cache(function(utterances){
  var uttCosts = map(function(u) {
    var notCost = hasNegModifier(u) ? cost_not : 0
    var unCost = hasNegMorph(u) ? cost_un : 0
    var totalCost = notCost + unCost
    return Math.exp(-totalCost)
  }, utterances)

  return Infer({model: function(){
    return utterances[discrete(uttCosts)]
  }})
})

var speakerOptimality = 1;
var speakerOptimality2 = 1;

var meaning = function(words, state){
  words == "happy" ? state > 0.7 :
  words == "not_happy" ? state <= 0.7 :
  words == "unhappy" ? state < 0.3 :
  words == "not_unhappy" ? state >= 0.3 :
  true
};

// var StatePrior = Categorical({
  // vs:[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
  // ps:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
// })

var StatePrior =  DiscreteBeta(1, 1)

var listener0 = cache(function(utterance, qud) {
  Infer({model: function(){
    var state = sample(StatePrior);
    var qudVal = qud == "state" ? state : meaning(qud, state)
    var m = meaning(utterance, state);
    condition(m);
    return qudVal;
  }, method: "enumerate"})
}, 10000);

var speaker1 = cache(function(state, qud) {
  Infer({model: function(){
    var utterance = sample(utterancePrior(utterances));
    var qudVal = qud == "state" ? state : meaning(qud, state)
    // var utterance = sample(utterancePrior(
      // qud =="happy" ? ["happy", "not_happy"] :
      // qud =="unhappy" ? ["unhappy", "not_unhappy"] :
      // utterances
    // ))
    var L0 = listener0(utterance, qud);
    factor(speakerOptimality*L0.score(qudVal));
    return utterance;
  }, method: "enumerate"})
}, 10000);

var listener1 = cache(function(list_of_utterances) {
  Infer({model: function(){
   var state = repeat(list_of_utterances.length, function(){ sample(StatePrior) })
   // var qud = list_of_utterances[0]  == "unhappy" ? "state" :
//       list_of_utterances[0]  == "not_happy" ? "happy" : 
  //    list_of_utterances[0]  == "not_unhappy" ? "unhappy" : 
  //    list_of_utterances[0]  == "happy" ? "state" : 
  //    "state"
   //  display(qud)
    var qud = "state"
     
     map2(function(u, s){
      // display(s)
       var S1 = speaker1(s, qud)
      // display(u + " " + S1.score(u))
       observe(S1, u)
    }, list_of_utterances, state)

    return {state: _.fromPairs(_.zip(list_of_utterances, state))}
    
  }, method: "enumerate"})
}, 10000);
'
```



```{r rsa-fixedSemantics}
fixedThresholdModel <- '
var utterances = [
  "happy",
  "not_unhappy",
  "not_happy",
  "unhappy"
  // "silence"
  // "neither_nor"
];

var cost_yes = 0;
var cost_not = 2;
var cost_un = 1;

var uttCosts = map(function(u) {
  var notCost = hasNegModifier(u) ? cost_not : 0
  var unCost = hasNegMorph(u) ? cost_un : 0
  var totalCost = notCost + unCost
  return Math.exp(-totalCost)
}, utterances)

var utterancePrior = Infer({model: function(){
    return utterances[discrete(uttCosts)]
}})

var speakerOptimality = 5;
var speakerOptimality2 = 1;

var meaning = function(words, state){
  words == "happy" ? state > 0.8 :
  words == "not_happy" ? state <= 0.8 :
  words == "unhappy" ? state < 0.3 :
  words == "not_unhappy" ? state >= 0.3 :
  true
};

// var StatePrior = Categorical({
  // vs:[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
  // ps:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
// })

var StatePrior =  DiscreteBeta(1, 1)

var listener0 = cache(function(utterance) {
  Infer({model: function(){
    var state = sample(StatePrior);
    var m = meaning(utterance, state);
    condition(m);
    return state;
  }, method: "enumerate"})
}, 10000);

var speaker1 = cache(function(state) {
  Infer({model: function(){
    var utterance = sample(utterancePrior);
    var L0 = listener0(utterance);
    factor(speakerOptimality*L0.score(state));
    return utterance;
  }, method: "enumerate"})
}, 10000);

var listener1 = cache(function(list_of_utterances) {
  Infer({model: function(){
   var state = repeat(list_of_utterances.length, function(){ sample(StatePrior) })

     map2(function(u, s){
      // display(s)
       var S1 = speaker1(s)
      // display(u + " " + S1.score(u))
       observe(S1, u)
    }, list_of_utterances, state)

    return {state: _.fromPairs(_.zip(list_of_utterances, state))}
    
  }, method: "enumerate"})
}, 10000);
'
```

```{r wpplCalls-changeQUD}
fixedThresholdListenerCall <- '
_.fromPairs(map(function(u){
  display(u)
  var post = listener1([u])
  display(u + " __ Comp(un) = " + expectation(post, function(x){return x.compositional_un}))
  display(u + " __ Comp(not) = " + expectation(post, function(x){return x.compositional_not}))
  return [u, post]
//  return [u, marginalize(post, "state")]
}, utterances))
'
#uncertainHasThresholdListenerCall<- 'listener1("unhappy")'
```


```{r multipleUtterancesQUDModelCall}
multipleUtterancesFixedThresholdListenerCall <- '
// var post = listener1(["happy", "not_happy", "unhappy", "not_unhappy"])
//var post = listener1(["not_unhappy", "unhappy","not_happy", "happy"])
var post = listener1(["not_unhappy", "unhappy","not_happy", "happy"])
display(" __ comp(un) = " + expectation(post, function(x){return x.compositional_un }))
display(" __ comp(not) = " + expectation(post, function(x){return x.compositional_not }))
//marginalize(post, "state")
post
'
```

```{r fixedThresholdSpeakerCall}
speakerCall <- '
_.flatten(
  map(function(s){
     // console.log(s + " th " + tH + " tu " + tU)
    var speakProbs = speaker1(s)
     return {  
        state: s,
        "happy": Math.exp(speakProbs.score("happy")),
        "unhappy": Math.exp(speakProbs.score("unhappy")),
        "not_unhappy": Math.exp(speakProbs.score("not_unhappy")),
        "not_happy": Math.exp(speakProbs.score("not_happy"))
      }
  }, midBins)
)
'
```


```{r runQUDListener}
rs.listener.wp.fixed <- webppl(paste(rsaBinsCoarse,
                                 utils, 
                                 fixedThresholdModel,
                                 fixedThresholdListenerCall,
                                 #multipleUtterancesListenerCall, # takes 6 min to run
                                 sep = '\n'))

rs.listener.wp.tidy.fixed <- bind_rows(
  data.frame(rs.listener.wp.fixed$happy) %>%
    mutate(utterance = "happy") %>%
    rename(support.state = state.happy),
  data.frame(rs.listener.wp.fixed$unhappy) %>%
    mutate(utterance = "unhappy")%>%
    rename(support.state = state.unhappy),
  data.frame(rs.listener.wp.fixed$not_unhappy) %>%
    mutate(utterance = "not_unhappy")%>%
    rename(support.state = state.not_unhappy),
  data.frame(rs.listener.wp.fixed$not_happy) %>%
    mutate(utterance = "not_happy")%>%
    rename(support.state = state.not_happy)
) %>%
  rename(prob = probs)

# rs.listener.wp.tidy.2 <- rs.listener.wp.2 %>%
#   gather(utterance, support.state, starts_with("state")) %>%
#   mutate(utterance = gsub("state.","", utterance))

rs.listener.wp.tidy.samples.fixed <- get_samples(rs.listener.wp.tidy.fixed %>%
    group_by(utterance, support.state) %>%
    summarize(prob = sum(prob)) %>%
    ungroup(), 10000) %>%
    #rename(prob = probs), 10000) %>%
    mutate(utterance = factor(utterance,
                            levels = rev(c("not_unhappy",
                                       "not_happy",
                                       "unhappy",
                                       "happy")),
                          labels = rev(c("not unhappy","not happy",  "unhappy", "happy"))))

ggplot(rs.listener.wp.tidy.samples.fixed, 
       aes( x = support.state, fill = utterance, color = utterance))+
  geom_density(alpha = 0.4, size = 1.3, adjust = 4)+
  #geom_bar(position = position_dodge(), alpha = 0.4, size = 1.3)+
  scale_fill_solarized()+
  theme_black()+
#  geom_histogram(alpha = 0.4, size = 1.3)+
  scale_color_solarized()+
  xlab("Degree of happiness")+
  #facet_wrap(~utterance)+
  ylab("Posterior probability density")+
  scale_x_continuous(breaks =c(0, 1))#+
  #scale_y_continuous(breaks = c(0, 2))

#ggsave(paste(fig.path, "model_L1_fixedSemantics_1utts_negationImpliesPolarQud_allUtts.pdf",  sep = ""),
 #      width = 5.5, height = 3.5)

# ggsave(paste(fig.path, "model_L1_fixedSemantics_1utts_stateQud_costNot2Un1_opt5.pdf",  sep = ""),
#        width = 5.5, height = 3.5)
```

```{r runFixedSpeaker}
rs.wp.fs <- webppl(paste(rsaBinsCoarse, utils, meaningFn,                                  fixedThresholdModel,speakerCall,
                      sep = '\n'))

rs.tidy <- data.frame(rs.wp.fs) %>%
  gather(utt, prob, -state)

ggplot(rs.tidy %>%
         mutate(utt = factor(utt,
                            levels = rev(c("not_unhappy",
                                       "not_happy",
                                       "unhappy",
                                       "happy")),
                          labels = rev(c("not unhappy","not happy",  "unhappy", "happy")))), 
       aes( x = state, y = prob, color = utt))+
  geom_line(size = 1.5, alpha = 0.9)+#aes(frame = happy_theta))+
  scale_color_solarized()+
  theme_black()+
  ylab("Speaker production probability")+
  xlab("Height")+
  scale_x_continuous(breaks = c(0, 1))+
  scale_y_continuous(breaks = c(0, 1))+
  theme(strip.text.y = element_text(angle = 0))

# ggsave(paste(fig.path, "model_S1_fixedThetaSpeaker_costNot2Un1_opt5.pdf", 
#              sep = ""),
#        width = 5, height = 3)
```
